{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6fcaf1a",
   "metadata": {},
   "source": [
    "# Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474153c",
   "metadata": {},
   "source": [
    "Import the libraries and importing keras model amd layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664c8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e32590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"concrete_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6947707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63287b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ac441",
   "metadata": {},
   "source": [
    "So the first concrete sample has 540 cubic meter of cement, 0 cubic meter of blast furnace slag, 0 cubic meter of fly ash, 162 cubic meter of water, 2.5 cubic meter of superplaticizer, 1040 cubic meter of coarse aggregate, 676 cubic meter of fine aggregate. Such a concrete mix which is 28 days old, has a compressive strength of 79.99 MPa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf051f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc4c3e",
   "metadata": {},
   "source": [
    "#### Split data into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08e9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=data.drop(columns='Strength')\n",
    "target=data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53592b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_norm=(predictor-predictor.mean())/predictor.std()\n",
    "predictor_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66167c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(predictor,target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799836d1",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check of the predictors and the target dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f401182",
   "metadata": {},
   "source": [
    "#### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db1bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols=predictor.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de508bf1",
   "metadata": {},
   "source": [
    "## Build a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f2b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    \n",
    "    # create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(10,activation='relu',input_shape=(n_cols,)))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1ffc2",
   "metadata": {},
   "source": [
    "The above function create a model that has three hidden layers, each of 5 hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba369d2",
   "metadata": {},
   "source": [
    "## Train and Test the Network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e216f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a668609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1992.3743\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.0429 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.6944 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.8340 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.8364 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.8972 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164.4822 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.8871 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.9374 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.0832 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.3734  \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 170.7940 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.6313 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.2557 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.1985 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.8676 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.8363 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.6816\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.1821 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.3567\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.5527 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.7726 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.6193 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.3202 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.6584 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.6777 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.0259 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.4682  \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.9946 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.1972 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.9414  \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.8315 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.5985 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.4279 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.3922\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.3502\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.1038  \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.4723 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.8168 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.1362 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.1798  \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.8140 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.9905 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.7746 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.0829 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.9677 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.1715  \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.4598 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.5068 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.7294 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bb923c7d50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3141518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828aeffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58.73176   ],\n",
       "       [30.461832  ],\n",
       "       [35.97067   ],\n",
       "       [21.197561  ],\n",
       "       [16.923752  ],\n",
       "       [28.282816  ],\n",
       "       [18.851711  ],\n",
       "       [17.740343  ],\n",
       "       [22.051956  ],\n",
       "       [40.120865  ],\n",
       "       [22.875114  ],\n",
       "       [22.01788   ],\n",
       "       [29.003304  ],\n",
       "       [60.87757   ],\n",
       "       [51.439857  ],\n",
       "       [53.61368   ],\n",
       "       [51.190952  ],\n",
       "       [47.144352  ],\n",
       "       [48.296867  ],\n",
       "       [46.107903  ],\n",
       "       [23.030632  ],\n",
       "       [18.26268   ],\n",
       "       [24.179514  ],\n",
       "       [47.94485   ],\n",
       "       [14.501095  ],\n",
       "       [25.724598  ],\n",
       "       [16.968288  ],\n",
       "       [49.19458   ],\n",
       "       [40.04694   ],\n",
       "       [38.759026  ],\n",
       "       [55.12574   ],\n",
       "       [26.336615  ],\n",
       "       [21.070515  ],\n",
       "       [21.887564  ],\n",
       "       [49.467125  ],\n",
       "       [39.538383  ],\n",
       "       [44.38529   ],\n",
       "       [18.153824  ],\n",
       "       [14.7019825 ],\n",
       "       [23.139776  ],\n",
       "       [71.34497   ],\n",
       "       [32.918373  ],\n",
       "       [38.768196  ],\n",
       "       [44.21467   ],\n",
       "       [55.598763  ],\n",
       "       [46.367554  ],\n",
       "       [14.942974  ],\n",
       "       [32.238914  ],\n",
       "       [24.409218  ],\n",
       "       [44.91659   ],\n",
       "       [25.970907  ],\n",
       "       [20.723412  ],\n",
       "       [56.42456   ],\n",
       "       [63.599255  ],\n",
       "       [23.892635  ],\n",
       "       [36.893196  ],\n",
       "       [26.570496  ],\n",
       "       [21.98629   ],\n",
       "       [47.975964  ],\n",
       "       [19.695953  ],\n",
       "       [39.478073  ],\n",
       "       [25.055038  ],\n",
       "       [57.29905   ],\n",
       "       [46.645287  ],\n",
       "       [21.571949  ],\n",
       "       [43.52101   ],\n",
       "       [32.84413   ],\n",
       "       [20.054003  ],\n",
       "       [46.364     ],\n",
       "       [55.0817    ],\n",
       "       [23.841688  ],\n",
       "       [35.17401   ],\n",
       "       [ 0.38271856],\n",
       "       [49.578228  ],\n",
       "       [53.05818   ],\n",
       "       [50.274483  ],\n",
       "       [53.033752  ],\n",
       "       [50.62802   ],\n",
       "       [53.064423  ],\n",
       "       [32.11086   ],\n",
       "       [25.489864  ],\n",
       "       [15.546183  ],\n",
       "       [49.570732  ],\n",
       "       [38.417164  ],\n",
       "       [48.226257  ],\n",
       "       [44.51191   ],\n",
       "       [40.54705   ],\n",
       "       [29.98372   ],\n",
       "       [41.092896  ],\n",
       "       [58.73176   ],\n",
       "       [64.40254   ],\n",
       "       [29.569887  ],\n",
       "       [32.82286   ],\n",
       "       [45.135853  ],\n",
       "       [36.416702  ],\n",
       "       [19.884571  ],\n",
       "       [28.554     ],\n",
       "       [58.73176   ],\n",
       "       [38.231247  ],\n",
       "       [44.283344  ],\n",
       "       [14.669031  ],\n",
       "       [58.760944  ],\n",
       "       [22.41286   ],\n",
       "       [41.772335  ],\n",
       "       [25.25352   ],\n",
       "       [60.685276  ],\n",
       "       [48.41043   ],\n",
       "       [68.2831    ],\n",
       "       [53.399155  ],\n",
       "       [26.72823   ],\n",
       "       [35.89053   ],\n",
       "       [13.406776  ],\n",
       "       [26.582449  ],\n",
       "       [30.119226  ],\n",
       "       [43.838825  ],\n",
       "       [31.998602  ],\n",
       "       [46.14067   ],\n",
       "       [29.494982  ],\n",
       "       [40.43687   ],\n",
       "       [47.29342   ],\n",
       "       [40.766617  ],\n",
       "       [44.142952  ],\n",
       "       [62.895054  ],\n",
       "       [63.76539   ],\n",
       "       [49.1724    ],\n",
       "       [ 2.5964103 ],\n",
       "       [28.287754  ],\n",
       "       [49.618675  ],\n",
       "       [10.22826   ],\n",
       "       [38.30091   ],\n",
       "       [18.758083  ],\n",
       "       [52.778595  ],\n",
       "       [53.21923   ],\n",
       "       [49.49489   ],\n",
       "       [10.789021  ],\n",
       "       [37.79249   ],\n",
       "       [22.436981  ],\n",
       "       [15.369631  ],\n",
       "       [13.106083  ],\n",
       "       [49.27832   ],\n",
       "       [54.4383    ],\n",
       "       [29.81943   ],\n",
       "       [ 7.276111  ],\n",
       "       [45.212772  ],\n",
       "       [43.87889   ],\n",
       "       [17.020714  ],\n",
       "       [47.81271   ],\n",
       "       [22.746515  ],\n",
       "       [18.620178  ],\n",
       "       [53.04003   ],\n",
       "       [17.586096  ],\n",
       "       [26.706194  ],\n",
       "       [49.95318   ],\n",
       "       [61.54158   ],\n",
       "       [19.774292  ],\n",
       "       [32.48824   ],\n",
       "       [23.274263  ],\n",
       "       [31.247652  ],\n",
       "       [48.288307  ],\n",
       "       [35.03218   ],\n",
       "       [13.776577  ],\n",
       "       [26.052027  ],\n",
       "       [36.330017  ],\n",
       "       [36.364853  ],\n",
       "       [42.88952   ],\n",
       "       [44.35968   ],\n",
       "       [19.293919  ],\n",
       "       [40.21721   ],\n",
       "       [39.06198   ],\n",
       "       [17.546852  ],\n",
       "       [54.853516  ],\n",
       "       [ 1.5221896 ],\n",
       "       [20.354723  ],\n",
       "       [32.463013  ],\n",
       "       [40.92184   ],\n",
       "       [15.382631  ],\n",
       "       [49.342445  ],\n",
       "       [44.731697  ],\n",
       "       [27.230623  ],\n",
       "       [41.244392  ],\n",
       "       [24.60892   ],\n",
       "       [ 7.7241817 ],\n",
       "       [46.78721   ],\n",
       "       [14.933586  ],\n",
       "       [31.207266  ],\n",
       "       [22.98589   ],\n",
       "       [39.494972  ],\n",
       "       [26.126152  ],\n",
       "       [31.858461  ],\n",
       "       [70.200455  ],\n",
       "       [61.77465   ],\n",
       "       [17.740559  ],\n",
       "       [44.382324  ],\n",
       "       [38.791958  ],\n",
       "       [16.213003  ],\n",
       "       [32.747993  ],\n",
       "       [ 8.447029  ],\n",
       "       [48.399193  ],\n",
       "       [11.130745  ],\n",
       "       [62.78936   ],\n",
       "       [24.926682  ],\n",
       "       [15.970816  ],\n",
       "       [43.52616   ],\n",
       "       [33.040833  ],\n",
       "       [43.148823  ],\n",
       "       [21.731596  ],\n",
       "       [45.960815  ],\n",
       "       [50.225468  ],\n",
       "       [44.976807  ],\n",
       "       [30.343012  ],\n",
       "       [32.52964   ],\n",
       "       [32.022873  ],\n",
       "       [46.677788  ],\n",
       "       [70.017204  ],\n",
       "       [31.239784  ],\n",
       "       [30.13042   ],\n",
       "       [41.104355  ],\n",
       "       [31.47541   ],\n",
       "       [20.944986  ],\n",
       "       [23.874258  ],\n",
       "       [22.727478  ],\n",
       "       [32.329155  ],\n",
       "       [40.755924  ],\n",
       "       [23.578613  ],\n",
       "       [48.843746  ],\n",
       "       [62.107117  ],\n",
       "       [22.388077  ],\n",
       "       [35.92228   ],\n",
       "       [20.550594  ],\n",
       "       [59.541016  ],\n",
       "       [40.741356  ],\n",
       "       [50.458572  ],\n",
       "       [39.151794  ],\n",
       "       [50.11264   ],\n",
       "       [19.142742  ],\n",
       "       [22.299961  ],\n",
       "       [46.828217  ],\n",
       "       [42.22351   ],\n",
       "       [24.749025  ],\n",
       "       [53.417225  ],\n",
       "       [34.347084  ],\n",
       "       [63.191525  ],\n",
       "       [24.90713   ],\n",
       "       [32.959305  ],\n",
       "       [56.55877   ],\n",
       "       [60.585155  ],\n",
       "       [26.470253  ],\n",
       "       [12.719717  ],\n",
       "       [69.31847   ],\n",
       "       [21.659475  ],\n",
       "       [43.982582  ],\n",
       "       [40.359642  ],\n",
       "       [22.902113  ],\n",
       "       [22.818233  ],\n",
       "       [22.088049  ],\n",
       "       [26.067608  ],\n",
       "       [43.818058  ],\n",
       "       [18.752775  ],\n",
       "       [33.19802   ],\n",
       "       [24.916363  ],\n",
       "       [18.638113  ],\n",
       "       [26.092173  ],\n",
       "       [14.104349  ],\n",
       "       [44.951134  ],\n",
       "       [47.127007  ],\n",
       "       [13.76347   ],\n",
       "       [38.918877  ],\n",
       "       [30.204342  ],\n",
       "       [62.48934   ],\n",
       "       [47.68686   ],\n",
       "       [27.274582  ],\n",
       "       [42.6159    ],\n",
       "       [43.438393  ],\n",
       "       [25.698517  ],\n",
       "       [39.84644   ],\n",
       "       [16.374647  ],\n",
       "       [ 6.3192954 ],\n",
       "       [27.464424  ],\n",
       "       [47.190887  ],\n",
       "       [56.526073  ],\n",
       "       [38.025574  ],\n",
       "       [31.982132  ],\n",
       "       [25.81664   ],\n",
       "       [42.647297  ],\n",
       "       [15.126911  ],\n",
       "       [40.984745  ],\n",
       "       [28.477724  ],\n",
       "       [14.06176   ],\n",
       "       [39.901546  ],\n",
       "       [17.693304  ],\n",
       "       [25.691626  ],\n",
       "       [52.11905   ],\n",
       "       [26.528818  ],\n",
       "       [26.723494  ],\n",
       "       [24.545143  ],\n",
       "       [ 9.335808  ],\n",
       "       [51.01143   ],\n",
       "       [42.690525  ],\n",
       "       [ 7.626428  ],\n",
       "       [44.227943  ],\n",
       "       [27.583761  ],\n",
       "       [50.843975  ],\n",
       "       [31.074791  ],\n",
       "       [19.60163   ],\n",
       "       [39.57711   ],\n",
       "       [30.378044  ],\n",
       "       [17.267305  ],\n",
       "       [34.502518  ],\n",
       "       [44.122986  ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "# model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a401d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 80ms/step - loss: 26448.9453 - val_loss: 14182.1475\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 7ms/step - loss: 9094.8994 - val_loss: 5275.9165\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 4024.9070 - val_loss: 2868.3479\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 2279.2390 - val_loss: 1762.4739\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1397.5723 - val_loss: 1149.8301\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 938.6027 - val_loss: 781.7204\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 681.3923 - val_loss: 614.8434\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 565.0300 - val_loss: 537.3608\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 6ms/step - loss: 500.0534 - val_loss: 489.0579\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 6ms/step - loss: 457.1810 - val_loss: 447.4451\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 6ms/step - loss: 419.2731 - val_loss: 412.7209\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 388.1376 - val_loss: 383.3922\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 358.1991 - val_loss: 358.3255\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 333.1131 - val_loss: 333.8850\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 6ms/step - loss: 310.0238 - val_loss: 311.5048\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 289.9959 - val_loss: 291.0546\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 6ms/step - loss: 271.2096 - val_loss: 274.1562\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 6ms/step - loss: 255.9576 - val_loss: 261.7664\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 244.3972 - val_loss: 248.0904\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 6ms/step - loss: 233.8739 - val_loss: 239.0762\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.1442 - val_loss: 231.8011\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.6972 - val_loss: 226.1458\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.2026 - val_loss: 220.7138\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.4432 - val_loss: 222.9383\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 208.3917 - val_loss: 212.3849\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 6ms/step - loss: 205.6974 - val_loss: 211.0016\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 6ms/step - loss: 204.3139 - val_loss: 211.1177\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.0404 - val_loss: 205.1602\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.6735 - val_loss: 205.4209\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.0725 - val_loss: 201.1362\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 8ms/step - loss: 198.0350 - val_loss: 200.6961\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.2059 - val_loss: 199.2803\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.8082 - val_loss: 195.8615\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 6ms/step - loss: 191.5741 - val_loss: 194.9014\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 8ms/step - loss: 189.4280 - val_loss: 199.9980\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.4362 - val_loss: 190.2021\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.4352 - val_loss: 188.3539\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.4260 - val_loss: 189.7167\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 7ms/step - loss: 187.4323 - val_loss: 185.3412\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.4348 - val_loss: 182.0188\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.4841 - val_loss: 180.8911\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.8060 - val_loss: 185.8865\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.5846 - val_loss: 175.6429\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.5819 - val_loss: 174.9498\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.4735 - val_loss: 170.4477\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.8339 - val_loss: 168.3282\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.5701 - val_loss: 164.8618\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 7ms/step - loss: 164.3234 - val_loss: 161.2779\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.9354 - val_loss: 158.6653\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 16ms/step - loss: 160.4124 - val_loss: 157.2694\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.4578 - val_loss: 154.4382\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.1172 - val_loss: 151.1793\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.7878 - val_loss: 149.6514\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.0399 - val_loss: 148.5839\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.1566 - val_loss: 145.7923\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.0900 - val_loss: 142.5009\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 8ms/step - loss: 143.3471 - val_loss: 141.9210\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 8ms/step - loss: 141.3086 - val_loss: 138.4140\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 6ms/step - loss: 140.4269 - val_loss: 136.2876\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 6ms/step - loss: 137.7684 - val_loss: 139.9402\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.3884 - val_loss: 134.3870\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.4991 - val_loss: 131.4473\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 8ms/step - loss: 138.6472 - val_loss: 129.6967\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.8115 - val_loss: 128.1157\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.4241 - val_loss: 128.1852\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 9ms/step - loss: 129.7841 - val_loss: 125.6086\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.0451 - val_loss: 125.6636\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.3617 - val_loss: 123.8152\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.3302 - val_loss: 123.6618\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1759 - val_loss: 121.1520\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.0246 - val_loss: 120.2578\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.3037 - val_loss: 119.6667\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.5680 - val_loss: 114.5799\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.8200 - val_loss: 113.5967\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7062 - val_loss: 114.0462\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.8515 - val_loss: 111.2575\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.1688 - val_loss: 110.2208\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.4358 - val_loss: 110.4737\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 114.1814 - val_loss: 108.9366\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1189 - val_loss: 107.7818\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.0640 - val_loss: 111.9485\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.9790 - val_loss: 108.6000\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 112.7608 - val_loss: 104.1598\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.0828 - val_loss: 103.9537\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.2256 - val_loss: 102.1650\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.0325 - val_loss: 101.9986\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.6563 - val_loss: 100.3488\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.6509 - val_loss: 101.4675\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.4891 - val_loss: 99.1247\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.9264 - val_loss: 99.3198\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.8932 - val_loss: 97.3588\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.3177 - val_loss: 97.1455\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.1673 - val_loss: 99.3714\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.4173 - val_loss: 94.9037\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.6141 - val_loss: 96.4762\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.7152 - val_loss: 95.0878\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.8580 - val_loss: 95.9389\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 10ms/step - loss: 98.1537 - val_loss: 93.2104\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.9669 - val_loss: 92.3558\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6069 - val_loss: 91.5704\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 82ms/step - loss: 8744.3076 - val_loss: 995.4125\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1104.4596 - val_loss: 575.5016\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 615.0167 - val_loss: 456.1599\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 515.4215 - val_loss: 401.9942\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 450.0685 - val_loss: 355.7427\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 406.5126 - val_loss: 325.5708\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.3656 - val_loss: 298.8663\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.2063 - val_loss: 282.4792\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 320.3103 - val_loss: 268.0540\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 300.6036 - val_loss: 254.9690\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 285.8588 - val_loss: 244.2049\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 271.0843 - val_loss: 234.3359\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 256.9818 - val_loss: 225.5005\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.8750 - val_loss: 215.9664\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.0357 - val_loss: 207.0148\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.4487 - val_loss: 197.5275\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.4880 - val_loss: 189.2521\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.7261 - val_loss: 180.6249\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.6988 - val_loss: 173.9935\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.4927 - val_loss: 167.8206\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.2771 - val_loss: 159.9450\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.1573 - val_loss: 152.0255\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.6323 - val_loss: 146.2923\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.7500 - val_loss: 140.1114\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.4623 - val_loss: 135.9203\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 136.3600 - val_loss: 130.2284\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.1984 - val_loss: 126.6879\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.3869 - val_loss: 122.7908\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 121.8215 - val_loss: 119.2658\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.6559 - val_loss: 116.4075\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6545 - val_loss: 108.2311\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.2047 - val_loss: 103.0181\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.0564 - val_loss: 102.8851\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.5513 - val_loss: 97.9532\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.4973 - val_loss: 96.8940\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 97.8274 - val_loss: 96.0535\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 97.0062 - val_loss: 95.7983\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.3078 - val_loss: 93.9634\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.0878 - val_loss: 91.0207\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.3404 - val_loss: 93.6261\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.9197 - val_loss: 88.5519\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.1518 - val_loss: 87.2442\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.4530 - val_loss: 85.5006\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.5279 - val_loss: 83.2199\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.2909 - val_loss: 88.9727\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.1871 - val_loss: 79.9578\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.4769 - val_loss: 80.1883\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0453 - val_loss: 77.8908\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.2341 - val_loss: 78.8744\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7917 - val_loss: 74.5866\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.1367 - val_loss: 74.9929\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.2885 - val_loss: 74.6948\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.6894 - val_loss: 77.8416\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.0378 - val_loss: 73.3285\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.2522 - val_loss: 72.3784\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4957 - val_loss: 80.3333\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7180 - val_loss: 73.1934\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.0073 - val_loss: 69.2042\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.4796 - val_loss: 69.4015\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.6715 - val_loss: 68.6622\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.7779 - val_loss: 67.8939\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.1356 - val_loss: 68.8830\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9741 - val_loss: 71.6583\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9922 - val_loss: 66.8943\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.7029 - val_loss: 66.0653\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2075 - val_loss: 66.0578\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.2447 - val_loss: 64.9401\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.4771 - val_loss: 65.0527\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.4853 - val_loss: 66.1399\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.0468 - val_loss: 64.4715\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.6021 - val_loss: 62.6115\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0235 - val_loss: 61.4502\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 9ms/step - loss: 68.7721 - val_loss: 65.0713\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 14ms/step - loss: 69.1061 - val_loss: 66.2654\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.1007 - val_loss: 67.1353\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.1035 - val_loss: 59.5757\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 8ms/step - loss: 69.1704 - val_loss: 58.5177\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9140 - val_loss: 59.9652\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2103 - val_loss: 63.4573\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0864 - val_loss: 60.3746\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.5596 - val_loss: 61.7403\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 69.2013 - val_loss: 57.0289\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4150 - val_loss: 56.4705\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.3556 - val_loss: 58.4340\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 10ms/step - loss: 65.3216 - val_loss: 55.7594\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9626 - val_loss: 54.6651\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.0422 - val_loss: 55.9522\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7896 - val_loss: 57.1196\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.0347 - val_loss: 55.4246\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.9842 - val_loss: 54.8386\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.2528 - val_loss: 53.9607\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.4086 - val_loss: 53.0839\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.2615 - val_loss: 53.8316\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.4539 - val_loss: 56.2197\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.8340 - val_loss: 52.8864\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.1305 - val_loss: 52.2829\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.5966 - val_loss: 52.3350\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.5378 - val_loss: 55.8597\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.4494 - val_loss: 54.3666\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9554 - val_loss: 61.4066\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 73ms/step - loss: 435207.1562 - val_loss: 269467.0625\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 192259.4219 - val_loss: 126321.4531\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 90240.6172 - val_loss: 53089.4023\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 29892.8379 - val_loss: 14560.9414\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 9539.8535 - val_loss: 5038.3130\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 2722.4006 - val_loss: 892.3593\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 464.7007 - val_loss: 318.8051\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 264.6040 - val_loss: 283.6188\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.7042 - val_loss: 277.5314\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.9635 - val_loss: 272.8031\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.3256 - val_loss: 267.3795\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.7039 - val_loss: 260.3793\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.2438 - val_loss: 253.5406\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.8282 - val_loss: 247.3485\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.1641 - val_loss: 241.0712\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.2550 - val_loss: 235.6093\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.7448 - val_loss: 230.6912\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.4027 - val_loss: 226.8134\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.6863 - val_loss: 223.4290\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.5858 - val_loss: 220.5871\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.6075 - val_loss: 217.6694\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.6520 - val_loss: 214.5412\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.1791 - val_loss: 212.4530\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.6480 - val_loss: 209.6269\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.9005 - val_loss: 207.6404\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 180.0546 - val_loss: 205.2245\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.4749 - val_loss: 203.8504\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 7ms/step - loss: 176.8669 - val_loss: 201.1978\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.2182 - val_loss: 200.1508\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.4397 - val_loss: 197.8857\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.2804 - val_loss: 196.1870\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.6523 - val_loss: 194.2836\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.6822 - val_loss: 193.3258\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.9594 - val_loss: 191.3342\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.5876 - val_loss: 189.4736\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.9724 - val_loss: 187.8719\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.4757 - val_loss: 186.4458\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.4572 - val_loss: 185.1254\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.2450 - val_loss: 183.2899\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.6906 - val_loss: 182.0246\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.0659 - val_loss: 180.3820\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.6100 - val_loss: 178.8107\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.1335 - val_loss: 177.6083\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.0457 - val_loss: 176.1671\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.4647 - val_loss: 174.5670\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.0454 - val_loss: 173.7721\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.0314 - val_loss: 171.8564\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.6537 - val_loss: 171.1277\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.5030 - val_loss: 169.2928\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.1533 - val_loss: 167.9643\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 140.3074 - val_loss: 167.2110\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.9834 - val_loss: 165.7704\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.9208 - val_loss: 164.8974\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.9220 - val_loss: 163.5816\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.8223 - val_loss: 162.9902\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.2181 - val_loss: 161.3978\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.2287 - val_loss: 160.9654\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.8429 - val_loss: 159.3901\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.8959 - val_loss: 158.6222\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.7806 - val_loss: 157.1703\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.8684 - val_loss: 156.2697\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 129.6098 - val_loss: 155.2213\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.1728 - val_loss: 154.3484\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.4063 - val_loss: 153.2940\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.6086 - val_loss: 152.2805\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.9551 - val_loss: 151.5802\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1844 - val_loss: 150.5723\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.1104 - val_loss: 149.7374\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.4144 - val_loss: 148.9772\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.7374 - val_loss: 148.0707\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.8814 - val_loss: 146.9161\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 9ms/step - loss: 121.1111 - val_loss: 146.5255\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.7370 - val_loss: 145.5039\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.8098 - val_loss: 144.6755\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 10ms/step - loss: 119.2228 - val_loss: 144.4325\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.2815 - val_loss: 143.1526\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6621 - val_loss: 142.3175\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.4741 - val_loss: 141.8996\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.4841 - val_loss: 140.9447\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3484 - val_loss: 140.4165\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.6679 - val_loss: 139.5298\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.9819 - val_loss: 138.8003\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1379 - val_loss: 137.9967\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6432 - val_loss: 137.2702\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.0101 - val_loss: 136.4117\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.5620 - val_loss: 135.9660\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.0207 - val_loss: 135.4437\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.2714 - val_loss: 135.4465\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6060 - val_loss: 134.8486\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.4087 - val_loss: 133.6587\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.4208 - val_loss: 132.7629\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.5622 - val_loss: 133.1413\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.2500 - val_loss: 132.7297\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.6198 - val_loss: 131.8480\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0813 - val_loss: 130.9713\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.7237 - val_loss: 130.6090\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5295 - val_loss: 130.7446\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.9218 - val_loss: 129.7067\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.6360 - val_loss: 128.7232\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.4008 - val_loss: 128.3473\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 596.3611 - val_loss: 404.6092\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 353.8167 - val_loss: 357.0764\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 304.1740 - val_loss: 333.2633\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 267.1638 - val_loss: 282.2035\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 222.5651 - val_loss: 204.5246\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.2310 - val_loss: 158.0140\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.5472 - val_loss: 134.8650\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.4419 - val_loss: 120.5700\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.1908 - val_loss: 114.5842\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.9076 - val_loss: 119.9621\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6423 - val_loss: 106.8457\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.6521 - val_loss: 108.9041\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.6676 - val_loss: 102.3951\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.8243 - val_loss: 100.0556\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.2480 - val_loss: 97.1299\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.7752 - val_loss: 97.1949\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.4806 - val_loss: 96.6380\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.1194 - val_loss: 92.4279\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.9089 - val_loss: 95.8440\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.8816 - val_loss: 93.8901\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.7059 - val_loss: 88.4576\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.7735 - val_loss: 90.0740\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.4786 - val_loss: 86.7118\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.1041 - val_loss: 106.1638\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.7443 - val_loss: 84.8443\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.8811 - val_loss: 83.2154\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.1955 - val_loss: 82.1355\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.9290 - val_loss: 84.7822\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.1472 - val_loss: 80.2546\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.5453 - val_loss: 86.0719\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7044 - val_loss: 77.5114\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.3338 - val_loss: 77.7276\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 8ms/step - loss: 76.2943 - val_loss: 75.6110\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.4359 - val_loss: 78.5695\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.2055 - val_loss: 74.4322\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.8860 - val_loss: 72.6515\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.0969 - val_loss: 72.1440\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4334 - val_loss: 71.3212\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.8713 - val_loss: 71.1862\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.7988 - val_loss: 72.1389\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.4814 - val_loss: 66.6588\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 65.7172 - val_loss: 65.9687\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.6784 - val_loss: 67.2924\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.5059 - val_loss: 63.4926\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.9821 - val_loss: 62.5332\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.8622 - val_loss: 61.9230\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.6202 - val_loss: 61.8382\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.6675 - val_loss: 72.4216\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.6131 - val_loss: 60.3909\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.2934 - val_loss: 59.4333\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.9981 - val_loss: 59.0631\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.7991 - val_loss: 58.6214\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.0728 - val_loss: 59.0213\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1594 - val_loss: 64.9405\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.1008 - val_loss: 56.9561\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.4040 - val_loss: 57.4775\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.5825 - val_loss: 57.6579\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.9428 - val_loss: 56.3933\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.0576 - val_loss: 56.6083\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 9ms/step - loss: 56.5241 - val_loss: 60.1909\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 56.8507 - val_loss: 55.7539\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.3574 - val_loss: 55.6574\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.4736 - val_loss: 55.5323\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.3584 - val_loss: 55.1642\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.0386 - val_loss: 66.1407\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.9422 - val_loss: 62.7004\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.7080 - val_loss: 55.6235\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.4095 - val_loss: 53.8681\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.1044 - val_loss: 53.2831\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 53.4926 - val_loss: 56.9410\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.8623 - val_loss: 56.9451\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.9132 - val_loss: 53.4681\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.4160 - val_loss: 52.8732\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.9344 - val_loss: 53.4725\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.9290 - val_loss: 52.8543\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.6427 - val_loss: 53.5401\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.9756 - val_loss: 52.1463\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.0550 - val_loss: 52.5529\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.5978 - val_loss: 51.6425\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 51.1209 - val_loss: 52.2159\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.7876 - val_loss: 53.8087\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 60.6284 - val_loss: 58.4657\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.7358 - val_loss: 51.5704\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 50.8800 - val_loss: 51.3021\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.1948 - val_loss: 51.7863\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 54.5270 - val_loss: 51.0062\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.0352 - val_loss: 52.3670\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.9213 - val_loss: 50.7206\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.7944 - val_loss: 51.9324\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.1478 - val_loss: 53.1643\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.3585 - val_loss: 49.8606\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.5785 - val_loss: 50.2962\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 16ms/step - loss: 50.8818 - val_loss: 59.1640\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.1983 - val_loss: 49.4752\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.2653 - val_loss: 49.8974\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.8555 - val_loss: 57.1065\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4779 - val_loss: 52.2742\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.5495 - val_loss: 51.9321\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.9483 - val_loss: 50.6829\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.8605 - val_loss: 68.3312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 1371.4248 - val_loss: 738.2938\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 389.4622 - val_loss: 354.8906\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 298.8929 - val_loss: 325.0930\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 274.9342 - val_loss: 308.5386\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.0519 - val_loss: 289.2985\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.6276 - val_loss: 273.7651\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.0571 - val_loss: 260.8727\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.1073 - val_loss: 249.5856\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.9142 - val_loss: 242.0086\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.8664 - val_loss: 231.7778\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.6408 - val_loss: 232.2670\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.0488 - val_loss: 224.0835\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.5435 - val_loss: 208.5194\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.2205 - val_loss: 210.6255\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.7336 - val_loss: 195.6530\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.4756 - val_loss: 199.1416\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.0279 - val_loss: 181.6827\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.3506 - val_loss: 176.3954\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.2964 - val_loss: 170.3413\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.2853 - val_loss: 165.9687\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.6675 - val_loss: 157.7272\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.1772 - val_loss: 152.6005\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2077 - val_loss: 148.4660\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.6827 - val_loss: 143.5382\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.7371 - val_loss: 161.0709\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.1546 - val_loss: 151.8860\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3726 - val_loss: 128.5310\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 6ms/step - loss: 113.9810 - val_loss: 121.1971\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6435 - val_loss: 120.7493\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.6786 - val_loss: 118.2723\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.5510 - val_loss: 110.1767\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2539 - val_loss: 106.6926\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.8967 - val_loss: 105.5030\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.8614 - val_loss: 100.9817\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5000 - val_loss: 111.4281\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0343 - val_loss: 99.5681\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.4342 - val_loss: 95.5778\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.7203 - val_loss: 93.2752\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.9722 - val_loss: 95.4841\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.3138 - val_loss: 108.9753\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.7626 - val_loss: 89.7512\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.4968 - val_loss: 93.6141\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.8681 - val_loss: 91.8481\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.0266 - val_loss: 90.1887\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7672 - val_loss: 86.7048\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.0969 - val_loss: 85.0416\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.6183 - val_loss: 91.6326\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.6492 - val_loss: 83.1142\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6755 - val_loss: 83.1507\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.9960 - val_loss: 83.9426\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.9112 - val_loss: 83.8926\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.0121 - val_loss: 83.5890\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.8757 - val_loss: 82.6689\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.6684 - val_loss: 91.6332\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.8512 - val_loss: 79.2937\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.9045 - val_loss: 86.2287\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.8863 - val_loss: 76.4262\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1053 - val_loss: 76.6634\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4429 - val_loss: 75.1256\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2605 - val_loss: 74.6245\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.3042 - val_loss: 78.6452\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1134 - val_loss: 83.5215\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9973 - val_loss: 79.1962\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.4073 - val_loss: 72.6059\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.7512 - val_loss: 86.2329\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9747 - val_loss: 74.6430\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.0519 - val_loss: 74.1474\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.3290 - val_loss: 70.6493\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.5791 - val_loss: 81.2436\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.4737 - val_loss: 71.0933\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.5438 - val_loss: 71.1499\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5095 - val_loss: 70.1242\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9427 - val_loss: 69.3046\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 67.0413 - val_loss: 69.8061\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.1690 - val_loss: 68.8258\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.2406 - val_loss: 68.4708\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8568 - val_loss: 69.8054\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.3113 - val_loss: 70.0449\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.6888 - val_loss: 69.0145\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.7432 - val_loss: 67.4724\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.6078 - val_loss: 66.4440\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.2188 - val_loss: 66.2267\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.3731 - val_loss: 66.6482\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.3134 - val_loss: 66.4819\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.4781 - val_loss: 65.9886\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.9748 - val_loss: 66.3319\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.8380 - val_loss: 66.1802\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.5733 - val_loss: 65.1906\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.2679 - val_loss: 65.1314\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8893 - val_loss: 67.4432\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.9348 - val_loss: 71.4295\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.2899 - val_loss: 64.1589\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3166 - val_loss: 64.9679\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.4481 - val_loss: 69.9226\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.5292 - val_loss: 67.8184\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.0635 - val_loss: 63.3862\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.4228 - val_loss: 76.0161\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.1505 - val_loss: 66.9411\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.5347 - val_loss: 67.4719\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.1782 - val_loss: 70.7740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 7055.3057 - val_loss: 752.8949\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 391.8285 - val_loss: 355.2287\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 300.8589 - val_loss: 250.5144\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 251.9700 - val_loss: 236.5426\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.1109 - val_loss: 228.0013\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 229.8920 - val_loss: 222.6734\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.4205 - val_loss: 219.9731\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.7027 - val_loss: 214.7992\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.0063 - val_loss: 211.8895\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 211.1751 - val_loss: 209.0129\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.6011 - val_loss: 206.2415\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.2430 - val_loss: 203.7202\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.0851 - val_loss: 201.1582\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.0589 - val_loss: 199.4084\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.1769 - val_loss: 196.8186\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.8276 - val_loss: 195.9006\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 9ms/step - loss: 194.2096 - val_loss: 193.4256\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.6828 - val_loss: 190.8808\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 190.3094 - val_loss: 189.1709\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.4665 - val_loss: 187.0840\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 185.7160 - val_loss: 185.8781\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.9799 - val_loss: 182.7720\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.7813 - val_loss: 182.1958\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.1396 - val_loss: 180.0062\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.9013 - val_loss: 174.2083\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.4713 - val_loss: 170.2628\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.7309 - val_loss: 167.5759\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 169.4693 - val_loss: 166.7018\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.0321 - val_loss: 162.5500\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.7800 - val_loss: 164.2136\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.3734 - val_loss: 159.8900\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.1505 - val_loss: 155.0141\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.1862 - val_loss: 152.5420\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.0526 - val_loss: 150.3561\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.1609 - val_loss: 147.8704\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.2132 - val_loss: 147.3363\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.9246 - val_loss: 145.5961\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.8207 - val_loss: 140.7656\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.3413 - val_loss: 142.3565\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.5386 - val_loss: 136.2702\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 140.4989 - val_loss: 134.1546\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.6768 - val_loss: 133.3470\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 135.9279 - val_loss: 134.4301\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.9790 - val_loss: 130.9583\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.7858 - val_loss: 131.3611\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.8952 - val_loss: 125.6094\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 128.7951 - val_loss: 123.7144\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.8122 - val_loss: 122.0954\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.1209 - val_loss: 120.8230\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.5885 - val_loss: 121.9639\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 121.9822 - val_loss: 118.7692\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 119.9361 - val_loss: 117.7054\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.3827 - val_loss: 115.0449\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 116.5199 - val_loss: 114.9306\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.2304 - val_loss: 112.4110\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.7550 - val_loss: 111.6789\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.4145 - val_loss: 108.9161\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8738 - val_loss: 109.7132\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3574 - val_loss: 109.6261\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 107.2903 - val_loss: 109.1553\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.3421 - val_loss: 104.4258\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 106.6080 - val_loss: 107.0704\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.4875 - val_loss: 101.6515\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.6699 - val_loss: 105.6536\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.3700 - val_loss: 107.5444\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.9575 - val_loss: 103.4154\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.5767 - val_loss: 98.5171\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.4799 - val_loss: 98.2642\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.0250 - val_loss: 95.7277\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.4497 - val_loss: 95.5324\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.1077 - val_loss: 95.3379\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.2644 - val_loss: 96.6999\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.8103 - val_loss: 94.9983\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 92.8353 - val_loss: 104.2498\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.0602 - val_loss: 90.5184\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.4468 - val_loss: 89.3434\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.7917 - val_loss: 90.4408\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.0073 - val_loss: 87.7135\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.6244 - val_loss: 89.7057\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.5494 - val_loss: 85.7267\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.4333 - val_loss: 89.3376\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.4764 - val_loss: 94.2977\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.5150 - val_loss: 89.6096\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.6989 - val_loss: 82.4676\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.9432 - val_loss: 87.1072\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0760 - val_loss: 80.9082\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.4468 - val_loss: 80.0377\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.7600 - val_loss: 81.7324\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 81.0773 - val_loss: 80.4680\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.2143 - val_loss: 77.7865\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.0972 - val_loss: 79.4367\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.1442 - val_loss: 76.6412\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.9345 - val_loss: 75.6050\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.4081 - val_loss: 78.4586\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.9675 - val_loss: 76.2894\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.5315 - val_loss: 75.0237\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.6041 - val_loss: 74.2160\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4529 - val_loss: 73.4866\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7277 - val_loss: 73.0504\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.6034 - val_loss: 92.1366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 9435.9102 - val_loss: 1660.1106\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 783.8769 - val_loss: 423.4767\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 412.4404 - val_loss: 412.7357\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 366.1773 - val_loss: 362.0229\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 319.5157 - val_loss: 303.9063\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.7929 - val_loss: 279.1509\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.0637 - val_loss: 264.5413\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.7896 - val_loss: 263.4545\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.7003 - val_loss: 243.7473\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.3178 - val_loss: 220.0551\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.7350 - val_loss: 209.7523\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.0532 - val_loss: 203.2492\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 183.7852 - val_loss: 191.8702\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.6456 - val_loss: 189.9165\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.5653 - val_loss: 182.2648\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.7735 - val_loss: 173.0195\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.2042 - val_loss: 167.5661\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.0107 - val_loss: 160.7117\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.4494 - val_loss: 158.4453\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.7530 - val_loss: 151.8271\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 139.8270 - val_loss: 149.3988\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.7476 - val_loss: 149.6114\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2019 - val_loss: 140.4414\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.2974 - val_loss: 138.1985\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.9599 - val_loss: 134.8853\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 124.5082 - val_loss: 132.3314\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 123.2881 - val_loss: 130.5169\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.7701 - val_loss: 128.6575\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.4141 - val_loss: 126.2763\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.9445 - val_loss: 129.2298\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.6375 - val_loss: 122.7448\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.8481 - val_loss: 121.9341\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.3548 - val_loss: 120.4830\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3336 - val_loss: 125.3957\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.2639 - val_loss: 122.3693\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 120.4472 - val_loss: 117.0100\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.8876 - val_loss: 116.0670\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.9452 - val_loss: 114.9576\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.3200 - val_loss: 114.5316\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.3884 - val_loss: 121.3239\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8755 - val_loss: 114.2172\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.6541 - val_loss: 116.8569\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 114.4813 - val_loss: 116.8308\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.9432 - val_loss: 116.0238\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.1782 - val_loss: 127.9991\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.7898 - val_loss: 115.2147\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8980 - val_loss: 112.3190\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6840 - val_loss: 111.9036\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 117.5801 - val_loss: 111.2942\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.4303 - val_loss: 110.7209\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.0837 - val_loss: 110.5393\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.4089 - val_loss: 111.1010\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5363 - val_loss: 112.7531\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8776 - val_loss: 159.6412\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 120.5690 - val_loss: 115.3759\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.0041 - val_loss: 110.5308\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.9432 - val_loss: 127.1671\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.2043 - val_loss: 109.7314\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5161 - val_loss: 110.0701\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 110.1556 - val_loss: 112.4792\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.5323 - val_loss: 120.2878\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.1493 - val_loss: 111.2451\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2990 - val_loss: 119.4772\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.7363 - val_loss: 125.6738\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3224 - val_loss: 116.7112\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9467 - val_loss: 114.2343\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.1803 - val_loss: 109.1907\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.8312 - val_loss: 109.4513\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.6818 - val_loss: 109.5520\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.7225 - val_loss: 117.5792\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8011 - val_loss: 109.4912\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4780 - val_loss: 110.0048\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.2678 - val_loss: 114.2407\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2224 - val_loss: 113.3734\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.1760 - val_loss: 136.2477\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4667 - val_loss: 118.2065\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.1444 - val_loss: 132.3346\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.5196 - val_loss: 137.5657\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 10ms/step - loss: 115.0476 - val_loss: 110.0362\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.1332 - val_loss: 109.0477\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.2914 - val_loss: 108.8336\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.7698 - val_loss: 109.5302\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.9255 - val_loss: 133.5637\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.4242 - val_loss: 108.5887\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.2687 - val_loss: 130.9333\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.5028 - val_loss: 109.1533\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6451 - val_loss: 112.2182\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8609 - val_loss: 118.8866\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.5348 - val_loss: 109.2002\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.8939 - val_loss: 115.8070\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.3228 - val_loss: 116.5046\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8638 - val_loss: 108.2554\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1937 - val_loss: 110.3297\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8182 - val_loss: 114.3600\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3686 - val_loss: 113.7775\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.3842 - val_loss: 108.1100\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.8037 - val_loss: 110.5361\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.3319 - val_loss: 111.0554\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 114.7262 - val_loss: 116.1815\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.1675 - val_loss: 119.6080\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 54437.2148 - val_loss: 22913.2012\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 11606.1465 - val_loss: 3496.3318\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1566.3396 - val_loss: 556.3489\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 447.4616 - val_loss: 463.6493\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 393.3481 - val_loss: 396.0005\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 339.6949 - val_loss: 330.4714\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 287.3070 - val_loss: 275.1299\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.1048 - val_loss: 222.1036\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.6364 - val_loss: 191.4771\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.8471 - val_loss: 176.2831\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.0657 - val_loss: 173.5449\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.2841 - val_loss: 162.4234\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.6908 - val_loss: 157.3897\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.6406 - val_loss: 152.6256\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.7741 - val_loss: 148.9989\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.4876 - val_loss: 144.7795\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.0796 - val_loss: 139.6863\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.2651 - val_loss: 141.4372\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.1410 - val_loss: 135.3224\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.8364 - val_loss: 130.0022\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.6085 - val_loss: 127.1318\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.6108 - val_loss: 127.6363\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.8134 - val_loss: 124.9138\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.4279 - val_loss: 121.5005\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.3585 - val_loss: 118.8423\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.8747 - val_loss: 116.5120\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.4675 - val_loss: 116.9007\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.1221 - val_loss: 118.7278\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 125.6072 - val_loss: 113.2818\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.8684 - val_loss: 111.7321\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.6167 - val_loss: 109.9748\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.2388 - val_loss: 109.7987\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.3473 - val_loss: 108.8871\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.0337 - val_loss: 106.5402\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 6ms/step - loss: 118.0041 - val_loss: 106.9286\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 6ms/step - loss: 115.5183 - val_loss: 106.3111\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 6ms/step - loss: 114.5143 - val_loss: 105.8651\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 8ms/step - loss: 113.0950 - val_loss: 103.2455\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 6ms/step - loss: 112.9330 - val_loss: 102.7715\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5252 - val_loss: 107.0239\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.4363 - val_loss: 102.4449\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8460 - val_loss: 100.2540\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8242 - val_loss: 100.2012\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.2483 - val_loss: 105.3273\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.2964 - val_loss: 98.3423\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.6010 - val_loss: 97.3940\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.2466 - val_loss: 97.1548\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.0619 - val_loss: 97.4850\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1686 - val_loss: 97.6076\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.7769 - val_loss: 95.8190\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.3863 - val_loss: 102.6597\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0176 - val_loss: 103.6906\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.1180 - val_loss: 94.2862\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.0063 - val_loss: 92.2297\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.5380 - val_loss: 97.4605\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.4194 - val_loss: 92.7420\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.8539 - val_loss: 92.4860\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.2602 - val_loss: 90.0123\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.6409 - val_loss: 90.8333\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 96.6062 - val_loss: 90.7195\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5507 - val_loss: 89.7223\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.3836 - val_loss: 92.5620\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5880 - val_loss: 91.9698\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.2647 - val_loss: 89.9624\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 11ms/step - loss: 95.6131 - val_loss: 87.4306\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.6640 - val_loss: 88.1909\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.0628 - val_loss: 91.3152\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.4856 - val_loss: 91.3035\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.4482 - val_loss: 85.2358\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.7402 - val_loss: 85.3259\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.1124 - val_loss: 90.6154\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.1450 - val_loss: 88.7124\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.9836 - val_loss: 93.0332\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.8574 - val_loss: 84.9501\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.4421 - val_loss: 83.6527\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.8899 - val_loss: 82.6003\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 89.7603 - val_loss: 82.3801\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 89.1287 - val_loss: 82.4069\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.4512 - val_loss: 84.6900\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.8032 - val_loss: 81.4255\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8951 - val_loss: 82.0280\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.3207 - val_loss: 83.8957\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.4235 - val_loss: 79.9004\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.7549 - val_loss: 82.6019\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8894 - val_loss: 79.4646\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.3738 - val_loss: 79.1574\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.1298 - val_loss: 79.0841\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.2883 - val_loss: 77.6240\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.2429 - val_loss: 80.5344\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0393 - val_loss: 76.4998\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.4925 - val_loss: 81.2904\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.5592 - val_loss: 79.5729\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.3602 - val_loss: 77.0161\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.5531 - val_loss: 75.0015\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7065 - val_loss: 79.7228\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.5319 - val_loss: 73.9915\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7690 - val_loss: 73.7257\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.5670 - val_loss: 77.6719\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.9444 - val_loss: 72.7540\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.4519 - val_loss: 72.3064\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 81ms/step - loss: 4642.9199 - val_loss: 1015.6384\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 565.6594 - val_loss: 476.9677\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 424.8783 - val_loss: 402.1811\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 371.8610 - val_loss: 369.9065\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 340.1238 - val_loss: 340.4242\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 314.9117 - val_loss: 316.5430\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 293.2815 - val_loss: 296.1548\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 274.7848 - val_loss: 276.3860\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 255.6850 - val_loss: 259.1198\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 238.6294 - val_loss: 241.4214\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.2378 - val_loss: 226.6888\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.9515 - val_loss: 214.5310\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.9602 - val_loss: 201.3790\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.5902 - val_loss: 191.0993\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.7125 - val_loss: 183.2404\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.3523 - val_loss: 175.1228\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.3457 - val_loss: 169.5715\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.5529 - val_loss: 165.7742\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.6782 - val_loss: 161.4804\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.0599 - val_loss: 156.7773\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 137.3673 - val_loss: 153.7827\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.5607 - val_loss: 150.1119\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.2713 - val_loss: 148.0624\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.6287 - val_loss: 145.5689\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.5760 - val_loss: 145.4846\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.0535 - val_loss: 143.1677\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 118.1983 - val_loss: 140.1614\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.4513 - val_loss: 141.5469\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6318 - val_loss: 145.9151\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.4683 - val_loss: 136.0135\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4123 - val_loss: 133.3559\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.4921 - val_loss: 132.9771\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 108.6897 - val_loss: 133.8814\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.4977 - val_loss: 129.7959\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.9006 - val_loss: 132.8671\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.2122 - val_loss: 126.0687\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.3237 - val_loss: 124.8248\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 9ms/step - loss: 101.5762 - val_loss: 123.5249\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.9049 - val_loss: 123.1729\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.5948 - val_loss: 121.7849\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.1920 - val_loss: 120.5294\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.7373 - val_loss: 120.2316\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.6364 - val_loss: 119.9383\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.8690 - val_loss: 118.0955\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.3245 - val_loss: 116.5804\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.4028 - val_loss: 115.2825\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.9112 - val_loss: 115.9839\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.4590 - val_loss: 113.8574\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.2372 - val_loss: 115.4443\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.8497 - val_loss: 110.5948\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.0236 - val_loss: 109.8780\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.5641 - val_loss: 109.2728\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 88.1259 - val_loss: 105.9624\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.9315 - val_loss: 104.4192\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.4568 - val_loss: 108.1637\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.1010 - val_loss: 106.3738\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.2167 - val_loss: 105.1781\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.6025 - val_loss: 99.0689\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.5126 - val_loss: 98.0661\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.1554 - val_loss: 98.4494\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.1976 - val_loss: 99.2546\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.3331 - val_loss: 95.8172\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.5687 - val_loss: 95.5634\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.5597 - val_loss: 94.6494\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.0225 - val_loss: 96.7423\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.9928 - val_loss: 93.6056\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.9754 - val_loss: 93.0324\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.8422 - val_loss: 92.2052\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.3791 - val_loss: 92.5071\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.1080 - val_loss: 90.9435\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4107 - val_loss: 90.7929\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.2258 - val_loss: 91.7237\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0596 - val_loss: 89.3736\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.6486 - val_loss: 90.5817\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.7053 - val_loss: 89.4145\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.0793 - val_loss: 90.4798\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4305 - val_loss: 87.8343\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.9455 - val_loss: 87.0978\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.7203 - val_loss: 86.1540\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 17ms/step - loss: 75.6195 - val_loss: 86.8331\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.1927 - val_loss: 85.5061\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.0685 - val_loss: 87.4298\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.2823 - val_loss: 84.2107\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.1064 - val_loss: 84.3356\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1869 - val_loss: 83.3574\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.9410 - val_loss: 83.8702\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.1050 - val_loss: 82.5679\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.8223 - val_loss: 82.8001\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.1896 - val_loss: 83.5766\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.7216 - val_loss: 80.9436\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.0599 - val_loss: 80.4869\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.6233 - val_loss: 80.4284\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.3149 - val_loss: 80.6082\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.4423 - val_loss: 79.4168\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.5817 - val_loss: 79.5094\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0872 - val_loss: 78.3477\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0853 - val_loss: 79.4682\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0544 - val_loss: 77.5743\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1399 - val_loss: 79.2295\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5411 - val_loss: 79.1289\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 28909.5137 - val_loss: 7023.2793\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 2092.1462 - val_loss: 374.6544\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.5800 - val_loss: 331.8564\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 298.1391 - val_loss: 304.0848\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 264.8614 - val_loss: 300.4503\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.9654 - val_loss: 283.9405\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.6474 - val_loss: 271.5847\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.2090 - val_loss: 260.8654\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.1723 - val_loss: 253.3355\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 217.7970 - val_loss: 245.4505\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.7858 - val_loss: 234.5075\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.7063 - val_loss: 231.7801\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.1564 - val_loss: 226.4056\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.5712 - val_loss: 220.7363\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.3807 - val_loss: 217.4238\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.5351 - val_loss: 214.7594\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.3540 - val_loss: 210.6157\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.0482 - val_loss: 207.0781\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.7035 - val_loss: 205.3310\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.6182 - val_loss: 202.1061\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.5500 - val_loss: 197.6350\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.7603 - val_loss: 197.5759\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.4773 - val_loss: 193.5830\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.9397 - val_loss: 194.8157\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.9679 - val_loss: 186.9437\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.0528 - val_loss: 184.8653\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.3948 - val_loss: 187.1669\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.5055 - val_loss: 179.9806\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.5149 - val_loss: 182.4028\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.4400 - val_loss: 175.7307\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.8821 - val_loss: 173.7164\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 144.1378 - val_loss: 169.8057\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 141.5567 - val_loss: 168.3352\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 139.3683 - val_loss: 163.9094\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.8465 - val_loss: 160.2517\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.5804 - val_loss: 158.4374\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.5798 - val_loss: 158.5576\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 130.6701 - val_loss: 156.2173\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.1586 - val_loss: 150.2775\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.9912 - val_loss: 151.0934\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.1471 - val_loss: 144.1231\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.3065 - val_loss: 143.0313\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.5505 - val_loss: 141.2433\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.8603 - val_loss: 138.0047\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.0633 - val_loss: 135.1964\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.5049 - val_loss: 134.3543\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.9035 - val_loss: 132.2783\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.9939 - val_loss: 131.2124\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.4762 - val_loss: 134.5218\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.4760 - val_loss: 126.4341\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7965 - val_loss: 125.7156\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.8957 - val_loss: 122.7444\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2721 - val_loss: 123.9575\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.6700 - val_loss: 118.9841\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.9370 - val_loss: 118.8325\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9524 - val_loss: 120.6017\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.6768 - val_loss: 117.4623\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.6373 - val_loss: 113.6828\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5095 - val_loss: 117.2603\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.3514 - val_loss: 114.2588\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.4940 - val_loss: 118.8464\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.7876 - val_loss: 108.9069\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.7780 - val_loss: 110.4128\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.4845 - val_loss: 113.4103\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.9750 - val_loss: 106.2921\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.1269 - val_loss: 104.3561\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.3325 - val_loss: 103.3182\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 9ms/step - loss: 88.1641 - val_loss: 104.0285\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.9886 - val_loss: 101.6943\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.2682 - val_loss: 99.7422\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.8387 - val_loss: 100.1176\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.3076 - val_loss: 98.4893\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 7ms/step - loss: 84.5751 - val_loss: 97.6719\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 6ms/step - loss: 85.2060 - val_loss: 96.3049\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.4778 - val_loss: 96.6435\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.7132 - val_loss: 98.5871\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.0207 - val_loss: 95.7073\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.4281 - val_loss: 93.6802\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.1736 - val_loss: 91.1574\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.3206 - val_loss: 92.0618\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.7548 - val_loss: 89.5577\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4091 - val_loss: 87.8564\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4184 - val_loss: 87.0571\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.0202 - val_loss: 90.7640\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.6643 - val_loss: 92.8532\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.1739 - val_loss: 86.6377\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.2732 - val_loss: 83.5902\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.7598 - val_loss: 85.7567\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.7307 - val_loss: 85.6622\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.1088 - val_loss: 101.0391\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4050 - val_loss: 80.9986\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0644 - val_loss: 80.7454\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2143 - val_loss: 83.0539\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.1853 - val_loss: 84.2932\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0446 - val_loss: 88.6619\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.8346 - val_loss: 85.2166\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9753 - val_loss: 80.0535\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.2837 - val_loss: 78.1882\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1335 - val_loss: 79.3186\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.7325 - val_loss: 77.0317\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 69ms/step - loss: 705.5408 - val_loss: 360.9444\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 384.0354 - val_loss: 360.2207\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 365.9885 - val_loss: 339.5062\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 355.3897 - val_loss: 329.3669\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.4626 - val_loss: 320.1091\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 336.1587 - val_loss: 311.2033\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 327.6492 - val_loss: 302.2573\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 320.2083 - val_loss: 295.7069\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 313.1498 - val_loss: 290.0033\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 309.3461 - val_loss: 285.6822\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.3648 - val_loss: 279.3216\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 296.3382 - val_loss: 273.1730\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 290.1916 - val_loss: 273.9779\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.5886 - val_loss: 265.9254\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 280.6766 - val_loss: 261.1546\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 275.5459 - val_loss: 256.7435\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.7858 - val_loss: 255.1929\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.4855 - val_loss: 251.4626\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.3313 - val_loss: 240.5980\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 257.6956 - val_loss: 234.9200\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.1732 - val_loss: 230.2155\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.1858 - val_loss: 222.0426\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.6805 - val_loss: 217.2687\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.4113 - val_loss: 211.1527\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.1861 - val_loss: 205.6341\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.4365 - val_loss: 202.7912\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 9ms/step - loss: 208.7252 - val_loss: 197.0408\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.6587 - val_loss: 192.7457\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.5156 - val_loss: 186.5534\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.8341 - val_loss: 183.8021\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.6174 - val_loss: 174.2618\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.4432 - val_loss: 169.8727\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.6039 - val_loss: 169.2378\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.0295 - val_loss: 163.1880\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.6832 - val_loss: 160.8349\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.3521 - val_loss: 156.4014\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.1181 - val_loss: 153.7389\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.3825 - val_loss: 150.4783\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.5032 - val_loss: 148.2354\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.8191 - val_loss: 148.2543\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.9242 - val_loss: 142.7175\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.8517 - val_loss: 140.5983\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.7554 - val_loss: 137.0421\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.0045 - val_loss: 135.2856\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.6734 - val_loss: 134.7893\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.6175 - val_loss: 132.6197\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.2614 - val_loss: 129.4608\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.8015 - val_loss: 139.2566\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 131.8219 - val_loss: 127.8632\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.5765 - val_loss: 133.4415\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 129.0770 - val_loss: 122.7864\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.3777 - val_loss: 124.2871\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3633 - val_loss: 133.9541\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.6477 - val_loss: 118.3366\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.3856 - val_loss: 123.8172\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 9ms/step - loss: 124.1132 - val_loss: 118.1843\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1675 - val_loss: 121.7497\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.8577 - val_loss: 117.2685\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.8297 - val_loss: 113.7260\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.0834 - val_loss: 118.1356\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5424 - val_loss: 110.7998\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5179 - val_loss: 111.9225\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 112.6341 - val_loss: 111.5759\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 9ms/step - loss: 112.0032 - val_loss: 110.1907\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.0348 - val_loss: 106.9844\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.6197 - val_loss: 106.1328\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0809 - val_loss: 105.0808\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1316 - val_loss: 105.3797\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.6977 - val_loss: 105.3644\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.4815 - val_loss: 103.9225\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.2586 - val_loss: 102.8842\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.9806 - val_loss: 103.5196\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2090 - val_loss: 102.8240\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.2184 - val_loss: 100.1231\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.3459 - val_loss: 99.0267\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.5293 - val_loss: 98.3401\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.7900 - val_loss: 97.7883\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.6593 - val_loss: 98.4994\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.1108 - val_loss: 97.0679\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.6897 - val_loss: 95.9833\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.2115 - val_loss: 95.5078\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.2533 - val_loss: 96.6889\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 9ms/step - loss: 95.1721 - val_loss: 96.4469\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.9053 - val_loss: 93.3363\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.2969 - val_loss: 94.6316\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 92.8360 - val_loss: 92.3959\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.7821 - val_loss: 92.3780\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.9241 - val_loss: 91.0975\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.6134 - val_loss: 91.5815\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.2533 - val_loss: 90.1784\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.9809 - val_loss: 90.0462\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.5860 - val_loss: 91.7063\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.9576 - val_loss: 87.7768\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.2344 - val_loss: 87.4643\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.1676 - val_loss: 88.3783\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.6297 - val_loss: 86.6707\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.4371 - val_loss: 85.5105\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.6174 - val_loss: 85.2931\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.9335 - val_loss: 85.7657\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 9ms/step - loss: 87.1588 - val_loss: 84.2973\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 2281.8296 - val_loss: 993.2725\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 669.0258 - val_loss: 424.4809\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 410.9947 - val_loss: 324.4023\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 358.3605 - val_loss: 296.5417\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 338.8512 - val_loss: 286.2962\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 328.4798 - val_loss: 280.3669\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 321.6312 - val_loss: 276.2933\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 314.9310 - val_loss: 271.0607\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 311.0665 - val_loss: 267.1661\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 305.8552 - val_loss: 263.2898\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 299.8868 - val_loss: 258.7968\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 295.7349 - val_loss: 255.2167\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 290.4525 - val_loss: 251.7818\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 285.6505 - val_loss: 246.9073\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 279.6836 - val_loss: 242.3796\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.9464 - val_loss: 237.2618\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 268.4706 - val_loss: 232.2509\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.9392 - val_loss: 228.8495\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.4244 - val_loss: 223.4054\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.4734 - val_loss: 216.7978\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.0937 - val_loss: 212.1681\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 235.6560 - val_loss: 206.6522\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.9826 - val_loss: 208.7166\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.0788 - val_loss: 195.6285\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.8737 - val_loss: 191.8954\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.2475 - val_loss: 187.1146\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.6524 - val_loss: 182.3110\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.7223 - val_loss: 177.6212\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.5865 - val_loss: 177.9017\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.7736 - val_loss: 173.4699\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.5963 - val_loss: 166.9911\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.6502 - val_loss: 163.3907\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.0730 - val_loss: 159.9210\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.7980 - val_loss: 158.4628\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.4821 - val_loss: 155.9227\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.8387 - val_loss: 154.9741\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.6140 - val_loss: 154.4247\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.7438 - val_loss: 142.7095\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.8796 - val_loss: 142.1395\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.3326 - val_loss: 138.1687\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.4189 - val_loss: 143.1432\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.5145 - val_loss: 132.6648\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.4512 - val_loss: 130.9466\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.5180 - val_loss: 128.9647\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.2070 - val_loss: 128.0045\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.4635 - val_loss: 126.0564\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.1725 - val_loss: 122.8274\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.8924 - val_loss: 122.0157\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.0624 - val_loss: 121.2422\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.4213 - val_loss: 127.4938\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.8892 - val_loss: 117.8613\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.0266 - val_loss: 115.1031\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.2860 - val_loss: 113.6947\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 123.4325 - val_loss: 112.8077\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.3872 - val_loss: 113.1143\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3370 - val_loss: 110.8666\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.2067 - val_loss: 108.3900\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.8824 - val_loss: 108.9226\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.5216 - val_loss: 106.3458\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.3545 - val_loss: 106.1679\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.4847 - val_loss: 104.5765\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.2307 - val_loss: 102.6504\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.9190 - val_loss: 104.5538\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.5950 - val_loss: 100.7013\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4906 - val_loss: 103.4461\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.8459 - val_loss: 100.2891\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.3436 - val_loss: 101.4262\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.9804 - val_loss: 101.4883\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.4016 - val_loss: 101.1064\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 9ms/step - loss: 108.0891 - val_loss: 97.2367\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.1988 - val_loss: 95.9647\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.0273 - val_loss: 98.4596\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.4190 - val_loss: 93.1594\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.8854 - val_loss: 93.7102\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.1773 - val_loss: 93.8810\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9498 - val_loss: 91.4823\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.9531 - val_loss: 92.7034\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 97.3871 - val_loss: 90.5158\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5225 - val_loss: 94.3381\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.6279 - val_loss: 89.4060\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 95.2798 - val_loss: 88.7688\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5096 - val_loss: 99.1374\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.6756 - val_loss: 92.5389\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.9459 - val_loss: 89.4627\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.4223 - val_loss: 87.2527\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.4268 - val_loss: 89.3138\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.0866 - val_loss: 85.5654\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.8878 - val_loss: 88.3127\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.7342 - val_loss: 84.6527\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.7352 - val_loss: 87.8773\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.6406 - val_loss: 83.8873\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.5213 - val_loss: 83.5826\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8407 - val_loss: 84.1923\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.2814 - val_loss: 83.6869\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.7487 - val_loss: 84.0010\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.7785 - val_loss: 83.5288\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.5841 - val_loss: 82.0941\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.8827 - val_loss: 88.2473\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.9635 - val_loss: 82.4877\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0261 - val_loss: 83.2282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 10203.5176 - val_loss: 3921.1577\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 3245.5535 - val_loss: 2375.0288\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1629.9146 - val_loss: 1284.0165\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 795.6323 - val_loss: 707.1897\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 500.8466 - val_loss: 458.1861\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 355.0319 - val_loss: 330.6148\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 276.3773 - val_loss: 281.6401\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 235.3645 - val_loss: 235.0080\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.1362 - val_loss: 213.0792\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.4609 - val_loss: 179.8680\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.1596 - val_loss: 173.1164\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.7702 - val_loss: 167.3470\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.9189 - val_loss: 160.1829\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.5849 - val_loss: 156.0649\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.9949 - val_loss: 158.8723\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 133.9225 - val_loss: 148.3755\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.2529 - val_loss: 151.2151\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.8877 - val_loss: 154.2895\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.4236 - val_loss: 141.2375\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.8777 - val_loss: 159.1562\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.0841 - val_loss: 136.6834\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.6332 - val_loss: 134.1029\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.7411 - val_loss: 131.6814\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.4675 - val_loss: 132.4987\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.6844 - val_loss: 128.5777\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.5378 - val_loss: 127.6955\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.7864 - val_loss: 124.7747\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6340 - val_loss: 123.2732\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.6874 - val_loss: 135.2708\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.1459 - val_loss: 122.1648\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.0666 - val_loss: 120.4960\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9976 - val_loss: 124.5840\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.2099 - val_loss: 119.5700\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.5498 - val_loss: 115.6404\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9231 - val_loss: 132.2434\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.5153 - val_loss: 116.1751\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 9ms/step - loss: 97.3694 - val_loss: 117.6028\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 95.4576 - val_loss: 114.4522\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.7365 - val_loss: 113.6331\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.8700 - val_loss: 113.2543\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.7574 - val_loss: 112.4041\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.4274 - val_loss: 114.2229\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.6728 - val_loss: 108.4583\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.4878 - val_loss: 109.9964\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.3088 - val_loss: 108.7799\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.0270 - val_loss: 107.2506\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.0749 - val_loss: 109.8654\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.1414 - val_loss: 117.8704\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.0865 - val_loss: 105.2859\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.9060 - val_loss: 106.7877\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.3824 - val_loss: 108.5449\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.1737 - val_loss: 107.7115\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.7484 - val_loss: 105.4772\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.4699 - val_loss: 121.5177\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.9490 - val_loss: 102.0093\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.5426 - val_loss: 102.3876\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.6835 - val_loss: 112.5802\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8095 - val_loss: 100.6554\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.8949 - val_loss: 100.6210\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.7700 - val_loss: 100.7136\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.2899 - val_loss: 109.0983\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.4691 - val_loss: 103.9080\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.4700 - val_loss: 100.7367\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.8068 - val_loss: 116.2527\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.9341 - val_loss: 102.5655\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.0079 - val_loss: 97.9135\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.3121 - val_loss: 100.5333\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.0974 - val_loss: 96.5801\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.9843 - val_loss: 96.6901\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.7636 - val_loss: 103.3160\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.5068 - val_loss: 96.5847\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 84.1958 - val_loss: 96.1797\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.9255 - val_loss: 99.5208\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.9567 - val_loss: 97.3992\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.3310 - val_loss: 95.0120\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.9986 - val_loss: 96.7471\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.8526 - val_loss: 94.7742\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.7427 - val_loss: 100.4299\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.4575 - val_loss: 97.1244\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.6913 - val_loss: 97.1710\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.0899 - val_loss: 93.6290\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.6447 - val_loss: 93.2393\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.2112 - val_loss: 95.9097\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.7641 - val_loss: 94.4775\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.8229 - val_loss: 92.8513\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.3617 - val_loss: 93.9088\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.7209 - val_loss: 93.7126\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.1416 - val_loss: 97.2741\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.3829 - val_loss: 94.1280\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.0790 - val_loss: 92.5754\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.1969 - val_loss: 92.2608\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.8903 - val_loss: 92.0538\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.6222 - val_loss: 103.9589\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.1465 - val_loss: 93.3031\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.5842 - val_loss: 93.1778\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.8112 - val_loss: 92.6971\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.9613 - val_loss: 92.6418\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.3162 - val_loss: 92.5085\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.1655 - val_loss: 89.8863\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.8369 - val_loss: 91.2321\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 15711.3721 - val_loss: 7299.5532\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 4583.7998 - val_loss: 2163.6091\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 1305.4370 - val_loss: 760.2144\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 689.9606 - val_loss: 604.1694\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 549.0319 - val_loss: 506.2576\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 466.3724 - val_loss: 435.9418\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 411.8915 - val_loss: 401.4949\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 376.5166 - val_loss: 366.9801\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 349.3343 - val_loss: 346.2411\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 328.7335 - val_loss: 322.7259\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 310.0118 - val_loss: 304.1261\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 292.9062 - val_loss: 287.0385\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 276.0677 - val_loss: 274.6221\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 258.9245 - val_loss: 255.2998\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 244.2200 - val_loss: 239.4068\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.9069 - val_loss: 224.7072\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 214.6600 - val_loss: 212.0714\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.5676 - val_loss: 202.3250\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 188.1442 - val_loss: 185.9845\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.0981 - val_loss: 178.0549\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.4668 - val_loss: 165.3658\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.0758 - val_loss: 160.6126\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 149.5065 - val_loss: 149.5717\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.9366 - val_loss: 143.3035\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 136.8505 - val_loss: 138.7827\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.4238 - val_loss: 141.5471\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 131.8367 - val_loss: 131.6691\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 125.9732 - val_loss: 128.1946\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 124.5180 - val_loss: 124.4182\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 119.8334 - val_loss: 122.7033\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 118.0615 - val_loss: 119.4237\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.7864 - val_loss: 117.2918\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 114.4505 - val_loss: 115.7684\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 111.9840 - val_loss: 113.5676\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 109.3521 - val_loss: 111.7675\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 108.3313 - val_loss: 110.7891\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 106.2441 - val_loss: 109.1027\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 105.6244 - val_loss: 108.3694\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 104.0051 - val_loss: 105.6911\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.8355 - val_loss: 104.0557\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.8398 - val_loss: 105.1283\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.5286 - val_loss: 101.2483\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.1338 - val_loss: 100.4825\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 96.0977 - val_loss: 101.5158\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.9642 - val_loss: 98.0200\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.7883 - val_loss: 96.9312\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.6000 - val_loss: 95.1560\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.7790 - val_loss: 94.1365\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 89.7857 - val_loss: 94.5755\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.7556 - val_loss: 92.2713\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.8949 - val_loss: 91.4958\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.0458 - val_loss: 91.7531\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.9230 - val_loss: 91.0286\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.1811 - val_loss: 90.6235\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.7090 - val_loss: 87.3819\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.4452 - val_loss: 87.8412\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.9482 - val_loss: 85.5229\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.7223 - val_loss: 84.4425\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.8936 - val_loss: 87.2136\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.2014 - val_loss: 82.5531\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.6471 - val_loss: 82.4247\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.7829 - val_loss: 81.3024\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.5406 - val_loss: 80.1531\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.0153 - val_loss: 79.6600\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.3449 - val_loss: 82.1086\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.8535 - val_loss: 78.2694\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.0621 - val_loss: 76.8182\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 72.5994 - val_loss: 83.6586\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.0762 - val_loss: 78.4994\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1986 - val_loss: 75.1491\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.7605 - val_loss: 76.9049\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.7322 - val_loss: 74.3241\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2422 - val_loss: 74.3880\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 9ms/step - loss: 68.9920 - val_loss: 72.4148\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8161 - val_loss: 76.2154\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.6663 - val_loss: 71.1079\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.0986 - val_loss: 70.2458\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1541 - val_loss: 69.5982\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4852 - val_loss: 71.4324\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4717 - val_loss: 69.1384\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.0337 - val_loss: 67.7227\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1605 - val_loss: 67.4335\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.7541 - val_loss: 67.3729\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8725 - val_loss: 66.7264\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.5022 - val_loss: 67.4362\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.2142 - val_loss: 65.3037\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.3263 - val_loss: 66.2571\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.1111 - val_loss: 64.9971\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 58.9247 - val_loss: 64.3102\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.9760 - val_loss: 64.3455\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.5863 - val_loss: 63.3003\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.9391 - val_loss: 62.8673\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.6010 - val_loss: 62.2848\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.5506 - val_loss: 62.7006\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.4103 - val_loss: 61.0732\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.3034 - val_loss: 61.2120\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.4717 - val_loss: 60.4453\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.7155 - val_loss: 61.9508\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.0097 - val_loss: 59.5268\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.9675 - val_loss: 59.5332\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 34236.5586 - val_loss: 4174.6362\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1292.3441 - val_loss: 985.5026\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 759.8221 - val_loss: 534.0325\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 510.4334 - val_loss: 492.6239\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 466.0376 - val_loss: 443.9783\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 436.9786 - val_loss: 421.1937\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 413.4852 - val_loss: 401.2079\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 393.4327 - val_loss: 385.5639\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 374.5597 - val_loss: 366.9375\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 357.6066 - val_loss: 351.2292\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 344.2284 - val_loss: 336.7876\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 331.7950 - val_loss: 325.3747\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 316.2461 - val_loss: 311.4728\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 304.0655 - val_loss: 302.3861\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 294.0980 - val_loss: 291.5804\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 285.4957 - val_loss: 287.8158\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 275.8190 - val_loss: 269.4780\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 265.5098 - val_loss: 260.1715\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.1597 - val_loss: 249.7112\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 246.8958 - val_loss: 240.9790\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.3256 - val_loss: 231.2155\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.8502 - val_loss: 220.6615\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.5804 - val_loss: 206.7237\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.4734 - val_loss: 197.7092\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.1734 - val_loss: 193.9147\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.6123 - val_loss: 189.7980\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.6307 - val_loss: 188.3618\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.6967 - val_loss: 184.2320\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.8125 - val_loss: 184.5243\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.2672 - val_loss: 182.3387\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.1352 - val_loss: 175.8012\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.8738 - val_loss: 173.1999\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.8677 - val_loss: 170.8073\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.5275 - val_loss: 168.6855\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 173.5872 - val_loss: 170.2000\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.8811 - val_loss: 164.9178\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.7854 - val_loss: 164.6652\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.5938 - val_loss: 161.3138\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.4647 - val_loss: 160.4713\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.6440 - val_loss: 159.8217\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.4243 - val_loss: 158.5443\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.8021 - val_loss: 164.2257\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.9363 - val_loss: 153.2717\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.6572 - val_loss: 153.1705\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.3417 - val_loss: 151.9479\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.0832 - val_loss: 151.4455\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.5047 - val_loss: 150.1267\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.6089 - val_loss: 147.6490\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.4035 - val_loss: 147.7785\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.6945 - val_loss: 154.7517\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.6552 - val_loss: 143.3700\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.0763 - val_loss: 142.2395\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.5159 - val_loss: 149.3998\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.7966 - val_loss: 140.8844\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.7644 - val_loss: 138.2161\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.9355 - val_loss: 137.5867\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.9881 - val_loss: 139.0011\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.1767 - val_loss: 135.7932\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 17ms/step - loss: 144.5235 - val_loss: 135.7587\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.6491 - val_loss: 134.5773\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.4521 - val_loss: 132.9952\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.4765 - val_loss: 135.2154\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.3437 - val_loss: 131.3641\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.8994 - val_loss: 130.5961\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.4186 - val_loss: 136.7242\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2950 - val_loss: 131.3669\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.3820 - val_loss: 128.7955\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.7547 - val_loss: 129.0126\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.5365 - val_loss: 128.3586\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.5823 - val_loss: 129.1119\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.0408 - val_loss: 125.7098\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 133.5157 - val_loss: 124.6060\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.7625 - val_loss: 125.1334\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.0318 - val_loss: 123.6204\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.5125 - val_loss: 123.6200\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.1169 - val_loss: 122.4335\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.0479 - val_loss: 120.9901\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.3282 - val_loss: 121.4878\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.9063 - val_loss: 123.1179\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 7ms/step - loss: 128.6406 - val_loss: 119.2086\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.8046 - val_loss: 118.8886\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1766 - val_loss: 120.1888\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.7853 - val_loss: 117.1638\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.9838 - val_loss: 117.4807\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.7740 - val_loss: 115.4863\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.5587 - val_loss: 116.8463\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.8506 - val_loss: 118.9042\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.6591 - val_loss: 114.3444\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.0298 - val_loss: 112.0883\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 9ms/step - loss: 121.7637 - val_loss: 110.8578\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.5837 - val_loss: 109.9267\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 119.3003 - val_loss: 112.3661\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1824 - val_loss: 108.2843\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.1735 - val_loss: 107.0951\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.9707 - val_loss: 105.3518\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.9516 - val_loss: 106.6838\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8978 - val_loss: 128.5873\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.7437 - val_loss: 111.0476\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.0451 - val_loss: 99.9971\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.7774 - val_loss: 98.8868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 82ms/step - loss: 5923.9946 - val_loss: 2808.4116\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1944.0521 - val_loss: 1192.4379\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 937.9973 - val_loss: 599.8514\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 485.5296 - val_loss: 310.5818\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.1279 - val_loss: 227.7926\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.9879 - val_loss: 218.5058\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.5573 - val_loss: 212.8085\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.9860 - val_loss: 208.4331\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 235.3717 - val_loss: 205.2469\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.3228 - val_loss: 202.6831\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.5149 - val_loss: 200.2085\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.4749 - val_loss: 198.1443\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.3361 - val_loss: 195.7215\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.0289 - val_loss: 193.9247\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.9904 - val_loss: 192.0901\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.3153 - val_loss: 190.4899\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.5026 - val_loss: 188.8741\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.7082 - val_loss: 187.4190\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.9474 - val_loss: 185.7693\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.4701 - val_loss: 184.4439\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 11ms/step - loss: 208.6398 - val_loss: 182.6348\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.9781 - val_loss: 181.1056\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.8711 - val_loss: 179.6286\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.8699 - val_loss: 178.0883\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.1314 - val_loss: 176.4058\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.0891 - val_loss: 174.9965\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.4375 - val_loss: 173.4894\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.2078 - val_loss: 172.1498\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.4990 - val_loss: 170.3243\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 192.2072 - val_loss: 169.0714\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.0888 - val_loss: 167.3875\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.4456 - val_loss: 166.3420\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.5309 - val_loss: 164.6185\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.0890 - val_loss: 163.1679\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.7955 - val_loss: 161.3237\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.2069 - val_loss: 159.8351\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.0772 - val_loss: 158.3349\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.2186 - val_loss: 156.7572\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0051 - val_loss: 155.5420\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.4048 - val_loss: 153.5986\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.4001 - val_loss: 153.2378\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.7398 - val_loss: 150.5930\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.1038 - val_loss: 149.4029\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.1553 - val_loss: 147.1715\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.2141 - val_loss: 145.5392\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.7768 - val_loss: 144.6743\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.4375 - val_loss: 142.4270\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.9127 - val_loss: 141.9602\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.0067 - val_loss: 139.6210\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.2243 - val_loss: 137.8751\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.8253 - val_loss: 136.3201\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.7993 - val_loss: 135.4564\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.4687 - val_loss: 133.6603\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.2594 - val_loss: 133.0018\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.3773 - val_loss: 131.8475\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.8976 - val_loss: 129.7854\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 11ms/step - loss: 142.7776 - val_loss: 129.8116\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.9489 - val_loss: 127.9324\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 7ms/step - loss: 140.6705 - val_loss: 126.4932\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.5616 - val_loss: 125.4947\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.6435 - val_loss: 125.4999\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.5975 - val_loss: 123.5810\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.5026 - val_loss: 122.9361\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.0340 - val_loss: 121.8501\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.8656 - val_loss: 121.4158\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.0009 - val_loss: 120.5441\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.9824 - val_loss: 119.6891\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.8546 - val_loss: 119.4774\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.0181 - val_loss: 118.5557\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.8434 - val_loss: 121.5721\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.4519 - val_loss: 118.3104\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.2782 - val_loss: 117.3155\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.7545 - val_loss: 116.6537\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.4804 - val_loss: 116.1992\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.1372 - val_loss: 116.7839\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.0423 - val_loss: 115.2981\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.4184 - val_loss: 115.0289\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.8640 - val_loss: 118.3650\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 123.0508 - val_loss: 114.3243\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.7627 - val_loss: 114.5143\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.2885 - val_loss: 113.8880\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.0975 - val_loss: 114.6873\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.5229 - val_loss: 113.5539\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.5094 - val_loss: 116.6644\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3879 - val_loss: 112.9761\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.3611 - val_loss: 113.4391\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.2936 - val_loss: 112.4988\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.1781 - val_loss: 112.1697\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.6569 - val_loss: 112.0906\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.9984 - val_loss: 115.9367\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.4730 - val_loss: 112.0762\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.3813 - val_loss: 112.2184\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.2660 - val_loss: 112.2793\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 9ms/step - loss: 116.5484 - val_loss: 112.0614\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.5006 - val_loss: 112.2076\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.1195 - val_loss: 114.1161\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 10ms/step - loss: 116.8368 - val_loss: 113.0026\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.8951 - val_loss: 111.9771\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.1527 - val_loss: 113.5413\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.2406 - val_loss: 115.4771\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 144790.2500 - val_loss: 36209.5859\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 12388.4092 - val_loss: 1770.0717\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 2001.5078 - val_loss: 1856.7144\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1651.9397 - val_loss: 1522.6265\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1494.0599 - val_loss: 1436.6368\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1391.8807 - val_loss: 1348.8358\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1306.1610 - val_loss: 1267.8984\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1220.5145 - val_loss: 1197.3977\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1146.9526 - val_loss: 1128.7269\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1081.4229 - val_loss: 1065.4419\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1013.5367 - val_loss: 1004.0533\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 953.2853 - val_loss: 949.2534\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 901.7607 - val_loss: 897.9706\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 850.6477 - val_loss: 853.1215\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 804.9012 - val_loss: 811.4462\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 762.1072 - val_loss: 770.1328\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 723.0725 - val_loss: 731.8276\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 687.7303 - val_loss: 695.8563\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 651.3821 - val_loss: 665.0721\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 622.6139 - val_loss: 635.5237\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 593.2838 - val_loss: 608.4329\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 566.7073 - val_loss: 583.3951\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 541.6116 - val_loss: 559.8840\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 519.7531 - val_loss: 538.4214\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 502.0575 - val_loss: 518.5657\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 480.0446 - val_loss: 499.1677\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 463.3438 - val_loss: 483.2878\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 10ms/step - loss: 448.5480 - val_loss: 466.7744\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 431.6208 - val_loss: 452.7343\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 420.9102 - val_loss: 440.2357\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 403.0639 - val_loss: 428.3006\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 393.7650 - val_loss: 414.8586\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 381.4424 - val_loss: 403.3745\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 370.8829 - val_loss: 393.4999\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 362.3786 - val_loss: 383.6602\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 351.6266 - val_loss: 374.2953\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 343.2666 - val_loss: 366.2176\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 336.2178 - val_loss: 357.9311\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 327.6997 - val_loss: 350.1885\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 320.3742 - val_loss: 343.9605\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 317.6208 - val_loss: 339.6491\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 306.4931 - val_loss: 330.9444\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 300.8624 - val_loss: 323.5548\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 294.1836 - val_loss: 318.1120\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.9591 - val_loss: 313.5697\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.2762 - val_loss: 307.5823\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 280.7563 - val_loss: 304.4490\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 274.4383 - val_loss: 298.3121\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 270.0119 - val_loss: 294.5451\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 265.6368 - val_loss: 290.0982\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.8245 - val_loss: 285.6204\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 256.9835 - val_loss: 281.3961\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 253.9242 - val_loss: 277.7128\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.1021 - val_loss: 275.9882\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 247.8177 - val_loss: 270.4162\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.7905 - val_loss: 266.6945\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.1575 - val_loss: 263.8348\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 236.4067 - val_loss: 260.8942\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.1034 - val_loss: 258.3028\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 232.7132 - val_loss: 253.9863\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.7289 - val_loss: 253.0192\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.1064 - val_loss: 248.4256\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.3047 - val_loss: 248.2390\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.2887 - val_loss: 243.1001\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.0350 - val_loss: 240.6152\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.6117 - val_loss: 238.8747\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.9440 - val_loss: 236.4927\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.5562 - val_loss: 244.7013\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 214.3240 - val_loss: 231.9286\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.3800 - val_loss: 235.9696\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.5985 - val_loss: 231.7028\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.3017 - val_loss: 225.2200\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.7828 - val_loss: 225.1116\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.8374 - val_loss: 221.8049\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.3511 - val_loss: 221.7100\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.2094 - val_loss: 218.3095\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.4825 - val_loss: 215.1995\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.0626 - val_loss: 213.4726\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.2246 - val_loss: 211.3988\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.7681 - val_loss: 209.9213\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.5372 - val_loss: 209.1131\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.7323 - val_loss: 206.8837\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.7632 - val_loss: 204.5921\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.8006 - val_loss: 203.5775\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 9ms/step - loss: 186.4327 - val_loss: 203.3276\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.6924 - val_loss: 212.6860\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.0128 - val_loss: 198.0648\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.7688 - val_loss: 197.2290\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.4610 - val_loss: 196.1601\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.6765 - val_loss: 195.0133\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0979 - val_loss: 193.5063\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.5351 - val_loss: 191.3379\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.6790 - val_loss: 200.7091\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.9877 - val_loss: 188.5353\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.5413 - val_loss: 187.0723\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.6042 - val_loss: 186.0590\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.9277 - val_loss: 184.8273\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.6405 - val_loss: 184.8318\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.7415 - val_loss: 182.2952\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.1844 - val_loss: 180.4501\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 6009.8496 - val_loss: 2568.4204\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1912.4733 - val_loss: 1486.5575\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1597.1744 - val_loss: 1473.8501\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1593.4695 - val_loss: 1472.5354\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1592.2244 - val_loss: 1471.3118\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1590.9410 - val_loss: 1470.0408\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1589.6040 - val_loss: 1468.7344\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1588.2356 - val_loss: 1467.3975\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1586.8386 - val_loss: 1466.0211\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1585.4105 - val_loss: 1464.6324\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1583.9657 - val_loss: 1463.2299\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1582.5062 - val_loss: 1461.8176\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1581.0345 - val_loss: 1460.3799\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1579.5554 - val_loss: 1458.9353\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 1578.0618 - val_loss: 1457.4885\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 1576.5479 - val_loss: 1456.0433\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 1575.0457 - val_loss: 1454.5568\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 1573.5173 - val_loss: 1453.0981\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 1571.9934 - val_loss: 1451.6228\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 1570.4764 - val_loss: 1450.1315\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 1568.9403 - val_loss: 1448.6588\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 1567.4199 - val_loss: 1447.1548\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 9ms/step - loss: 1565.8662 - val_loss: 1445.6881\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 1564.3412 - val_loss: 1444.1794\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 1562.7784 - val_loss: 1442.6989\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 1561.2455 - val_loss: 1441.1748\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 1559.6779 - val_loss: 1439.6964\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 1558.1350 - val_loss: 1438.1863\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 1556.5787 - val_loss: 1436.6829\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 1555.0269 - val_loss: 1435.1714\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 1553.4696 - val_loss: 1433.6624\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 1551.9088 - val_loss: 1432.1626\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 1550.3569 - val_loss: 1430.6587\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 1548.7979 - val_loss: 1429.1616\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 1547.2400 - val_loss: 1427.6689\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 1545.6898 - val_loss: 1426.1383\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 1544.1210 - val_loss: 1424.6196\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 1542.5525 - val_loss: 1423.1201\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 1540.9917 - val_loss: 1421.6149\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 1539.4401 - val_loss: 1420.0951\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 1537.8743 - val_loss: 1418.5890\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 1536.3110 - val_loss: 1417.0776\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 1534.7517 - val_loss: 1415.5609\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 7ms/step - loss: 1533.1840 - val_loss: 1414.0554\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 1531.6267 - val_loss: 1412.5475\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 1530.0685 - val_loss: 1411.0402\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 1528.5065 - val_loss: 1409.5372\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 1526.9501 - val_loss: 1408.0320\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 1525.3887 - val_loss: 1406.5236\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 1523.8282 - val_loss: 1405.0135\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 1522.2661 - val_loss: 1403.5039\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 1520.7104 - val_loss: 1401.9879\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 1519.1443 - val_loss: 1400.4827\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 1517.5938 - val_loss: 1398.9664\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 1516.0259 - val_loss: 1397.4685\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 1514.4683 - val_loss: 1395.9611\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 1512.9105 - val_loss: 1394.4426\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 1511.3380 - val_loss: 1392.9539\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 1509.7888 - val_loss: 1391.4443\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 1508.2330 - val_loss: 1389.9303\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 1506.6757 - val_loss: 1388.4246\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 1505.1193 - val_loss: 1386.9319\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 1503.5710 - val_loss: 1385.4360\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 1502.0214 - val_loss: 1383.9321\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 1500.4612 - val_loss: 1382.4307\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 1498.9089 - val_loss: 1380.9320\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 1497.3601 - val_loss: 1379.4271\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 1495.8085 - val_loss: 1377.9260\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 1494.2574 - val_loss: 1376.4348\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 1492.7119 - val_loss: 1374.9331\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 7ms/step - loss: 1491.1620 - val_loss: 1373.4437\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 1489.6171 - val_loss: 1371.9569\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 1488.0737 - val_loss: 1370.4556\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 1486.5251 - val_loss: 1368.9667\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 8ms/step - loss: 1484.9750 - val_loss: 1367.4678\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 1483.4240 - val_loss: 1365.9740\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 1481.8809 - val_loss: 1364.4805\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 1480.3420 - val_loss: 1362.9827\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 1478.7959 - val_loss: 1361.5028\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 1477.2588 - val_loss: 1360.0206\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 1475.7250 - val_loss: 1358.5314\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 1474.1852 - val_loss: 1357.0485\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 9ms/step - loss: 1472.6469 - val_loss: 1355.5720\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 1471.1163 - val_loss: 1354.0851\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 1469.5854 - val_loss: 1352.5897\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 1468.0424 - val_loss: 1351.1205\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 10ms/step - loss: 1466.5109 - val_loss: 1349.6423\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 1464.9806 - val_loss: 1348.1606\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 1463.4504 - val_loss: 1346.6748\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 1461.9167 - val_loss: 1345.2087\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 1460.3937 - val_loss: 1343.7361\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 1458.8674 - val_loss: 1342.2662\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 1457.3450 - val_loss: 1340.7871\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 1455.8213 - val_loss: 1339.2998\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 10ms/step - loss: 1454.2915 - val_loss: 1337.8308\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 1452.7631 - val_loss: 1336.3691\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 1451.2460 - val_loss: 1334.8955\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 1449.7244 - val_loss: 1333.4269\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 1448.1971 - val_loss: 1331.9700\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 1446.6793 - val_loss: 1330.4965\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 799.2191 - val_loss: 348.3996\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.7649 - val_loss: 328.2032\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.9464 - val_loss: 319.8879\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.5479 - val_loss: 306.6532\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.6887 - val_loss: 297.7231\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.4549 - val_loss: 290.9653\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.4989 - val_loss: 277.2578\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.7480 - val_loss: 270.3259\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 197.3533 - val_loss: 259.5796\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.0785 - val_loss: 249.5500\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.5384 - val_loss: 241.0894\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.4969 - val_loss: 230.6416\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.7516 - val_loss: 220.6802\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.5457 - val_loss: 213.2188\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.8113 - val_loss: 211.1659\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.8018 - val_loss: 203.5759\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.5892 - val_loss: 186.2891\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.7374 - val_loss: 174.5898\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.5081 - val_loss: 162.6461\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.6755 - val_loss: 150.4553\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 125.0131 - val_loss: 146.1947\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.7837 - val_loss: 140.5291\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.7820 - val_loss: 132.8789\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2393 - val_loss: 132.5981\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.8836 - val_loss: 127.9303\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.6670 - val_loss: 127.0181\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.6272 - val_loss: 126.9591\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.0087 - val_loss: 115.7962\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5495 - val_loss: 115.7387\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.1264 - val_loss: 115.5980\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.2390 - val_loss: 110.3400\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.2956 - val_loss: 111.9137\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.7044 - val_loss: 108.2697\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.9503 - val_loss: 109.4556\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.8677 - val_loss: 106.4896\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.2229 - val_loss: 105.2421\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.9908 - val_loss: 100.8471\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.5604 - val_loss: 97.7447\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.0498 - val_loss: 97.6394\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.1211 - val_loss: 101.5432\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.8118 - val_loss: 93.5713\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7561 - val_loss: 97.4714\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4844 - val_loss: 97.5534\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3852 - val_loss: 98.1826\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.5833 - val_loss: 91.1962\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.3433 - val_loss: 99.6967\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.5532 - val_loss: 86.5671\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.2369 - val_loss: 96.9155\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.8504 - val_loss: 95.5316\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.5558 - val_loss: 94.7522\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.9748 - val_loss: 85.2282\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.6678 - val_loss: 97.4779\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1958 - val_loss: 88.3920\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2376 - val_loss: 91.9133\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.6587 - val_loss: 91.5133\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.4140 - val_loss: 90.1554\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2733 - val_loss: 89.4494\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.6535 - val_loss: 94.1416\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5218 - val_loss: 90.6421\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.9451 - val_loss: 86.3681\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 10ms/step - loss: 71.3948 - val_loss: 92.7584\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.6335 - val_loss: 91.6016\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7266 - val_loss: 84.6721\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9257 - val_loss: 85.4309\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.4776 - val_loss: 88.3265\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7198 - val_loss: 83.6313\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4906 - val_loss: 83.8665\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 9ms/step - loss: 64.4057 - val_loss: 82.6914\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.1297 - val_loss: 82.6026\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.4535 - val_loss: 80.3607\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.5542 - val_loss: 80.6593\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9466 - val_loss: 81.1050\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.5621 - val_loss: 77.0630\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.7682 - val_loss: 75.4908\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.4311 - val_loss: 76.4052\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6980 - val_loss: 72.9986\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6776 - val_loss: 72.8613\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.3604 - val_loss: 78.7913\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.3730 - val_loss: 75.6970\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.8461 - val_loss: 70.4138\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.9026 - val_loss: 70.4317\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.0090 - val_loss: 71.7761\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.4857 - val_loss: 71.3573\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.9783 - val_loss: 71.9603\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.9664 - val_loss: 68.2059\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.0450 - val_loss: 69.1982\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.8537 - val_loss: 66.0136\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.6409 - val_loss: 66.4035\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.9009 - val_loss: 67.5558\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.9394 - val_loss: 65.4468\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.9444 - val_loss: 68.5372\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.4501 - val_loss: 64.4052\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.4035 - val_loss: 65.6926\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.0995 - val_loss: 63.7361\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.0074 - val_loss: 64.1755\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 52.2296 - val_loss: 62.6130\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 8ms/step - loss: 52.9150 - val_loss: 62.2233\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.4287 - val_loss: 62.2514\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 7ms/step - loss: 51.7202 - val_loss: 64.2704\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.9715 - val_loss: 63.0705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 4392.3291 - val_loss: 1270.3325\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1161.8073 - val_loss: 811.4130\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 677.0897 - val_loss: 517.8447\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 472.8434 - val_loss: 394.1813\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.0291 - val_loss: 291.1482\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.8433 - val_loss: 236.0761\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.8482 - val_loss: 207.5067\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.6725 - val_loss: 180.9508\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.3961 - val_loss: 172.4624\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.9115 - val_loss: 172.1031\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.2136 - val_loss: 168.8732\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.8384 - val_loss: 168.7233\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.0569 - val_loss: 167.6505\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.0295 - val_loss: 160.6973\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.8971 - val_loss: 156.2606\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.9079 - val_loss: 162.4167\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.2750 - val_loss: 151.3961\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.0518 - val_loss: 148.8697\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.7993 - val_loss: 148.1213\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 133.5445 - val_loss: 147.3589\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.3191 - val_loss: 141.8112\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.1670 - val_loss: 143.1337\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.6281 - val_loss: 138.7146\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.7095 - val_loss: 138.5861\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.1443 - val_loss: 134.2314\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.1808 - val_loss: 133.6238\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.9562 - val_loss: 132.2438\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.3285 - val_loss: 130.3078\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.0006 - val_loss: 129.7275\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.0176 - val_loss: 128.1523\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 117.2926 - val_loss: 136.8791\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.8581 - val_loss: 128.5627\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.8418 - val_loss: 132.9355\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.7692 - val_loss: 125.0845\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 112.4141 - val_loss: 127.3722\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6290 - val_loss: 125.3170\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8798 - val_loss: 121.8025\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.1573 - val_loss: 124.0121\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.7444 - val_loss: 122.7955\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.1721 - val_loss: 117.7179\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.3157 - val_loss: 119.0125\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.8342 - val_loss: 116.9642\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 9ms/step - loss: 103.5104 - val_loss: 115.7852\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.3062 - val_loss: 112.6612\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.2531 - val_loss: 116.7294\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.6954 - val_loss: 111.5130\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.5023 - val_loss: 109.1417\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.7787 - val_loss: 113.5967\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.0631 - val_loss: 107.7963\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.7623 - val_loss: 111.1870\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.8678 - val_loss: 109.4969\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 96.3476 - val_loss: 105.2553\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6496 - val_loss: 112.5869\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.9548 - val_loss: 102.9951\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.5658 - val_loss: 103.1578\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.5565 - val_loss: 116.1893\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.9797 - val_loss: 103.2204\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.1320 - val_loss: 103.2180\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.3366 - val_loss: 102.2829\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.9794 - val_loss: 109.9317\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.4595 - val_loss: 98.2908\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.8851 - val_loss: 99.3616\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.2982 - val_loss: 96.8357\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.4433 - val_loss: 96.0120\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8954 - val_loss: 110.9777\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.2238 - val_loss: 94.7747\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.8867 - val_loss: 94.4154\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.1618 - val_loss: 93.4780\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.6863 - val_loss: 95.5481\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.4880 - val_loss: 91.7533\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.2829 - val_loss: 90.5262\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7867 - val_loss: 93.4590\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.0142 - val_loss: 89.0417\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.2150 - val_loss: 92.7645\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0039 - val_loss: 91.3670\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5799 - val_loss: 87.6242\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1795 - val_loss: 86.9574\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.6278 - val_loss: 86.7247\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7276 - val_loss: 87.2867\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 9ms/step - loss: 79.3685 - val_loss: 84.9633\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6479 - val_loss: 88.8214\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0808 - val_loss: 88.2844\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.8437 - val_loss: 83.7093\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.9037 - val_loss: 95.1451\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.5018 - val_loss: 86.2658\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.1601 - val_loss: 88.9474\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4780 - val_loss: 90.9407\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.6300 - val_loss: 84.9337\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.4659 - val_loss: 84.7839\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.5665 - val_loss: 82.7869\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.5672 - val_loss: 81.4365\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 10ms/step - loss: 76.5692 - val_loss: 80.1640\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.0108 - val_loss: 81.1317\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6400 - val_loss: 79.8669\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1752 - val_loss: 80.5419\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6775 - val_loss: 78.9543\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1496 - val_loss: 83.1042\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.6887 - val_loss: 79.9436\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.9638 - val_loss: 77.5608\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.9350 - val_loss: 81.3378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 69ms/step - loss: 460.4227 - val_loss: 264.0793\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.3285 - val_loss: 254.8239\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.3734 - val_loss: 217.6292\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.7845 - val_loss: 208.5820\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 227.3573 - val_loss: 192.0834\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 212.1722 - val_loss: 182.0977\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.8432 - val_loss: 173.1318\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.6421 - val_loss: 164.2699\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.8438 - val_loss: 156.6707\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.7593 - val_loss: 148.0927\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.6243 - val_loss: 156.9543\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.5595 - val_loss: 136.3620\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.6200 - val_loss: 132.5063\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.9250 - val_loss: 132.0365\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.9049 - val_loss: 124.2911\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.1263 - val_loss: 123.9179\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.0143 - val_loss: 116.4850\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.3824 - val_loss: 124.4935\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.1084 - val_loss: 111.7111\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 120.0477 - val_loss: 112.4699\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.0512 - val_loss: 114.1762\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.9162 - val_loss: 106.2065\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 111.5723 - val_loss: 104.7460\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.9412 - val_loss: 107.4400\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8206 - val_loss: 104.6864\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.5182 - val_loss: 103.6971\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7911 - val_loss: 101.1372\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 102.8623 - val_loss: 97.8656\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 103.6192 - val_loss: 97.2473\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9141 - val_loss: 94.0024\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.5460 - val_loss: 92.9169\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.9431 - val_loss: 97.1633\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.7050 - val_loss: 90.5021\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5405 - val_loss: 93.2988\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.8089 - val_loss: 88.0083\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.4244 - val_loss: 87.3282\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.5585 - val_loss: 87.3908\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.2477 - val_loss: 84.1722\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.3783 - val_loss: 90.6571\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.6224 - val_loss: 84.0051\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.3290 - val_loss: 84.9102\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.8445 - val_loss: 94.5101\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.3692 - val_loss: 79.7404\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 84.5320 - val_loss: 77.8419\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.6261 - val_loss: 75.9858\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.5170 - val_loss: 78.2105\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5189 - val_loss: 79.4746\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6084 - val_loss: 75.8337\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7879 - val_loss: 73.2961\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.8180 - val_loss: 71.6008\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.0796 - val_loss: 80.0332\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4857 - val_loss: 70.2028\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4626 - val_loss: 69.0999\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.5962 - val_loss: 69.2771\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.7424 - val_loss: 84.0390\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.7393 - val_loss: 67.8557\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5147 - val_loss: 73.4266\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.4682 - val_loss: 69.2016\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0342 - val_loss: 67.8763\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 9ms/step - loss: 69.8001 - val_loss: 66.9556\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5952 - val_loss: 73.2822\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8594 - val_loss: 67.6665\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7766 - val_loss: 65.3509\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.5633 - val_loss: 65.3998\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9333 - val_loss: 67.5878\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 6ms/step - loss: 62.8359 - val_loss: 68.8841\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 6ms/step - loss: 67.1694 - val_loss: 67.2187\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8612 - val_loss: 62.6486\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.9325 - val_loss: 65.0754\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.2877 - val_loss: 64.3192\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.2171 - val_loss: 64.1284\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.1035 - val_loss: 62.8292\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.5624 - val_loss: 61.6175\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.7706 - val_loss: 60.3949\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.1698 - val_loss: 71.8147\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.5287 - val_loss: 59.2473\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.7833 - val_loss: 59.2273\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.4022 - val_loss: 63.4946\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.1937 - val_loss: 59.5651\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.8712 - val_loss: 60.5242\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.3351 - val_loss: 60.7993\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.6234 - val_loss: 58.1311\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.8742 - val_loss: 57.3556\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.8258 - val_loss: 56.8653\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.3374 - val_loss: 56.3773\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.2034 - val_loss: 56.1450\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.0464 - val_loss: 56.3817\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 11ms/step - loss: 51.5739 - val_loss: 60.1725\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 52.8992 - val_loss: 56.5394\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.0180 - val_loss: 56.0707\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.9744 - val_loss: 54.6568\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.8612 - val_loss: 54.1735\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.6529 - val_loss: 54.8023\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.2839 - val_loss: 52.7985\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.8502 - val_loss: 53.3964\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.0888 - val_loss: 85.0825\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.6806 - val_loss: 55.0950\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.3588 - val_loss: 54.5272\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 47.9608 - val_loss: 54.2641\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.5930 - val_loss: 54.0436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 53135.0781 - val_loss: 16195.5391\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 5437.6455 - val_loss: 898.0249\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 628.7287 - val_loss: 577.8000\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 568.3745 - val_loss: 516.8032\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 495.0279 - val_loss: 501.9994\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 466.4530 - val_loss: 466.5353\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 438.2011 - val_loss: 429.9124\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 8ms/step - loss: 410.9825 - val_loss: 411.3816\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 390.0428 - val_loss: 387.3919\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 370.1765 - val_loss: 369.3525\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 351.4210 - val_loss: 347.0151\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.9924 - val_loss: 336.2782\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 319.8786 - val_loss: 319.1674\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 308.9926 - val_loss: 306.2977\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 297.8891 - val_loss: 294.8450\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 287.9656 - val_loss: 286.0615\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 279.4434 - val_loss: 275.7344\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 271.0846 - val_loss: 270.1216\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 263.0290 - val_loss: 260.0797\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.8840 - val_loss: 252.3388\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 250.5960 - val_loss: 243.5269\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.0124 - val_loss: 235.8537\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 236.8216 - val_loss: 228.7953\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.1894 - val_loss: 220.3376\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.0372 - val_loss: 214.0936\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.1939 - val_loss: 210.0323\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.0284 - val_loss: 202.9130\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.2145 - val_loss: 198.4506\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.8165 - val_loss: 194.1662\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.1189 - val_loss: 189.8619\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.6874 - val_loss: 185.9249\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.0390 - val_loss: 181.4985\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.4334 - val_loss: 180.3464\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.4638 - val_loss: 175.1474\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.5395 - val_loss: 171.5428\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.2893 - val_loss: 168.2529\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 166.4997 - val_loss: 168.9109\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.0787 - val_loss: 161.9727\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.9480 - val_loss: 159.3160\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.9138 - val_loss: 157.5101\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.1452 - val_loss: 155.0972\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.4985 - val_loss: 152.7942\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.4966 - val_loss: 149.7390\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.2616 - val_loss: 147.4883\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.6724 - val_loss: 146.2763\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.5642 - val_loss: 144.7493\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.2523 - val_loss: 142.4325\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.0486 - val_loss: 141.2450\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2534 - val_loss: 138.7505\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.9069 - val_loss: 139.0667\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.2314 - val_loss: 138.5314\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.7937 - val_loss: 135.7755\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.6437 - val_loss: 136.2497\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.5027 - val_loss: 134.2344\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.9307 - val_loss: 131.1952\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.1901 - val_loss: 131.0488\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.4565 - val_loss: 129.1096\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.1444 - val_loss: 127.7574\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.8804 - val_loss: 127.8633\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.8924 - val_loss: 125.1483\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.8532 - val_loss: 128.2534\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3428 - val_loss: 126.0050\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.2385 - val_loss: 122.6984\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.0721 - val_loss: 121.4233\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.9483 - val_loss: 121.4716\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.9992 - val_loss: 120.7568\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.5784 - val_loss: 119.2382\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.9025 - val_loss: 120.8013\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7265 - val_loss: 117.2588\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.7917 - val_loss: 116.2285\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.0373 - val_loss: 117.7573\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.7504 - val_loss: 113.6453\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.0160 - val_loss: 112.5413\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.0024 - val_loss: 113.0518\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5562 - val_loss: 109.9921\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.8982 - val_loss: 111.4350\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.1881 - val_loss: 107.6618\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8339 - val_loss: 108.5642\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8870 - val_loss: 106.8761\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9762 - val_loss: 106.3630\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.4202 - val_loss: 106.3111\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9910 - val_loss: 104.7760\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.3152 - val_loss: 104.9521\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.7850 - val_loss: 104.5068\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6467 - val_loss: 103.4267\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7735 - val_loss: 104.4602\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.2624 - val_loss: 102.6721\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.4057 - val_loss: 102.3214\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0777 - val_loss: 101.5691\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.5530 - val_loss: 101.7464\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.7306 - val_loss: 100.8700\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1733 - val_loss: 100.4187\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.3640 - val_loss: 100.1564\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.8775 - val_loss: 102.3612\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.1110 - val_loss: 98.9073\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.2256 - val_loss: 98.6483\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.1068 - val_loss: 97.8503\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.7695 - val_loss: 97.9275\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.7505 - val_loss: 97.7472\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 102.9753 - val_loss: 97.0329\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 3899.6748 - val_loss: 590.1487\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 324.2465 - val_loss: 314.8274\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.4622 - val_loss: 236.2523\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.8265 - val_loss: 231.7604\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.7937 - val_loss: 225.2120\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.0031 - val_loss: 221.6033\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.3328 - val_loss: 216.3784\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.3266 - val_loss: 214.9038\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.2754 - val_loss: 207.4488\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.7225 - val_loss: 206.4848\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.8415 - val_loss: 200.0250\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.5353 - val_loss: 200.4438\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.5354 - val_loss: 194.6309\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.0264 - val_loss: 192.5245\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.2249 - val_loss: 190.2104\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.7856 - val_loss: 184.9875\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.6846 - val_loss: 180.9499\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.4401 - val_loss: 185.7500\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.3042 - val_loss: 173.4425\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.2044 - val_loss: 176.6368\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.1995 - val_loss: 168.6885\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.4890 - val_loss: 168.8605\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.3692 - val_loss: 170.4142\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.9850 - val_loss: 173.2549\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.5594 - val_loss: 164.3784\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.4823 - val_loss: 160.9349\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.2996 - val_loss: 171.9642\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.5251 - val_loss: 159.4788\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.0263 - val_loss: 156.3234\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.4512 - val_loss: 149.8914\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.4000 - val_loss: 148.2760\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.7375 - val_loss: 149.2911\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.3422 - val_loss: 144.7251\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.9419 - val_loss: 149.8700\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.0671 - val_loss: 156.0587\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.0241 - val_loss: 142.3448\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.2343 - val_loss: 145.5775\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.3097 - val_loss: 139.7700\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.9618 - val_loss: 136.1827\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.8650 - val_loss: 135.7014\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 16ms/step - loss: 140.3121 - val_loss: 135.5387\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.7878 - val_loss: 132.5467\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.5260 - val_loss: 134.8563\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.1582 - val_loss: 129.2049\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2711 - val_loss: 128.7790\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.8407 - val_loss: 126.9775\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.4778 - val_loss: 127.9320\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.9501 - val_loss: 136.1371\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.7549 - val_loss: 120.6644\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.1318 - val_loss: 119.6962\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.7132 - val_loss: 117.3153\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1087 - val_loss: 128.0689\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.9040 - val_loss: 117.1085\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.4244 - val_loss: 112.9240\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.5570 - val_loss: 115.2358\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.2581 - val_loss: 119.9263\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.1407 - val_loss: 113.7827\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.3206 - val_loss: 106.3334\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0667 - val_loss: 111.3501\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.4099 - val_loss: 102.8767\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0375 - val_loss: 106.8670\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6777 - val_loss: 113.0578\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.7688 - val_loss: 98.6474\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9458 - val_loss: 98.1142\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9964 - val_loss: 108.2691\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.6516 - val_loss: 94.7385\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.7118 - val_loss: 93.7547\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.1164 - val_loss: 93.4666\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.4717 - val_loss: 91.3926\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.9692 - val_loss: 90.3376\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.5560 - val_loss: 92.1690\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.7893 - val_loss: 89.0803\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.1020 - val_loss: 86.6624\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.1862 - val_loss: 88.2260\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.4077 - val_loss: 86.4484\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.0591 - val_loss: 84.7999\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.7231 - val_loss: 83.0146\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.3013 - val_loss: 82.2609\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 9ms/step - loss: 83.5437 - val_loss: 92.5053\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.5488 - val_loss: 81.3568\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.3546 - val_loss: 84.4400\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.8927 - val_loss: 82.7053\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5504 - val_loss: 92.4427\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.9456 - val_loss: 88.4831\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.2964 - val_loss: 81.9376\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.0488 - val_loss: 77.4329\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.0684 - val_loss: 77.0913\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2407 - val_loss: 83.1077\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.2086 - val_loss: 77.3243\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.9470 - val_loss: 85.6962\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.5613 - val_loss: 76.3515\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 69.5247 - val_loss: 75.5134\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.4944 - val_loss: 77.2150\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.9911 - val_loss: 75.6645\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1855 - val_loss: 74.7174\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.9419 - val_loss: 76.2520\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9105 - val_loss: 76.7268\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1577 - val_loss: 76.7831\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.2247 - val_loss: 73.8260\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.1155 - val_loss: 75.0373\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 439.9268 - val_loss: 377.9756\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 260.3664 - val_loss: 248.8622\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.2437 - val_loss: 205.0337\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.9274 - val_loss: 189.2816\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.8866 - val_loss: 191.4478\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.7443 - val_loss: 159.8186\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.0715 - val_loss: 148.4364\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.4214 - val_loss: 140.5566\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.8018 - val_loss: 147.3304\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.6958 - val_loss: 181.5204\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.0938 - val_loss: 136.0267\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.9213 - val_loss: 130.0400\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.8931 - val_loss: 129.1820\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.2110 - val_loss: 142.9545\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.9848 - val_loss: 125.2807\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.9526 - val_loss: 122.6888\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.4665 - val_loss: 120.2808\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.5852 - val_loss: 117.4573\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.8874 - val_loss: 126.9981\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1814 - val_loss: 115.9544\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.4878 - val_loss: 120.0931\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.9784 - val_loss: 112.8015\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.6911 - val_loss: 110.1599\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.8485 - val_loss: 110.3524\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.4849 - val_loss: 106.2807\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.3050 - val_loss: 108.5722\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 10ms/step - loss: 105.4072 - val_loss: 107.2276\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.2912 - val_loss: 103.5990\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2598 - val_loss: 107.6204\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.5909 - val_loss: 101.6231\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.3186 - val_loss: 101.0709\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.7180 - val_loss: 106.3929\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.8188 - val_loss: 137.5929\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.9942 - val_loss: 103.7613\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.9681 - val_loss: 96.6235\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.0437 - val_loss: 94.7296\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.4556 - val_loss: 94.6098\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.5191 - val_loss: 102.2109\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.9185 - val_loss: 90.7985\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.1820 - val_loss: 90.9213\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.3417 - val_loss: 88.7428\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.9217 - val_loss: 92.9577\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.6275 - val_loss: 86.9706\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.9356 - val_loss: 86.3786\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.0690 - val_loss: 85.5212\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.9040 - val_loss: 91.6892\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.7619 - val_loss: 92.4541\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.6681 - val_loss: 83.4108\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.9656 - val_loss: 83.3321\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.8599 - val_loss: 94.0893\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0789 - val_loss: 84.2730\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.3445 - val_loss: 106.8728\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0850 - val_loss: 82.4406\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7791 - val_loss: 79.2952\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.6082 - val_loss: 78.5144\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.5549 - val_loss: 79.8049\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.6199 - val_loss: 77.0566\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7101 - val_loss: 76.4900\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.6379 - val_loss: 92.2701\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4506 - val_loss: 85.8263\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4730 - val_loss: 81.3232\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4050 - val_loss: 78.5597\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7171 - val_loss: 77.1856\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7358 - val_loss: 79.1204\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.9823 - val_loss: 84.2585\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.8432 - val_loss: 76.2832\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3534 - val_loss: 74.5931\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 9ms/step - loss: 75.9551 - val_loss: 75.5232\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7703 - val_loss: 86.6968\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6289 - val_loss: 73.2126\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.8220 - val_loss: 77.5624\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.9373 - val_loss: 75.2996\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.9376 - val_loss: 74.7736\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.3958 - val_loss: 71.3861\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.2103 - val_loss: 76.6519\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.4664 - val_loss: 72.2221\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.3112 - val_loss: 85.2122\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.9215 - val_loss: 78.1271\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7055 - val_loss: 72.7605\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.4745 - val_loss: 72.7774\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1758 - val_loss: 71.1957\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.4052 - val_loss: 74.3923\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6412 - val_loss: 72.7383\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2597 - val_loss: 89.7087\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.6441 - val_loss: 77.5420\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.2093 - val_loss: 71.1689\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9792 - val_loss: 73.8544\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5660 - val_loss: 79.5533\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.9542 - val_loss: 68.7846\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.6336 - val_loss: 71.3833\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1976 - val_loss: 76.8042\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.1047 - val_loss: 72.7454\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7870 - val_loss: 68.7454\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.5605 - val_loss: 90.1649\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.7319 - val_loss: 66.7959\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7156 - val_loss: 67.2205\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.6684 - val_loss: 67.2354\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.1674 - val_loss: 78.3021\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.6383 - val_loss: 68.1361\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.4243 - val_loss: 68.2438\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 87ms/step - loss: 264.3156 - val_loss: 230.9527\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.3355 - val_loss: 208.0413\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.3133 - val_loss: 235.6855\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.2435 - val_loss: 188.5177\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.2163 - val_loss: 185.1386\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.1108 - val_loss: 175.1844\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.4152 - val_loss: 179.5781\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.1717 - val_loss: 170.2253\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.9910 - val_loss: 165.4017\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.9452 - val_loss: 162.6713\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.3922 - val_loss: 181.8428\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.6787 - val_loss: 156.3001\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.3690 - val_loss: 154.5754\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.6083 - val_loss: 151.6850\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.1186 - val_loss: 149.6575\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.7423 - val_loss: 150.3135\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3338 - val_loss: 145.4494\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.3060 - val_loss: 143.8687\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.7934 - val_loss: 143.2198\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.2450 - val_loss: 139.9834\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.3780 - val_loss: 162.3974\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3246 - val_loss: 138.5052\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.5260 - val_loss: 134.0936\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.5455 - val_loss: 133.0215\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 10ms/step - loss: 116.4248 - val_loss: 143.6618\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.7544 - val_loss: 138.6237\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.0346 - val_loss: 145.9130\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4345 - val_loss: 127.0314\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.7360 - val_loss: 124.3923\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.6955 - val_loss: 137.8230\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.4082 - val_loss: 129.8385\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.5061 - val_loss: 119.4037\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.6947 - val_loss: 117.9568\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.1907 - val_loss: 115.6650\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.6995 - val_loss: 127.6395\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.7468 - val_loss: 113.6642\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.4291 - val_loss: 115.8845\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.4600 - val_loss: 112.0730\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6230 - val_loss: 109.7891\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.1953 - val_loss: 108.7674\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.4945 - val_loss: 108.3437\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.4863 - val_loss: 115.6384\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.1010 - val_loss: 104.2785\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.1674 - val_loss: 112.2972\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.1031 - val_loss: 107.4464\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.5016 - val_loss: 112.7298\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.9373 - val_loss: 99.2865\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.0915 - val_loss: 110.4255\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.0017 - val_loss: 98.2511\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.6560 - val_loss: 97.0738\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.4887 - val_loss: 102.1425\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.2627 - val_loss: 95.0086\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.7998 - val_loss: 93.2115\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.7325 - val_loss: 95.2370\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.2238 - val_loss: 91.3397\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.3115 - val_loss: 91.6415\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.6145 - val_loss: 91.3462\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7493 - val_loss: 99.4487\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.1536 - val_loss: 88.4571\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.9216 - val_loss: 87.3560\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.0991 - val_loss: 89.5953\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.6987 - val_loss: 102.1891\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.8419 - val_loss: 85.3655\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0773 - val_loss: 84.7557\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.1359 - val_loss: 88.4144\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.8359 - val_loss: 89.0382\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.5380 - val_loss: 82.9240\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.0590 - val_loss: 82.4449\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9162 - val_loss: 82.7471\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4717 - val_loss: 81.9859\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.1560 - val_loss: 81.6736\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.3330 - val_loss: 82.2852\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3912 - val_loss: 81.0995\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.9846 - val_loss: 80.6282\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.5530 - val_loss: 82.7286\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.9099 - val_loss: 80.9450\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.3773 - val_loss: 83.1326\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.9780 - val_loss: 81.2987\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.3292 - val_loss: 78.5249\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 9ms/step - loss: 69.9600 - val_loss: 80.2982\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1524 - val_loss: 86.1199\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.3172 - val_loss: 77.5848\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.5846 - val_loss: 83.5666\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.6160 - val_loss: 77.3548\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.3575 - val_loss: 80.2809\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.6253 - val_loss: 77.4541\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.0874 - val_loss: 77.6492\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.8990 - val_loss: 76.4999\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.3936 - val_loss: 77.3591\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7804 - val_loss: 78.3613\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 12ms/step - loss: 71.3960 - val_loss: 75.9942\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.0225 - val_loss: 76.5274\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0851 - val_loss: 82.6230\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.8353 - val_loss: 87.1320\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5061 - val_loss: 78.4829\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8945 - val_loss: 77.5591\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5704 - val_loss: 75.7151\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.2525 - val_loss: 75.2302\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9074 - val_loss: 74.8638\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9581 - val_loss: 79.4629\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1706.0447 - val_loss: 652.1896\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 537.8658 - val_loss: 462.7278\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 432.8182 - val_loss: 408.1085\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 391.7489 - val_loss: 375.9336\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 360.7369 - val_loss: 347.6374\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.9093 - val_loss: 331.3955\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.7950 - val_loss: 308.6497\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 307.0688 - val_loss: 295.6089\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 287.5318 - val_loss: 285.9865\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.9838 - val_loss: 273.1936\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 267.1912 - val_loss: 268.9678\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 254.0161 - val_loss: 251.4386\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.5488 - val_loss: 247.8643\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 235.9522 - val_loss: 244.9879\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.0652 - val_loss: 225.9440\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.9888 - val_loss: 216.9544\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.6283 - val_loss: 210.0013\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.7901 - val_loss: 200.1886\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.1466 - val_loss: 194.3240\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.2277 - val_loss: 183.8110\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.4578 - val_loss: 188.3369\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.1786 - val_loss: 169.9181\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.1180 - val_loss: 161.3688\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.5272 - val_loss: 156.6531\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.4335 - val_loss: 148.3443\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.9196 - val_loss: 151.5385\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.4699 - val_loss: 141.8574\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.9511 - val_loss: 132.6056\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.8403 - val_loss: 130.4399\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.9578 - val_loss: 126.8149\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.4127 - val_loss: 123.7374\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.3518 - val_loss: 123.8055\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.0450 - val_loss: 123.6879\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.7904 - val_loss: 110.9696\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.5175 - val_loss: 110.6478\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.3513 - val_loss: 114.4073\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.3441 - val_loss: 105.5457\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.6789 - val_loss: 105.4401\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.6943 - val_loss: 101.0649\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.0296 - val_loss: 115.0159\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.5448 - val_loss: 98.0989\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.9377 - val_loss: 97.6020\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.9194 - val_loss: 93.8925\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.7920 - val_loss: 95.1847\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.5989 - val_loss: 91.8409\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.8003 - val_loss: 90.2040\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.1554 - val_loss: 93.5423\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 7ms/step - loss: 84.3589 - val_loss: 88.8742\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.3499 - val_loss: 92.5782\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.4324 - val_loss: 84.9798\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.8524 - val_loss: 85.4266\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.2809 - val_loss: 85.4886\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7511 - val_loss: 86.3972\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1573 - val_loss: 82.3433\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.5412 - val_loss: 80.0466\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.8802 - val_loss: 83.7385\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.7637 - val_loss: 80.3073\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.8558 - val_loss: 80.4175\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.0091 - val_loss: 85.9232\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.0956 - val_loss: 78.1110\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.4385 - val_loss: 73.8890\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1072 - val_loss: 78.4512\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.9899 - val_loss: 75.9087\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.1431 - val_loss: 74.6889\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 9ms/step - loss: 66.9240 - val_loss: 72.9361\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9922 - val_loss: 72.6779\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 6ms/step - loss: 64.6217 - val_loss: 71.6390\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.3020 - val_loss: 75.5756\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 6ms/step - loss: 63.0841 - val_loss: 70.6990\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 14ms/step - loss: 62.5329 - val_loss: 68.7417\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9616 - val_loss: 70.9647\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.7686 - val_loss: 69.5676\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.0145 - val_loss: 74.0557\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.8690 - val_loss: 70.7594\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.1620 - val_loss: 70.8413\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8696 - val_loss: 67.1263\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6261 - val_loss: 66.6022\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.1533 - val_loss: 72.6294\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3424 - val_loss: 83.6439\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.0213 - val_loss: 85.6359\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.3847 - val_loss: 65.4694\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.3350 - val_loss: 65.1353\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.1261 - val_loss: 67.0744\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8976 - val_loss: 67.6967\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.7914 - val_loss: 63.8684\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.9524 - val_loss: 66.3036\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.4173 - val_loss: 66.7210\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.0514 - val_loss: 64.0910\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.5974 - val_loss: 63.5870\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.3750 - val_loss: 67.2774\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.6598 - val_loss: 65.3421\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.9577 - val_loss: 63.4363\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.1431 - val_loss: 67.2499\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.4533 - val_loss: 62.7590\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.6852 - val_loss: 62.1098\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.3204 - val_loss: 71.6211\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.7997 - val_loss: 62.1678\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.2046 - val_loss: 61.3900\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.0005 - val_loss: 60.8837\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 9ms/step - loss: 57.4421 - val_loss: 61.7672\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 73ms/step - loss: 2062.3831 - val_loss: 1052.3086\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 711.9872 - val_loss: 499.5038\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 418.9000 - val_loss: 350.2165\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 298.9566 - val_loss: 282.5197\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 7ms/step - loss: 241.6434 - val_loss: 242.9781\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.9720 - val_loss: 219.3014\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.4025 - val_loss: 206.0781\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.3322 - val_loss: 196.1182\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.5140 - val_loss: 189.6192\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.2861 - val_loss: 187.2828\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 10ms/step - loss: 174.9253 - val_loss: 182.2629\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.8939 - val_loss: 179.9522\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 168.5569 - val_loss: 179.5594\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 6ms/step - loss: 167.8262 - val_loss: 175.2759\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 10ms/step - loss: 164.4471 - val_loss: 172.1769\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 13ms/step - loss: 159.8354 - val_loss: 172.5817\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.9500 - val_loss: 166.7643\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 9ms/step - loss: 154.5703 - val_loss: 166.3690\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.0125 - val_loss: 164.7741\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.4140 - val_loss: 160.2576\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 6ms/step - loss: 146.3744 - val_loss: 156.8586\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.3634 - val_loss: 156.5522\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.5804 - val_loss: 153.1995\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.8370 - val_loss: 151.4296\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 8ms/step - loss: 138.8429 - val_loss: 149.8055\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 7ms/step - loss: 137.1727 - val_loss: 148.6773\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 7ms/step - loss: 135.1884 - val_loss: 145.9518\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 7ms/step - loss: 133.2314 - val_loss: 144.3013\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.3956 - val_loss: 142.8889\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.4075 - val_loss: 144.8737\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.5925 - val_loss: 139.9822\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3621 - val_loss: 136.2277\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 6ms/step - loss: 120.5847 - val_loss: 133.8332\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7101 - val_loss: 133.0292\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.8485 - val_loss: 132.5819\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.1663 - val_loss: 126.1825\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.2805 - val_loss: 123.9740\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 16ms/step - loss: 110.2136 - val_loss: 120.9999\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0580 - val_loss: 118.9115\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.1362 - val_loss: 119.2547\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.6528 - val_loss: 115.1613\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.7739 - val_loss: 113.8327\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.5296 - val_loss: 108.7871\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.5981 - val_loss: 107.3664\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.2976 - val_loss: 104.6299\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.6307 - val_loss: 100.1709\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.1234 - val_loss: 97.1375\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.6793 - val_loss: 95.1180\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.1913 - val_loss: 94.2057\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.3750 - val_loss: 90.6169\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.4274 - val_loss: 99.6282\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.8659 - val_loss: 87.8593\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.7103 - val_loss: 85.5164\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.2694 - val_loss: 89.1231\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.3944 - val_loss: 87.1277\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4548 - val_loss: 82.7570\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.4690 - val_loss: 80.3300\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4181 - val_loss: 82.5437\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.7668 - val_loss: 79.1305\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.7996 - val_loss: 72.4140\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.3161 - val_loss: 79.4429\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1225 - val_loss: 81.8034\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0020 - val_loss: 78.6346\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.9142 - val_loss: 67.0613\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.2683 - val_loss: 66.4896\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.8082 - val_loss: 65.0182\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.7912 - val_loss: 69.7330\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.3850 - val_loss: 62.7460\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.3424 - val_loss: 64.1855\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 6ms/step - loss: 56.1687 - val_loss: 62.0961\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.4683 - val_loss: 62.2246\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.2333 - val_loss: 61.3636\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.5374 - val_loss: 65.4488\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.1238 - val_loss: 61.1702\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.3097 - val_loss: 63.4959\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.4975 - val_loss: 62.7173\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 9ms/step - loss: 54.4343 - val_loss: 59.9257\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.8135 - val_loss: 59.2977\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.1586 - val_loss: 61.5129\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 52.0507 - val_loss: 60.8315\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.3521 - val_loss: 61.7798\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.1034 - val_loss: 59.0220\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.6325 - val_loss: 58.6055\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.5601 - val_loss: 59.5230\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 53.2881 - val_loss: 59.4910\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.6196 - val_loss: 57.7590\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.7621 - val_loss: 61.9981\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.5969 - val_loss: 59.0739\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.9023 - val_loss: 57.9944\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.8724 - val_loss: 59.4743\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.3862 - val_loss: 59.2836\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.3420 - val_loss: 57.7353\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.5014 - val_loss: 59.1275\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.9652 - val_loss: 61.3675\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.8152 - val_loss: 64.1399\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.1263 - val_loss: 59.0215\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.9567 - val_loss: 58.2571\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4776 - val_loss: 59.3470\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.6861 - val_loss: 56.9514\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.9238 - val_loss: 59.8945\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 22326.1289 - val_loss: 3044.1550\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 964.8981 - val_loss: 556.8462\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 489.9995 - val_loss: 460.8341\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 386.1956 - val_loss: 396.5514\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 344.5566 - val_loss: 365.5414\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 319.3611 - val_loss: 342.8260\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.8741 - val_loss: 322.8615\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.5810 - val_loss: 303.3297\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 272.2881 - val_loss: 288.4603\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.2993 - val_loss: 274.1889\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 250.3348 - val_loss: 261.4187\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.8433 - val_loss: 251.1601\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.8885 - val_loss: 241.8085\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.5068 - val_loss: 234.5388\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.4903 - val_loss: 228.0326\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 214.6567 - val_loss: 223.1278\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.9348 - val_loss: 217.9195\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.0591 - val_loss: 213.3785\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.3351 - val_loss: 209.2843\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.4195 - val_loss: 204.8777\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.5941 - val_loss: 201.1772\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.3805 - val_loss: 198.0486\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.5618 - val_loss: 194.9365\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.6766 - val_loss: 191.8526\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 178.3260 - val_loss: 189.1308\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.3303 - val_loss: 187.8283\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.5244 - val_loss: 184.3319\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.1890 - val_loss: 181.8525\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.7316 - val_loss: 183.1981\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.5754 - val_loss: 177.7402\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.1402 - val_loss: 175.8605\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.8086 - val_loss: 173.6934\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.4240 - val_loss: 171.9870\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.3922 - val_loss: 170.4058\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.8528 - val_loss: 168.8394\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.7456 - val_loss: 167.3952\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.0273 - val_loss: 165.7919\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.8537 - val_loss: 166.7343\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.7277 - val_loss: 162.7225\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.6490 - val_loss: 161.3636\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.5405 - val_loss: 160.0847\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.5208 - val_loss: 158.4860\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.0902 - val_loss: 157.2882\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.6659 - val_loss: 155.7301\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.9731 - val_loss: 155.5324\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 133.6903 - val_loss: 153.6168\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.5337 - val_loss: 151.8857\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.0896 - val_loss: 150.4034\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.8412 - val_loss: 150.6510\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 10ms/step - loss: 130.8373 - val_loss: 147.4961\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.1884 - val_loss: 147.8865\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.0411 - val_loss: 145.2045\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.0758 - val_loss: 143.6614\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.8741 - val_loss: 142.5068\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.8808 - val_loss: 141.6795\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1241 - val_loss: 139.9477\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.4283 - val_loss: 141.0434\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1232 - val_loss: 140.8580\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.1377 - val_loss: 136.5123\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.6853 - val_loss: 134.9693\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.6633 - val_loss: 133.7353\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.0462 - val_loss: 132.4832\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.7618 - val_loss: 131.7418\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5322 - val_loss: 129.8579\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.2952 - val_loss: 130.0856\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.0300 - val_loss: 127.5639\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5638 - val_loss: 126.1855\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 9ms/step - loss: 106.5305 - val_loss: 125.2247\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.5797 - val_loss: 123.9439\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.5427 - val_loss: 122.8773\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.8577 - val_loss: 124.0811\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.7813 - val_loss: 122.9159\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.1631 - val_loss: 120.6963\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.3211 - val_loss: 119.1906\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.6494 - val_loss: 120.0483\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.8989 - val_loss: 117.1394\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.3949 - val_loss: 116.2446\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.2077 - val_loss: 115.5157\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.9519 - val_loss: 114.6133\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5253 - val_loss: 114.0246\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6457 - val_loss: 113.1166\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5628 - val_loss: 114.1842\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.1668 - val_loss: 113.2798\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.3226 - val_loss: 116.2778\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.5674 - val_loss: 113.1874\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.5695 - val_loss: 110.2346\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.9208 - val_loss: 108.5346\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.1445 - val_loss: 107.5771\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.6807 - val_loss: 106.9910\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.6108 - val_loss: 106.9718\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.1007 - val_loss: 105.5128\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.0197 - val_loss: 106.4695\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.8082 - val_loss: 107.6372\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.6543 - val_loss: 103.7382\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.4245 - val_loss: 103.0061\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.3487 - val_loss: 104.1649\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.6637 - val_loss: 101.5002\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.4907 - val_loss: 101.6233\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.7727 - val_loss: 102.1847\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.2541 - val_loss: 99.5553\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 54085.6328 - val_loss: 25070.4668\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 12785.1387 - val_loss: 3237.9858\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 883.4930 - val_loss: 462.6052\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 427.8638 - val_loss: 328.2417\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 321.8492 - val_loss: 320.1080\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 301.0869 - val_loss: 298.0815\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 287.8285 - val_loss: 288.8898\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 276.2627 - val_loss: 273.6475\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.6461 - val_loss: 257.7679\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.5186 - val_loss: 238.5761\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.6066 - val_loss: 239.5119\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.8536 - val_loss: 225.9184\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 9ms/step - loss: 207.4561 - val_loss: 221.9986\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.8954 - val_loss: 220.9418\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.7943 - val_loss: 210.1421\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.2101 - val_loss: 207.9382\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.2191 - val_loss: 203.2340\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.0620 - val_loss: 200.2178\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.8913 - val_loss: 195.8778\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.4567 - val_loss: 191.4668\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.0567 - val_loss: 189.2105\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.5133 - val_loss: 190.6399\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.5840 - val_loss: 181.9488\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.1541 - val_loss: 178.5247\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.0092 - val_loss: 173.5426\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.2012 - val_loss: 165.8222\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.9436 - val_loss: 159.5361\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.8947 - val_loss: 154.9746\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.5967 - val_loss: 149.3994\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 10ms/step - loss: 132.3393 - val_loss: 144.8485\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.6054 - val_loss: 140.4404\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.5206 - val_loss: 139.3797\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.1627 - val_loss: 134.8692\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7374 - val_loss: 133.3637\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6608 - val_loss: 128.9776\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.2719 - val_loss: 126.7182\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.2294 - val_loss: 126.1909\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.9194 - val_loss: 128.2477\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8704 - val_loss: 126.8804\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.8689 - val_loss: 120.2731\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.2708 - val_loss: 119.2005\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.3792 - val_loss: 115.1790\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.6960 - val_loss: 115.1902\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.2325 - val_loss: 111.8289\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.4474 - val_loss: 110.3105\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6673 - val_loss: 108.2919\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.1569 - val_loss: 111.7838\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.7873 - val_loss: 106.8623\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.3335 - val_loss: 102.1315\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.4732 - val_loss: 100.6573\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 10ms/step - loss: 87.2227 - val_loss: 99.5226\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.8242 - val_loss: 99.3456\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.3031 - val_loss: 97.8070\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.1754 - val_loss: 96.9771\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.9874 - val_loss: 95.9892\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.5838 - val_loss: 95.7306\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.2802 - val_loss: 98.7965\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.5107 - val_loss: 94.1654\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 10ms/step - loss: 81.4072 - val_loss: 95.0846\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.2559 - val_loss: 93.4819\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.1169 - val_loss: 92.6663\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.8333 - val_loss: 92.5211\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1462 - val_loss: 90.9748\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1574 - val_loss: 90.6871\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.0409 - val_loss: 89.4376\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.1287 - val_loss: 88.1547\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.8895 - val_loss: 88.2004\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.9830 - val_loss: 90.8221\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.2624 - val_loss: 90.2914\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7887 - val_loss: 86.2573\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4317 - val_loss: 85.2446\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4063 - val_loss: 90.8546\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.2084 - val_loss: 84.5468\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.8367 - val_loss: 85.8831\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4843 - val_loss: 84.3985\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.2554 - val_loss: 83.2633\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.5109 - val_loss: 82.3316\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.1390 - val_loss: 85.5886\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 9ms/step - loss: 72.8981 - val_loss: 81.4958\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.3560 - val_loss: 83.9646\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.7459 - val_loss: 81.7415\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.9240 - val_loss: 85.4150\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5141 - val_loss: 80.4355\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.0645 - val_loss: 82.7551\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.8965 - val_loss: 80.1972\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.7713 - val_loss: 79.6869\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7425 - val_loss: 79.8437\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.5405 - val_loss: 78.6649\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.9889 - val_loss: 80.3955\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.9700 - val_loss: 79.2932\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.9222 - val_loss: 79.4931\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.3016 - val_loss: 77.7384\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7052 - val_loss: 77.5180\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.0708 - val_loss: 79.6728\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1701 - val_loss: 76.6772\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.4996 - val_loss: 77.0888\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.5874 - val_loss: 76.7769\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9849 - val_loss: 76.8620\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.0303 - val_loss: 75.8295\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.2664 - val_loss: 75.2616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 504.7864 - val_loss: 270.5287\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.3010 - val_loss: 245.5359\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 267.5907 - val_loss: 233.3075\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.5617 - val_loss: 224.5106\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.4118 - val_loss: 212.8860\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 232.4058 - val_loss: 202.3257\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.8746 - val_loss: 196.7340\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.8158 - val_loss: 184.1615\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.8483 - val_loss: 172.3815\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.4224 - val_loss: 163.8545\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.1753 - val_loss: 156.3464\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.9430 - val_loss: 149.8500\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.5558 - val_loss: 144.3348\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.2676 - val_loss: 141.0885\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.7079 - val_loss: 135.4522\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.9461 - val_loss: 132.2159\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.5567 - val_loss: 130.1588\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.7544 - val_loss: 128.7502\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.4083 - val_loss: 123.5584\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.8468 - val_loss: 121.1965\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.9518 - val_loss: 119.9281\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2095 - val_loss: 118.3387\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.4119 - val_loss: 116.7843\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.5146 - val_loss: 116.7101\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.3455 - val_loss: 115.6614\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.6103 - val_loss: 111.8578\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.9972 - val_loss: 113.4769\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3545 - val_loss: 109.5440\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3230 - val_loss: 106.7776\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5581 - val_loss: 104.9723\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.9765 - val_loss: 108.6105\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.5797 - val_loss: 114.5382\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8958 - val_loss: 99.5092\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.1696 - val_loss: 97.8096\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.8079 - val_loss: 98.5334\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.0256 - val_loss: 95.1325\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.6827 - val_loss: 92.6615\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.3030 - val_loss: 94.8298\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.0603 - val_loss: 92.2157\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.9438 - val_loss: 89.8095\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.6386 - val_loss: 89.0676\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.5732 - val_loss: 87.3238\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.8867 - val_loss: 85.1251\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8654 - val_loss: 85.6175\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.0401 - val_loss: 85.2664\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 9ms/step - loss: 84.9799 - val_loss: 83.6581\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.7688 - val_loss: 80.5177\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.0284 - val_loss: 86.1660\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.1645 - val_loss: 79.2326\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.8676 - val_loss: 77.9559\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.5207 - val_loss: 78.0108\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5639 - val_loss: 77.5708\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.4886 - val_loss: 83.7940\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6057 - val_loss: 75.2540\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.1162 - val_loss: 83.8102\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 9ms/step - loss: 81.2099 - val_loss: 74.7975\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5184 - val_loss: 74.4926\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.6567 - val_loss: 71.8837\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 9ms/step - loss: 74.9772 - val_loss: 72.6774\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.8351 - val_loss: 72.3068\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.5705 - val_loss: 70.3375\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.3800 - val_loss: 70.9523\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.8028 - val_loss: 74.1628\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.1821 - val_loss: 70.0479\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.0380 - val_loss: 71.9679\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.6253 - val_loss: 73.0579\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.0322 - val_loss: 74.1565\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.2665 - val_loss: 67.4600\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5631 - val_loss: 73.0711\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1516 - val_loss: 67.8288\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2605 - val_loss: 64.8485\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.1900 - val_loss: 66.6060\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.4118 - val_loss: 61.4118\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.0524 - val_loss: 63.2065\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8361 - val_loss: 60.3028\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.0778 - val_loss: 58.5388\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.5518 - val_loss: 59.2134\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9488 - val_loss: 63.9328\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.8560 - val_loss: 62.5330\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4043 - val_loss: 56.7046\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9074 - val_loss: 63.6590\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.0921 - val_loss: 57.6622\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7710 - val_loss: 54.7813\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8727 - val_loss: 56.7332\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.5739 - val_loss: 63.6685\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.6499 - val_loss: 54.3615\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.8290 - val_loss: 53.7161\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 10ms/step - loss: 62.3694 - val_loss: 53.5875\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8452 - val_loss: 56.6823\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.2262 - val_loss: 55.8274\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.0674 - val_loss: 52.7332\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.8973 - val_loss: 52.1800\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6374 - val_loss: 56.0368\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.2647 - val_loss: 51.7702\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.9365 - val_loss: 52.7308\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.4050 - val_loss: 52.1913\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.4750 - val_loss: 58.2583\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.3953 - val_loss: 52.3553\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 9ms/step - loss: 59.9608 - val_loss: 51.0446\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.7415 - val_loss: 50.6049\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1196.3098 - val_loss: 733.9888\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 590.4329 - val_loss: 476.9238\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 424.5747 - val_loss: 350.9787\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.3292 - val_loss: 296.2038\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 306.3967 - val_loss: 273.7806\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.0125 - val_loss: 258.7948\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 278.9743 - val_loss: 248.9388\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 267.8797 - val_loss: 239.0217\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 258.1183 - val_loss: 230.7286\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 246.7762 - val_loss: 233.7619\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.2171 - val_loss: 216.0066\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.5695 - val_loss: 207.4709\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.7083 - val_loss: 201.7193\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 214.5897 - val_loss: 196.8996\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.7062 - val_loss: 192.6802\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.2207 - val_loss: 185.0121\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.0717 - val_loss: 203.2093\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.1064 - val_loss: 191.8403\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.4604 - val_loss: 178.8687\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.2837 - val_loss: 183.3463\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.2902 - val_loss: 175.5566\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.0790 - val_loss: 163.8925\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.7849 - val_loss: 158.0893\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.2764 - val_loss: 158.2804\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.7160 - val_loss: 155.3147\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.1099 - val_loss: 150.6419\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.0725 - val_loss: 146.8458\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 157.5523 - val_loss: 154.4854\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 150.9818 - val_loss: 142.1591\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.1906 - val_loss: 139.8506\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.9693 - val_loss: 140.3870\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.3415 - val_loss: 134.7697\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.0504 - val_loss: 146.5979\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.3675 - val_loss: 139.1273\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.1273 - val_loss: 128.2712\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.7592 - val_loss: 123.4759\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.6587 - val_loss: 128.7419\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.3497 - val_loss: 120.7078\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.7339 - val_loss: 116.5842\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 119.5341 - val_loss: 115.2009\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.4763 - val_loss: 117.9046\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.7085 - val_loss: 121.0918\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.3546 - val_loss: 119.8571\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.6859 - val_loss: 111.6376\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.8745 - val_loss: 106.1993\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.5470 - val_loss: 113.6310\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7286 - val_loss: 104.3490\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1056 - val_loss: 104.2033\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.6715 - val_loss: 101.4968\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.7501 - val_loss: 109.0582\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.3285 - val_loss: 108.1998\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.4117 - val_loss: 97.2884\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.6052 - val_loss: 95.2015\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.6941 - val_loss: 98.2255\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.0064 - val_loss: 96.3093\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0738 - val_loss: 92.6592\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.0206 - val_loss: 92.6568\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0113 - val_loss: 89.7156\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.3131 - val_loss: 92.2902\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.6434 - val_loss: 86.9926\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.9008 - val_loss: 86.3835\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.0486 - val_loss: 82.2227\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 11ms/step - loss: 83.2030 - val_loss: 80.1474\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.1936 - val_loss: 81.8561\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5885 - val_loss: 79.6575\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7436 - val_loss: 77.5342\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7124 - val_loss: 78.8464\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.8996 - val_loss: 75.5067\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.6272 - val_loss: 75.2941\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 74.6782 - val_loss: 74.1973\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.1709 - val_loss: 81.7864\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.6694 - val_loss: 78.5123\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.1965 - val_loss: 74.9729\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2865 - val_loss: 74.9582\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.2584 - val_loss: 71.9723\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.0489 - val_loss: 70.7522\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.1183 - val_loss: 72.0678\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.3969 - val_loss: 71.2089\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.0842 - val_loss: 71.5837\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6368 - val_loss: 76.8688\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1809 - val_loss: 69.2526\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7183 - val_loss: 69.2924\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.9317 - val_loss: 77.6149\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3766 - val_loss: 71.1796\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.1315 - val_loss: 68.9586\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.6293 - val_loss: 69.5777\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.8583 - val_loss: 68.6142\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.9385 - val_loss: 71.7524\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.5608 - val_loss: 68.0691\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.4528 - val_loss: 69.4890\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.6195 - val_loss: 66.1652\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 10ms/step - loss: 67.0214 - val_loss: 67.4812\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.3999 - val_loss: 67.2064\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.3525 - val_loss: 65.8972\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 67.5821 - val_loss: 83.2817\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.7734 - val_loss: 68.8040\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.6895 - val_loss: 66.2675\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.9985 - val_loss: 66.0856\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7625 - val_loss: 67.7513\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.0122 - val_loss: 65.6990\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 77ms/step - loss: 10797.1230 - val_loss: 3974.6348\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 1697.7595 - val_loss: 436.0910\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 450.2132 - val_loss: 401.8343\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 396.6537 - val_loss: 371.7101\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 373.9566 - val_loss: 361.2852\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 359.7152 - val_loss: 349.8898\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.3455 - val_loss: 339.0675\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 329.5446 - val_loss: 332.2594\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 320.3668 - val_loss: 324.7307\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 311.3742 - val_loss: 317.4401\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 295.4778 - val_loss: 306.3228\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 283.1100 - val_loss: 291.4615\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 272.0469 - val_loss: 280.9882\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.6464 - val_loss: 267.6463\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 245.6879 - val_loss: 255.4819\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.0910 - val_loss: 243.7981\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.6189 - val_loss: 225.3728\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.2847 - val_loss: 208.6943\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 9ms/step - loss: 184.9162 - val_loss: 195.7449\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.0373 - val_loss: 183.7344\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.6050 - val_loss: 173.9789\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.3844 - val_loss: 164.8898\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.6768 - val_loss: 160.6270\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.4510 - val_loss: 151.4329\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 133.8282 - val_loss: 147.9924\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.7950 - val_loss: 142.2642\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.3699 - val_loss: 158.2351\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.4736 - val_loss: 136.9411\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.2683 - val_loss: 133.6797\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.1982 - val_loss: 150.7073\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.2553 - val_loss: 140.0044\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.6893 - val_loss: 128.7505\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6172 - val_loss: 128.8159\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.6130 - val_loss: 125.8066\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.9623 - val_loss: 134.4944\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.5293 - val_loss: 123.0930\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.3583 - val_loss: 122.2587\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.8596 - val_loss: 123.4918\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.3128 - val_loss: 123.3134\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 9ms/step - loss: 110.0870 - val_loss: 119.5155\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.5965 - val_loss: 124.0437\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.9269 - val_loss: 125.1120\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.5708 - val_loss: 118.4518\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9464 - val_loss: 117.6784\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.1739 - val_loss: 122.2523\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3639 - val_loss: 115.7114\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1090 - val_loss: 114.5916\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.5363 - val_loss: 114.1554\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6157 - val_loss: 114.6739\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.4714 - val_loss: 116.2818\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7041 - val_loss: 112.8890\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.7890 - val_loss: 112.1959\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.9258 - val_loss: 111.8185\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.3223 - val_loss: 109.6208\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.1690 - val_loss: 108.5093\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.2184 - val_loss: 106.6411\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.1185 - val_loss: 106.1172\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.8853 - val_loss: 106.7252\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.4658 - val_loss: 104.8280\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.1955 - val_loss: 101.2237\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.1508 - val_loss: 102.1377\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.7327 - val_loss: 100.3416\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0564 - val_loss: 100.3698\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.4233 - val_loss: 97.6529\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.0813 - val_loss: 95.9948\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.1284 - val_loss: 112.9824\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.0606 - val_loss: 94.3819\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.3422 - val_loss: 94.6240\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.1820 - val_loss: 92.2795\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.4667 - val_loss: 90.7928\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.0569 - val_loss: 94.6618\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.0637 - val_loss: 91.9430\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.7273 - val_loss: 87.7824\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7292 - val_loss: 86.3598\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7425 - val_loss: 86.3392\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.8599 - val_loss: 83.6712\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.2081 - val_loss: 84.6161\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.9675 - val_loss: 81.5532\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 15ms/step - loss: 79.1818 - val_loss: 80.5810\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5544 - val_loss: 85.0321\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0633 - val_loss: 78.0491\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.8056 - val_loss: 78.1746\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.5053 - val_loss: 79.2994\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.0624 - val_loss: 76.9363\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6784 - val_loss: 75.8102\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.4828 - val_loss: 74.7632\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.3084 - val_loss: 75.8938\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4301 - val_loss: 76.6835\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4566 - val_loss: 73.0790\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.5585 - val_loss: 72.9740\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.6439 - val_loss: 71.5123\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.0230 - val_loss: 71.6346\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.4981 - val_loss: 71.6348\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4463 - val_loss: 70.5493\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.1976 - val_loss: 73.1784\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3930 - val_loss: 73.4108\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1837 - val_loss: 69.2080\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.8353 - val_loss: 69.3533\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.2647 - val_loss: 69.8507\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1183 - val_loss: 69.4070\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1619.3782 - val_loss: 695.1449\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 634.6433 - val_loss: 532.1368\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 443.8633 - val_loss: 397.4155\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 350.3618 - val_loss: 338.5521\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 295.5711 - val_loss: 280.4958\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.8803 - val_loss: 257.1523\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.2433 - val_loss: 232.8485\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.7827 - val_loss: 221.7403\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 214.1181 - val_loss: 207.3641\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.5792 - val_loss: 197.9705\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 199.8020 - val_loss: 192.0366\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.0165 - val_loss: 183.0629\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.7177 - val_loss: 179.3584\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.5440 - val_loss: 171.1831\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.0424 - val_loss: 166.8042\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.4121 - val_loss: 164.2300\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.3432 - val_loss: 158.9880\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.0497 - val_loss: 162.2120\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 6ms/step - loss: 160.7814 - val_loss: 149.0936\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.2587 - val_loss: 146.5205\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 6ms/step - loss: 154.2070 - val_loss: 142.0704\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 7ms/step - loss: 150.0505 - val_loss: 138.9285\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 6ms/step - loss: 149.5251 - val_loss: 153.1676\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.3542 - val_loss: 133.7477\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 6ms/step - loss: 149.1954 - val_loss: 132.3121\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.6498 - val_loss: 143.3697\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.1006 - val_loss: 126.0616\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.4268 - val_loss: 122.4838\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.0166 - val_loss: 123.2051\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.8107 - val_loss: 143.9761\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.2119 - val_loss: 115.1124\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.3000 - val_loss: 127.3359\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 6ms/step - loss: 123.1564 - val_loss: 113.7864\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 14ms/step - loss: 126.3470 - val_loss: 122.5088\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.2529 - val_loss: 113.1568\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3177 - val_loss: 111.3539\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.4940 - val_loss: 112.9365\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.4817 - val_loss: 110.6534\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.7628 - val_loss: 126.2134\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.6467 - val_loss: 109.3781\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.5331 - val_loss: 118.9225\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 6ms/step - loss: 120.1563 - val_loss: 111.2151\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.1641 - val_loss: 109.3105\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.6536 - val_loss: 111.4374\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.6586 - val_loss: 106.6391\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.2969 - val_loss: 111.9985\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.3117 - val_loss: 108.8439\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.0799 - val_loss: 107.6764\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.3239 - val_loss: 112.1551\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.4262 - val_loss: 106.4121\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.8290 - val_loss: 116.4531\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.2006 - val_loss: 105.3625\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2027 - val_loss: 107.5119\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.7430 - val_loss: 106.9057\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7051 - val_loss: 104.8764\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8979 - val_loss: 111.0335\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 10ms/step - loss: 109.7247 - val_loss: 103.9152\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0925 - val_loss: 114.3469\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.8258 - val_loss: 104.6024\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1241 - val_loss: 104.4591\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.0492 - val_loss: 114.8417\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0257 - val_loss: 103.8307\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.4302 - val_loss: 104.4603\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.7197 - val_loss: 105.5141\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.3592 - val_loss: 106.0217\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.0042 - val_loss: 104.3292\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 11ms/step - loss: 106.4515 - val_loss: 105.4787\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 106.6154 - val_loss: 104.5418\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 7ms/step - loss: 103.6256 - val_loss: 104.8917\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0440 - val_loss: 104.6767\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1416 - val_loss: 104.2042\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.7357 - val_loss: 103.8542\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.4995 - val_loss: 103.9458\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.7511 - val_loss: 103.9275\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.8262 - val_loss: 103.6259\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.1571 - val_loss: 104.1298\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.6015 - val_loss: 103.4834\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.0434 - val_loss: 110.2777\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.2480 - val_loss: 102.7143\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.3997 - val_loss: 101.9797\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.1161 - val_loss: 103.0396\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.4411 - val_loss: 103.5517\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.8535 - val_loss: 104.8520\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.0668 - val_loss: 102.2991\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.3536 - val_loss: 122.4324\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.5155 - val_loss: 114.8521\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.1110 - val_loss: 100.4639\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.7923 - val_loss: 100.3827\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 6ms/step - loss: 97.0279 - val_loss: 102.5417\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.8648 - val_loss: 99.7411\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.4108 - val_loss: 104.3834\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.3988 - val_loss: 111.3211\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.9071 - val_loss: 101.6882\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.3519 - val_loss: 99.6181\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.7558 - val_loss: 98.7966\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.5705 - val_loss: 99.8349\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.3306 - val_loss: 98.5146\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.6686 - val_loss: 98.0169\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.0082 - val_loss: 97.0375\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.1427 - val_loss: 98.0512\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 97053.4688 - val_loss: 40835.6328\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 21621.6973 - val_loss: 7653.8486\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 3978.2014 - val_loss: 1582.1152\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 1424.8392 - val_loss: 1146.3326\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1199.8914 - val_loss: 1048.7349\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1083.0818 - val_loss: 852.9677\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 863.2294 - val_loss: 713.4894\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 707.6939 - val_loss: 586.3920\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 608.3834 - val_loss: 523.2787\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 536.6293 - val_loss: 476.0727\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 485.5078 - val_loss: 427.7217\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 445.1880 - val_loss: 395.7000\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 410.8931 - val_loss: 371.2477\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 379.6360 - val_loss: 346.4159\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 357.5467 - val_loss: 334.3346\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 336.6177 - val_loss: 307.8012\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.0913 - val_loss: 292.0473\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 297.9438 - val_loss: 280.4355\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 284.6862 - val_loss: 265.6149\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 269.8829 - val_loss: 255.2976\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.9532 - val_loss: 245.4200\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 253.2700 - val_loss: 237.5948\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 9ms/step - loss: 242.2375 - val_loss: 230.4833\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 236.5171 - val_loss: 227.0219\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.5104 - val_loss: 218.3588\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 222.7222 - val_loss: 216.9561\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.1280 - val_loss: 209.3329\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.4124 - val_loss: 202.0805\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.5219 - val_loss: 198.8713\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.9902 - val_loss: 199.3315\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 11ms/step - loss: 192.0856 - val_loss: 187.9942\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.9212 - val_loss: 183.0000\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.2451 - val_loss: 176.9214\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.2104 - val_loss: 169.7974\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.2316 - val_loss: 171.5988\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.3549 - val_loss: 159.4853\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.4160 - val_loss: 161.3640\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.9643 - val_loss: 155.0906\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 147.3863 - val_loss: 153.3360\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.6596 - val_loss: 148.1323\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.8276 - val_loss: 144.9162\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.6766 - val_loss: 141.9714\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.9223 - val_loss: 140.0360\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 131.1767 - val_loss: 133.6062\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.0677 - val_loss: 128.0065\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.3947 - val_loss: 122.1950\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.6763 - val_loss: 122.1813\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5186 - val_loss: 117.4057\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 110.6399 - val_loss: 115.5941\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.8460 - val_loss: 117.5798\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 108.8493 - val_loss: 114.9470\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.6423 - val_loss: 109.9389\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.5603 - val_loss: 110.2181\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1804 - val_loss: 109.9554\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1896 - val_loss: 116.6198\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.0486 - val_loss: 106.1159\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.2131 - val_loss: 114.2845\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.8691 - val_loss: 116.5695\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.8929 - val_loss: 106.2289\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.6837 - val_loss: 111.8870\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.3016 - val_loss: 114.4488\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.9255 - val_loss: 103.1529\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9026 - val_loss: 106.9149\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.8368 - val_loss: 104.7016\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.2738 - val_loss: 105.7091\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9616 - val_loss: 102.2760\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.5728 - val_loss: 102.7593\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.9547 - val_loss: 100.8392\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.0285 - val_loss: 101.3806\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.4092 - val_loss: 101.5127\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.7047 - val_loss: 100.0157\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.5953 - val_loss: 99.6881\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.5057 - val_loss: 99.9605\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.4939 - val_loss: 99.8387\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.8316 - val_loss: 99.0630\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.2789 - val_loss: 98.7434\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.8040 - val_loss: 98.4514\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.7904 - val_loss: 106.7074\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.7663 - val_loss: 98.2041\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.1797 - val_loss: 97.0407\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 92.6246 - val_loss: 98.5671\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.8844 - val_loss: 95.9561\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.5015 - val_loss: 96.0596\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.8751 - val_loss: 95.2949\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.9674 - val_loss: 95.9882\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 9ms/step - loss: 90.1643 - val_loss: 94.7757\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 90.2559 - val_loss: 93.8377\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.4295 - val_loss: 100.7710\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.5879 - val_loss: 92.9433\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.5401 - val_loss: 100.6718\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.7873 - val_loss: 94.1549\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.8829 - val_loss: 91.7528\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.8689 - val_loss: 91.6223\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.6230 - val_loss: 91.3289\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.0933 - val_loss: 90.8667\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.4113 - val_loss: 90.5663\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.2779 - val_loss: 90.5086\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.4541 - val_loss: 92.4191\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.0231 - val_loss: 89.5977\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.0440 - val_loss: 89.3957\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 71164.5312 - val_loss: 28495.0742\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 13689.5020 - val_loss: 3812.1379\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 1686.5172 - val_loss: 699.6572\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 606.5718 - val_loss: 607.7473\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 561.2050 - val_loss: 565.8470\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 522.9601 - val_loss: 526.3087\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 488.7839 - val_loss: 494.1645\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 458.4212 - val_loss: 460.9968\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 428.1772 - val_loss: 431.4177\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 401.7841 - val_loss: 402.0986\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 376.5158 - val_loss: 376.6521\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 354.3159 - val_loss: 351.8076\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 332.3279 - val_loss: 328.5078\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 312.7973 - val_loss: 307.0358\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 293.6336 - val_loss: 290.3154\n",
      "Epoch 16/100\n",
      "23/23 - 1s - 23ms/step - loss: 279.6985 - val_loss: 277.2767\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 268.9698 - val_loss: 269.1794\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.5279 - val_loss: 263.3134\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.4745 - val_loss: 258.8267\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 253.9700 - val_loss: 254.8329\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.6321 - val_loss: 251.6692\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 246.6902 - val_loss: 248.4667\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 7ms/step - loss: 243.7573 - val_loss: 245.7759\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 241.0839 - val_loss: 243.0285\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.5053 - val_loss: 240.8635\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 236.1003 - val_loss: 238.6898\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 234.1724 - val_loss: 236.8718\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.9211 - val_loss: 234.9364\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.1194 - val_loss: 233.1651\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 227.6557 - val_loss: 231.0429\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.7032 - val_loss: 229.1903\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 224.2620 - val_loss: 227.4156\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.1047 - val_loss: 225.9938\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.6583 - val_loss: 223.7928\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 220.3470 - val_loss: 222.2092\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.1957 - val_loss: 220.3889\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.5293 - val_loss: 218.7651\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.0508 - val_loss: 217.1848\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.7519 - val_loss: 215.7408\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.8470 - val_loss: 214.3506\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.1243 - val_loss: 213.0032\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.5907 - val_loss: 211.8890\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.4345 - val_loss: 210.7208\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.3252 - val_loss: 209.3096\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.9371 - val_loss: 208.0141\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.9708 - val_loss: 206.6523\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.5580 - val_loss: 206.3253\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.6883 - val_loss: 204.6407\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.2791 - val_loss: 203.6257\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.5534 - val_loss: 202.1059\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.4669 - val_loss: 201.1863\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.3399 - val_loss: 200.0262\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.5017 - val_loss: 199.0615\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.6687 - val_loss: 198.1611\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.9531 - val_loss: 197.8756\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 195.6116 - val_loss: 196.1838\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.6243 - val_loss: 195.2630\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.8706 - val_loss: 194.3762\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.5766 - val_loss: 193.6147\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.3327 - val_loss: 192.6946\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.1898 - val_loss: 191.3245\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.3389 - val_loss: 190.2970\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.0244 - val_loss: 190.6678\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.5377 - val_loss: 188.0480\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 186.8128 - val_loss: 187.2546\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.9464 - val_loss: 185.9522\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.4356 - val_loss: 184.0452\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.9492 - val_loss: 183.2915\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.1396 - val_loss: 181.8772\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.2112 - val_loss: 180.7870\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.3635 - val_loss: 179.2603\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.3256 - val_loss: 177.2336\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.6333 - val_loss: 175.6564\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.0031 - val_loss: 173.3854\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.8711 - val_loss: 170.6606\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 9ms/step - loss: 172.2807 - val_loss: 169.0401\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.9564 - val_loss: 168.1390\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.4478 - val_loss: 166.6043\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.9448 - val_loss: 163.3489\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.3027 - val_loss: 166.0632\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.6465 - val_loss: 159.9877\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.5837 - val_loss: 158.4731\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.5475 - val_loss: 159.4725\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.2419 - val_loss: 153.9952\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.6461 - val_loss: 150.9100\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.3307 - val_loss: 142.5676\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.7477 - val_loss: 135.4969\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.2904 - val_loss: 128.0300\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.8623 - val_loss: 127.3088\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.0238 - val_loss: 118.4740\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.8023 - val_loss: 115.8952\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.0311 - val_loss: 112.9360\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.6039 - val_loss: 113.5323\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.0612 - val_loss: 112.5230\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1848 - val_loss: 109.6091\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.6519 - val_loss: 108.4287\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3414 - val_loss: 108.0520\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.5136 - val_loss: 106.9535\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.0426 - val_loss: 107.2609\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.7162 - val_loss: 105.3541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 341.8888 - val_loss: 208.8530\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.0692 - val_loss: 190.1430\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.9710 - val_loss: 175.2960\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.4808 - val_loss: 160.1873\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.3019 - val_loss: 147.6545\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.3760 - val_loss: 143.4288\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 141.9700 - val_loss: 136.9948\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.1647 - val_loss: 119.6531\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.9706 - val_loss: 110.7163\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.9281 - val_loss: 106.7787\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.5026 - val_loss: 99.4706\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.0705 - val_loss: 94.3559\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.8446 - val_loss: 91.4757\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.8878 - val_loss: 95.9186\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.9237 - val_loss: 87.2059\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.7463 - val_loss: 85.4337\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.1003 - val_loss: 85.3310\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.0430 - val_loss: 84.9352\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4566 - val_loss: 82.1650\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.8323 - val_loss: 81.4399\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.9503 - val_loss: 84.2263\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 10ms/step - loss: 77.7537 - val_loss: 84.6859\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.8686 - val_loss: 80.8255\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.2428 - val_loss: 85.2082\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.5728 - val_loss: 80.2533\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.2097 - val_loss: 80.3510\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.0366 - val_loss: 80.7869\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.0745 - val_loss: 82.3562\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6372 - val_loss: 86.1414\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 7ms/step - loss: 71.0293 - val_loss: 82.5045\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.0498 - val_loss: 82.1127\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.0849 - val_loss: 81.3756\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2976 - val_loss: 80.7617\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.7838 - val_loss: 87.3841\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.4789 - val_loss: 80.6324\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.8138 - val_loss: 79.0030\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.2231 - val_loss: 80.0414\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7998 - val_loss: 81.5703\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.6693 - val_loss: 79.7379\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.2632 - val_loss: 79.3346\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.1967 - val_loss: 79.2645\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.9424 - val_loss: 77.3358\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.8731 - val_loss: 81.3496\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.0909 - val_loss: 76.6452\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.9221 - val_loss: 76.7442\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.6378 - val_loss: 81.2882\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.1815 - val_loss: 77.1277\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.4242 - val_loss: 76.1759\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7153 - val_loss: 76.0900\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.7047 - val_loss: 76.4267\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.4948 - val_loss: 75.5837\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.3661 - val_loss: 76.9488\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8376 - val_loss: 75.9448\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.5279 - val_loss: 87.9603\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 6ms/step - loss: 67.3572 - val_loss: 74.9829\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 6ms/step - loss: 64.3765 - val_loss: 78.6257\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.6541 - val_loss: 74.9927\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.2183 - val_loss: 77.0704\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.3054 - val_loss: 77.2787\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 14ms/step - loss: 64.1939 - val_loss: 76.6486\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.8168 - val_loss: 75.4006\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.8964 - val_loss: 74.5255\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9916 - val_loss: 76.7650\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.8585 - val_loss: 80.9592\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.0161 - val_loss: 79.3307\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.2474 - val_loss: 74.7304\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.6242 - val_loss: 74.8287\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.6053 - val_loss: 75.2566\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.8191 - val_loss: 78.9475\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.6645 - val_loss: 78.1110\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.2767 - val_loss: 75.9414\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 6ms/step - loss: 71.6310 - val_loss: 80.3218\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.2314 - val_loss: 73.4924\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.1360 - val_loss: 73.0606\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.8733 - val_loss: 76.1330\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.0354 - val_loss: 72.9269\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7786 - val_loss: 78.3848\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.8604 - val_loss: 74.2328\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.2895 - val_loss: 74.0370\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1431 - val_loss: 93.8086\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.7040 - val_loss: 72.9050\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.9139 - val_loss: 74.9466\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.5449 - val_loss: 75.0285\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.8739 - val_loss: 80.7289\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.1379 - val_loss: 73.8145\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 7ms/step - loss: 63.2119 - val_loss: 73.2003\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.3553 - val_loss: 74.8624\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8226 - val_loss: 72.2498\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.5119 - val_loss: 72.1448\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.3563 - val_loss: 74.8194\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 9ms/step - loss: 61.8950 - val_loss: 71.9688\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.4195 - val_loss: 75.4950\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.1878 - val_loss: 75.5334\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.4676 - val_loss: 72.0824\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.5835 - val_loss: 73.7450\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.3993 - val_loss: 75.9283\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.6497 - val_loss: 71.7850\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9095 - val_loss: 71.2475\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8870 - val_loss: 75.5935\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7826 - val_loss: 70.2373\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 592.6017 - val_loss: 348.2024\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 279.4269 - val_loss: 210.3884\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.0735 - val_loss: 203.7813\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.7890 - val_loss: 198.6839\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.8456 - val_loss: 195.0205\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.3850 - val_loss: 192.0006\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.4596 - val_loss: 189.4516\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.8826 - val_loss: 186.7086\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.5275 - val_loss: 184.3352\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.0512 - val_loss: 182.4268\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.3529 - val_loss: 179.9797\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 199.6714 - val_loss: 177.9060\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.5500 - val_loss: 175.4277\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.8292 - val_loss: 173.1518\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.2408 - val_loss: 170.4966\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.6293 - val_loss: 168.1354\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.3288 - val_loss: 165.2423\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.9099 - val_loss: 162.5539\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.7094 - val_loss: 159.5617\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.0602 - val_loss: 156.9325\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.1916 - val_loss: 155.0194\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.2663 - val_loss: 151.7168\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.3160 - val_loss: 148.8724\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.5265 - val_loss: 145.7934\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.2857 - val_loss: 142.9206\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.3047 - val_loss: 139.7439\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.1481 - val_loss: 138.3885\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.9113 - val_loss: 134.4486\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.7379 - val_loss: 132.5002\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.4597 - val_loss: 129.6023\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.4666 - val_loss: 127.3331\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.2762 - val_loss: 124.6785\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.2308 - val_loss: 121.6639\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.2296 - val_loss: 121.0905\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.4032 - val_loss: 118.6422\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 126.5340 - val_loss: 115.6559\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.5473 - val_loss: 115.4305\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.4886 - val_loss: 113.2026\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.5772 - val_loss: 112.5697\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.7128 - val_loss: 110.0661\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.9988 - val_loss: 108.3848\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5675 - val_loss: 105.7076\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.4941 - val_loss: 103.1161\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.1550 - val_loss: 105.3642\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9376 - val_loss: 100.6772\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.0350 - val_loss: 97.7849\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.8248 - val_loss: 96.7222\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.8105 - val_loss: 96.0152\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 89.1745 - val_loss: 95.7507\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.3315 - val_loss: 90.5728\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.6413 - val_loss: 90.0860\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7910 - val_loss: 88.0449\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.0407 - val_loss: 83.5183\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.7502 - val_loss: 84.5232\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.8107 - val_loss: 84.4153\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.8751 - val_loss: 82.2403\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.5195 - val_loss: 76.8605\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.2855 - val_loss: 74.0662\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8396 - val_loss: 72.7560\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.4971 - val_loss: 72.2488\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1425 - val_loss: 70.0641\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3017 - val_loss: 72.9818\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.8163 - val_loss: 67.5820\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.1773 - val_loss: 65.9825\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.2125 - val_loss: 66.2026\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.1896 - val_loss: 65.2542\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 57.2070 - val_loss: 64.6687\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.0404 - val_loss: 62.9076\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.0758 - val_loss: 62.5320\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.3165 - val_loss: 64.8652\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.6411 - val_loss: 61.6093\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.2109 - val_loss: 62.4122\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.0607 - val_loss: 63.9999\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.8952 - val_loss: 61.2729\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.5387 - val_loss: 59.8005\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.7715 - val_loss: 62.0138\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 9ms/step - loss: 53.0105 - val_loss: 59.9097\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.1861 - val_loss: 59.6026\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.1271 - val_loss: 58.2561\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.9486 - val_loss: 58.7392\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.3625 - val_loss: 57.4565\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.2062 - val_loss: 59.5683\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.0946 - val_loss: 59.0105\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.2203 - val_loss: 58.1318\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.9514 - val_loss: 57.2847\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.0652 - val_loss: 56.8832\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.9165 - val_loss: 57.3041\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4693 - val_loss: 59.9390\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.9900 - val_loss: 56.4716\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.2693 - val_loss: 56.8976\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4433 - val_loss: 56.3892\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.5068 - val_loss: 62.5244\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.6352 - val_loss: 57.6734\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.7577 - val_loss: 56.5848\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4475 - val_loss: 55.9988\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.4574 - val_loss: 56.7036\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.2902 - val_loss: 57.2594\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.3622 - val_loss: 55.2069\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.0243 - val_loss: 57.4234\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.2817 - val_loss: 57.0222\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 476.0859 - val_loss: 266.0009\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 260.2701 - val_loss: 234.0687\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.7149 - val_loss: 217.4515\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.1272 - val_loss: 196.5174\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.4422 - val_loss: 184.0406\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.7599 - val_loss: 170.6682\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.4031 - val_loss: 162.5251\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.1294 - val_loss: 156.9011\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 6ms/step - loss: 167.8217 - val_loss: 150.4715\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 7ms/step - loss: 157.3638 - val_loss: 140.1785\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 7ms/step - loss: 146.3244 - val_loss: 131.8572\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 7ms/step - loss: 135.9299 - val_loss: 121.8526\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 7ms/step - loss: 122.9364 - val_loss: 112.8201\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 7ms/step - loss: 112.8117 - val_loss: 103.2958\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 7ms/step - loss: 101.8484 - val_loss: 95.7758\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 6ms/step - loss: 93.3449 - val_loss: 89.1833\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.4006 - val_loss: 88.4009\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.5287 - val_loss: 77.8318\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.3174 - val_loss: 78.2948\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.4776 - val_loss: 73.2678\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.3944 - val_loss: 73.4818\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.6575 - val_loss: 73.3583\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.1756 - val_loss: 70.7055\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.2952 - val_loss: 72.6901\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.6512 - val_loss: 69.8635\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.7338 - val_loss: 69.1968\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.7452 - val_loss: 68.1213\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.4554 - val_loss: 68.4939\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.8841 - val_loss: 67.0939\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.6855 - val_loss: 66.5290\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.3389 - val_loss: 66.4427\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1412 - val_loss: 65.9182\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1632 - val_loss: 65.3793\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.5550 - val_loss: 65.0054\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.5377 - val_loss: 64.3859\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.0961 - val_loss: 63.7455\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.4463 - val_loss: 63.6404\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6130 - val_loss: 62.5366\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.3649 - val_loss: 70.7020\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 9ms/step - loss: 58.8830 - val_loss: 62.2018\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.4908 - val_loss: 63.9720\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.4022 - val_loss: 62.8142\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.7925 - val_loss: 60.9469\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.9029 - val_loss: 63.3092\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.0223 - val_loss: 60.0226\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.4199 - val_loss: 62.1108\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.5337 - val_loss: 59.1507\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.1605 - val_loss: 59.2196\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.6465 - val_loss: 58.9570\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.9343 - val_loss: 58.0874\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.4040 - val_loss: 58.2585\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.1955 - val_loss: 57.9585\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.7689 - val_loss: 59.4377\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.0025 - val_loss: 64.2898\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.3375 - val_loss: 57.0430\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.6735 - val_loss: 55.8135\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 52.6031 - val_loss: 56.4588\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.1555 - val_loss: 55.0624\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.2656 - val_loss: 56.4177\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.2666 - val_loss: 54.6809\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.8770 - val_loss: 54.6169\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.1631 - val_loss: 55.6763\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.6811 - val_loss: 53.7229\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.1076 - val_loss: 53.9667\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.4688 - val_loss: 56.9436\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.0568 - val_loss: 54.6410\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 52.3825 - val_loss: 53.1461\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.5632 - val_loss: 53.7595\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.0234 - val_loss: 53.3840\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.8283 - val_loss: 54.3658\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.7677 - val_loss: 52.4116\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.0290 - val_loss: 52.2913\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.3413 - val_loss: 53.3750\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.3318 - val_loss: 52.1764\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.0388 - val_loss: 52.3770\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.9996 - val_loss: 52.1295\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 9ms/step - loss: 49.1975 - val_loss: 51.9349\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.6517 - val_loss: 52.3559\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.6951 - val_loss: 52.1342\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.7369 - val_loss: 52.2719\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.1846 - val_loss: 51.6954\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.1265 - val_loss: 56.9882\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.3147 - val_loss: 53.0341\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.0233 - val_loss: 50.8735\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.5844 - val_loss: 54.2815\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 50.8014 - val_loss: 54.0774\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.3378 - val_loss: 54.3689\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 6ms/step - loss: 47.9438 - val_loss: 51.6842\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 7ms/step - loss: 48.3152 - val_loss: 51.5108\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 7ms/step - loss: 47.9054 - val_loss: 51.0742\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 6ms/step - loss: 48.0874 - val_loss: 51.0056\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.0360 - val_loss: 54.3247\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.1854 - val_loss: 51.2094\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 47.8850 - val_loss: 50.9041\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.2535 - val_loss: 52.3594\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 6ms/step - loss: 50.0594 - val_loss: 50.6993\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 7ms/step - loss: 47.4724 - val_loss: 50.8019\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 7ms/step - loss: 48.5496 - val_loss: 53.1511\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 7ms/step - loss: 47.8061 - val_loss: 53.2576\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.7915 - val_loss: 52.9161\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 72ms/step - loss: 392.9948 - val_loss: 410.1440\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 319.2436 - val_loss: 348.3088\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 288.8256 - val_loss: 304.9760\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.2719 - val_loss: 282.8605\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.7159 - val_loss: 269.9588\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.9985 - val_loss: 263.4265\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.0708 - val_loss: 246.0749\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.1958 - val_loss: 238.8201\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.4427 - val_loss: 229.5796\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 209.6758 - val_loss: 224.1536\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 6ms/step - loss: 201.2607 - val_loss: 215.1826\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 6ms/step - loss: 195.1548 - val_loss: 209.5842\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 6ms/step - loss: 187.4828 - val_loss: 202.0448\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.3789 - val_loss: 194.9482\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.6847 - val_loss: 188.9624\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.0948 - val_loss: 182.5816\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.2618 - val_loss: 187.4583\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.2049 - val_loss: 183.3492\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.6493 - val_loss: 164.6877\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.1481 - val_loss: 159.8950\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.4280 - val_loss: 153.5617\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.3230 - val_loss: 149.8667\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.1628 - val_loss: 144.0287\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.4086 - val_loss: 136.0207\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.4558 - val_loss: 131.9024\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.4755 - val_loss: 126.3711\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.8531 - val_loss: 119.9466\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5871 - val_loss: 115.3802\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0170 - val_loss: 112.1209\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.8892 - val_loss: 112.4304\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.1056 - val_loss: 102.7928\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 11ms/step - loss: 93.1566 - val_loss: 101.0889\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.0016 - val_loss: 103.4153\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.5979 - val_loss: 97.1049\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8752 - val_loss: 96.5858\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.0456 - val_loss: 101.4518\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.6726 - val_loss: 94.1448\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.1747 - val_loss: 89.2207\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.7737 - val_loss: 87.2588\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1596 - val_loss: 87.3312\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5035 - val_loss: 86.4365\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.8107 - val_loss: 84.6727\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4839 - val_loss: 79.9097\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.7314 - val_loss: 79.2350\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.8371 - val_loss: 79.5381\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.8350 - val_loss: 75.3667\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.9424 - val_loss: 83.1768\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.4425 - val_loss: 84.1532\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.2041 - val_loss: 72.6604\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.4386 - val_loss: 71.3525\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.2717 - val_loss: 71.2078\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3624 - val_loss: 72.6051\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8669 - val_loss: 71.4873\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.0856 - val_loss: 68.1900\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.6994 - val_loss: 69.0581\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.9485 - val_loss: 75.3028\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.6757 - val_loss: 81.7216\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.4766 - val_loss: 66.9385\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.7791 - val_loss: 67.4728\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.4217 - val_loss: 67.7773\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.6671 - val_loss: 67.1882\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.7981 - val_loss: 68.9561\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.8925 - val_loss: 67.2257\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.4998 - val_loss: 69.1239\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.4026 - val_loss: 66.0262\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.6056 - val_loss: 64.9540\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.4749 - val_loss: 64.7826\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.9284 - val_loss: 64.6222\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.6528 - val_loss: 66.2440\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 51.9926 - val_loss: 69.2669\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 52.1892 - val_loss: 72.9350\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.7968 - val_loss: 67.5221\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 48.5014 - val_loss: 66.2540\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 49.4348 - val_loss: 64.1549\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 47.4187 - val_loss: 65.2108\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 46.2197 - val_loss: 63.9138\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 46.6374 - val_loss: 63.5473\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 45.2304 - val_loss: 63.9819\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 45.7900 - val_loss: 66.1786\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 10ms/step - loss: 48.1065 - val_loss: 64.1796\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 45.6430 - val_loss: 64.8763\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 6ms/step - loss: 44.8309 - val_loss: 64.3481\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 45.2726 - val_loss: 64.9520\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 44.6985 - val_loss: 63.9605\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.8366 - val_loss: 63.7377\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 44.7428 - val_loss: 63.3624\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.7736 - val_loss: 63.7858\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.5303 - val_loss: 63.9701\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.8774 - val_loss: 64.4479\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 42.9240 - val_loss: 64.2670\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.3601 - val_loss: 62.3122\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.9478 - val_loss: 66.4113\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 44.0322 - val_loss: 62.4131\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 44.3619 - val_loss: 63.1323\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 42.2490 - val_loss: 62.0255\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 42.7994 - val_loss: 62.6258\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 43.5375 - val_loss: 63.5936\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 42.2372 - val_loss: 62.1790\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 42.9892 - val_loss: 65.1798\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 44.5728 - val_loss: 68.7949\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 1130.0065 - val_loss: 490.5425\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 345.3123 - val_loss: 320.2088\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 306.8098 - val_loss: 302.3840\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 292.8222 - val_loss: 289.5312\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 281.0039 - val_loss: 279.0266\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 272.8148 - val_loss: 269.5037\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.1121 - val_loss: 255.7640\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 248.9145 - val_loss: 247.5249\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.4071 - val_loss: 234.0323\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.6423 - val_loss: 225.9302\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.5643 - val_loss: 217.2139\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.3517 - val_loss: 221.5338\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 8ms/step - loss: 190.4020 - val_loss: 199.6990\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.0720 - val_loss: 176.2428\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.8951 - val_loss: 166.0014\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.3395 - val_loss: 160.2452\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.7692 - val_loss: 150.8373\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.4691 - val_loss: 148.2475\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.0299 - val_loss: 141.1857\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 128.6380 - val_loss: 140.0379\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.3848 - val_loss: 143.6317\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.0793 - val_loss: 145.1844\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.6812 - val_loss: 140.2459\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.7580 - val_loss: 137.3447\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1234 - val_loss: 143.6396\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.4318 - val_loss: 131.9719\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.4493 - val_loss: 132.0384\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.7446 - val_loss: 140.3188\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6614 - val_loss: 129.4404\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8481 - val_loss: 130.3164\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.5916 - val_loss: 134.0361\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1012 - val_loss: 156.9054\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.9531 - val_loss: 131.0887\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5562 - val_loss: 137.0796\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6932 - val_loss: 128.2577\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.0754 - val_loss: 131.0438\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.3660 - val_loss: 128.1283\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.3452 - val_loss: 127.3496\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.3206 - val_loss: 132.4177\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.2183 - val_loss: 127.0746\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.7027 - val_loss: 131.1568\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2297 - val_loss: 126.0350\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.1682 - val_loss: 136.6901\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.4474 - val_loss: 125.0009\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.8764 - val_loss: 124.7688\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.0380 - val_loss: 155.2550\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.5145 - val_loss: 125.3045\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.6019 - val_loss: 134.9554\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.0490 - val_loss: 125.7475\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.1177 - val_loss: 166.5232\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.5487 - val_loss: 127.2505\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.9057 - val_loss: 132.0783\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.1488 - val_loss: 123.2645\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6472 - val_loss: 124.9691\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3064 - val_loss: 137.6809\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.2082 - val_loss: 122.9349\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.2163 - val_loss: 123.1331\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.7040 - val_loss: 127.4034\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2693 - val_loss: 135.3623\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.1986 - val_loss: 131.8871\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.3372 - val_loss: 123.4114\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0372 - val_loss: 122.3505\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.5863 - val_loss: 126.1780\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.5094 - val_loss: 147.5052\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.6802 - val_loss: 122.0160\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5283 - val_loss: 123.5463\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.2375 - val_loss: 125.5396\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.5049 - val_loss: 128.6228\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.0451 - val_loss: 124.9227\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.6613 - val_loss: 121.5753\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.6133 - val_loss: 122.1975\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1448 - val_loss: 133.3449\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5035 - val_loss: 126.2901\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.4300 - val_loss: 120.9307\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 11ms/step - loss: 114.5636 - val_loss: 121.9135\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3861 - val_loss: 131.7498\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 7ms/step - loss: 113.9122 - val_loss: 126.4592\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.9620 - val_loss: 133.8137\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.5791 - val_loss: 120.3811\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.2002 - val_loss: 134.6177\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.5665 - val_loss: 135.0170\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.4964 - val_loss: 127.3800\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 106.7624 - val_loss: 128.2985\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2074 - val_loss: 120.8769\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 10ms/step - loss: 112.1512 - val_loss: 120.0889\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2083 - val_loss: 123.6595\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.2599 - val_loss: 125.0903\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.7069 - val_loss: 137.1725\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 107.6786 - val_loss: 119.4030\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.7457 - val_loss: 129.1134\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.1175 - val_loss: 119.3155\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.9365 - val_loss: 120.9093\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.9916 - val_loss: 123.1349\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.2630 - val_loss: 133.2756\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.5894 - val_loss: 145.4094\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.9222 - val_loss: 119.8871\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.9989 - val_loss: 124.0154\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.0173 - val_loss: 118.8343\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.4291 - val_loss: 128.5118\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.3847 - val_loss: 125.4660\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 102ms/step - loss: 39211.7969 - val_loss: 25494.5996\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 19229.9746 - val_loss: 14298.6768\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 11460.5322 - val_loss: 8903.5986\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 6175.8545 - val_loss: 3925.6433\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 2702.1516 - val_loss: 1925.9264\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1465.1110 - val_loss: 1075.9260\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 872.4728 - val_loss: 709.0450\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 7ms/step - loss: 619.7901 - val_loss: 555.5423\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 6ms/step - loss: 483.0600 - val_loss: 445.8397\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 397.4313 - val_loss: 377.6375\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.9497 - val_loss: 336.3653\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 311.8532 - val_loss: 311.0174\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 293.3367 - val_loss: 294.4919\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 285.5639 - val_loss: 283.0433\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 286.7010 - val_loss: 276.8385\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 272.5599 - val_loss: 266.5735\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 261.8032 - val_loss: 260.8718\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.1914 - val_loss: 271.0466\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 257.6316 - val_loss: 262.2063\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 255.4208 - val_loss: 251.0252\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 244.6344 - val_loss: 243.4551\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 239.0586 - val_loss: 237.8333\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.4724 - val_loss: 235.9023\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.0632 - val_loss: 230.9520\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.9725 - val_loss: 226.6785\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.8141 - val_loss: 225.2024\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.2763 - val_loss: 220.1405\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 7ms/step - loss: 227.3184 - val_loss: 221.9782\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.8910 - val_loss: 212.7895\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.9139 - val_loss: 213.1266\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 213.1093 - val_loss: 217.5020\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 212.3465 - val_loss: 205.4605\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.3824 - val_loss: 200.8089\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 203.1300 - val_loss: 198.5859\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.8740 - val_loss: 200.0984\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 200.3354 - val_loss: 192.6335\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.3940 - val_loss: 191.1398\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.2218 - val_loss: 196.1241\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.1611 - val_loss: 201.8951\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.7634 - val_loss: 183.5635\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.4604 - val_loss: 182.9183\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.0273 - val_loss: 179.7575\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.2107 - val_loss: 177.7481\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.8734 - val_loss: 175.4659\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.5413 - val_loss: 172.4088\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.2474 - val_loss: 170.2000\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0776 - val_loss: 168.2644\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.9688 - val_loss: 166.3536\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.8623 - val_loss: 164.4305\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.1592 - val_loss: 165.2412\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.7028 - val_loss: 161.3529\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.9412 - val_loss: 160.9779\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.5955 - val_loss: 157.2590\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 164.8715 - val_loss: 154.8892\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.4841 - val_loss: 155.0833\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.5873 - val_loss: 150.3351\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.4323 - val_loss: 151.2661\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 157.5466 - val_loss: 147.8394\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.8832 - val_loss: 144.8663\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 153.8311 - val_loss: 143.5324\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.3330 - val_loss: 141.0413\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.9317 - val_loss: 139.6701\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.9709 - val_loss: 138.8116\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.7797 - val_loss: 133.7231\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.0701 - val_loss: 135.0168\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.3480 - val_loss: 143.7831\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.4750 - val_loss: 126.6664\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2774 - val_loss: 122.5394\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.8993 - val_loss: 128.5043\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 135.4456 - val_loss: 117.2177\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.4212 - val_loss: 114.0989\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.1532 - val_loss: 112.9360\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.3342 - val_loss: 110.1242\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.1623 - val_loss: 115.0684\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.0419 - val_loss: 105.8946\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.7885 - val_loss: 104.1827\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.3222 - val_loss: 104.5180\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.6524 - val_loss: 100.0172\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.1393 - val_loss: 98.2453\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.4334 - val_loss: 96.6510\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.3850 - val_loss: 94.1495\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.0451 - val_loss: 94.3573\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1049 - val_loss: 95.5452\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.0488 - val_loss: 94.8594\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.4327 - val_loss: 91.8555\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 106.1322 - val_loss: 90.6074\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.9207 - val_loss: 92.2320\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.7315 - val_loss: 91.9821\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.7182 - val_loss: 89.9140\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.3271 - val_loss: 97.2146\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.5954 - val_loss: 92.2491\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.7553 - val_loss: 99.0887\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1184 - val_loss: 91.0226\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.4277 - val_loss: 87.7388\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 96.6319 - val_loss: 88.3626\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.8591 - val_loss: 97.8371\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.9798 - val_loss: 88.6340\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.5802 - val_loss: 88.5668\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.7874 - val_loss: 86.3143\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.4291 - val_loss: 85.8986\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 90548.8906 - val_loss: 15206.2861\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 5095.4751 - val_loss: 2266.6567\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 2702.1978 - val_loss: 1839.3704\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 2141.3464 - val_loss: 1670.6265\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 1985.6903 - val_loss: 1554.8323\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1854.5925 - val_loss: 1457.6752\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 1733.0641 - val_loss: 1366.1213\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1614.5399 - val_loss: 1280.5808\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 9ms/step - loss: 1501.6312 - val_loss: 1196.9008\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 1397.8373 - val_loss: 1121.7084\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 1301.6165 - val_loss: 1050.9418\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 1211.9899 - val_loss: 984.2312\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 1133.8806 - val_loss: 921.0854\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 1060.9644 - val_loss: 871.0359\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 984.0565 - val_loss: 811.2757\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 915.2451 - val_loss: 765.6230\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 857.2094 - val_loss: 720.0322\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 800.5726 - val_loss: 678.8087\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 737.4358 - val_loss: 606.6804\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 646.8886 - val_loss: 561.1226\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 591.6085 - val_loss: 534.5117\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 552.0391 - val_loss: 485.3551\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 510.8419 - val_loss: 458.2635\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 483.7270 - val_loss: 446.4314\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 458.9863 - val_loss: 414.5544\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 10ms/step - loss: 435.1529 - val_loss: 404.4778\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 414.5930 - val_loss: 382.5908\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 396.4692 - val_loss: 369.6658\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 381.4179 - val_loss: 359.5713\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 366.1375 - val_loss: 340.9414\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 7ms/step - loss: 349.5517 - val_loss: 327.4752\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 338.5285 - val_loss: 332.1434\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 11ms/step - loss: 329.8393 - val_loss: 308.3672\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 313.3882 - val_loss: 294.2809\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 300.8369 - val_loss: 307.3170\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 297.0066 - val_loss: 278.1493\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 281.4977 - val_loss: 268.3275\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 270.4624 - val_loss: 261.9505\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 262.4891 - val_loss: 254.0501\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 254.8838 - val_loss: 245.0450\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 247.1033 - val_loss: 243.7681\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.4098 - val_loss: 236.4073\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 234.3480 - val_loss: 224.8309\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 227.9540 - val_loss: 220.9265\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.6361 - val_loss: 214.2091\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.0346 - val_loss: 211.4706\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.5056 - val_loss: 217.3680\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.0211 - val_loss: 200.9578\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.1962 - val_loss: 197.4390\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 197.7271 - val_loss: 192.9910\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.2725 - val_loss: 196.5610\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 189.3545 - val_loss: 188.3228\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.6579 - val_loss: 179.5847\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 182.7076 - val_loss: 179.2109\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.3395 - val_loss: 173.1256\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 174.1338 - val_loss: 175.5498\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.6661 - val_loss: 168.8741\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.3960 - val_loss: 167.8074\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.9527 - val_loss: 164.5198\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.3558 - val_loss: 153.7020\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.5600 - val_loss: 148.7460\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.3403 - val_loss: 143.2999\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.2030 - val_loss: 139.2475\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.2389 - val_loss: 137.8012\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.8214 - val_loss: 133.5163\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.6226 - val_loss: 131.9470\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.3104 - val_loss: 129.4261\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.2508 - val_loss: 127.6976\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.4206 - val_loss: 139.4402\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 131.3396 - val_loss: 125.9775\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.4269 - val_loss: 124.5324\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.1319 - val_loss: 122.8555\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.5092 - val_loss: 129.0611\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.9699 - val_loss: 121.2864\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.8865 - val_loss: 120.7837\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 10ms/step - loss: 121.0747 - val_loss: 121.1505\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6920 - val_loss: 120.1406\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.1686 - val_loss: 119.3102\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.3834 - val_loss: 118.2683\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.1696 - val_loss: 125.8344\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 118.1905 - val_loss: 118.4889\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.1431 - val_loss: 120.2482\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 6ms/step - loss: 114.8375 - val_loss: 119.9923\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 7ms/step - loss: 113.9055 - val_loss: 118.0941\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 6ms/step - loss: 114.8507 - val_loss: 120.1485\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.8552 - val_loss: 118.3900\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.4749 - val_loss: 119.2422\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.2412 - val_loss: 117.2152\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.8681 - val_loss: 116.0360\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6059 - val_loss: 116.5916\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.2906 - val_loss: 117.0921\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.3163 - val_loss: 116.3258\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.2303 - val_loss: 116.1819\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.9475 - val_loss: 117.1619\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.0811 - val_loss: 117.2199\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.9421 - val_loss: 117.3128\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.1609 - val_loss: 116.2617\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.9605 - val_loss: 115.9800\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.2343 - val_loss: 116.3537\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.0045 - val_loss: 116.5355\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 224168.2031 - val_loss: 108459.6406\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 10ms/step - loss: 55762.4961 - val_loss: 21454.1055\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 9662.1279 - val_loss: 2678.8125\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 2496.3608 - val_loss: 2062.9226\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 2019.7456 - val_loss: 1626.8253\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 1687.1119 - val_loss: 1416.8021\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 1468.4753 - val_loss: 1239.5552\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 1287.8586 - val_loss: 1101.0272\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 1143.4224 - val_loss: 985.4458\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 1006.9558 - val_loss: 882.8890\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 898.7950 - val_loss: 801.2519\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 810.2502 - val_loss: 726.9570\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 736.3228 - val_loss: 667.7595\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 676.5501 - val_loss: 615.1992\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 621.9685 - val_loss: 570.0479\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 578.3544 - val_loss: 530.9893\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 9ms/step - loss: 535.4044 - val_loss: 498.2001\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 502.2760 - val_loss: 467.8739\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 471.9617 - val_loss: 442.3864\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 445.7424 - val_loss: 419.4159\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 422.3590 - val_loss: 399.5821\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 402.3818 - val_loss: 381.1438\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 384.6445 - val_loss: 364.7471\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 367.1758 - val_loss: 350.8084\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 352.3907 - val_loss: 336.7089\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 338.5505 - val_loss: 325.1570\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 326.4387 - val_loss: 314.7249\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.5781 - val_loss: 303.8195\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 305.6502 - val_loss: 294.8556\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 295.6416 - val_loss: 286.6899\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 287.2382 - val_loss: 279.4558\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 278.6503 - val_loss: 271.7491\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 271.4915 - val_loss: 264.9503\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 265.3276 - val_loss: 259.4006\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.1313 - val_loss: 253.1543\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 252.4658 - val_loss: 247.8313\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 247.5734 - val_loss: 245.1916\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 242.3910 - val_loss: 238.3321\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 237.5823 - val_loss: 234.5768\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.2897 - val_loss: 230.2764\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.5249 - val_loss: 226.6341\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.2747 - val_loss: 223.1224\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 221.7112 - val_loss: 220.8130\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.5942 - val_loss: 217.0689\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.5763 - val_loss: 214.0526\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.9134 - val_loss: 214.5276\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 208.8929 - val_loss: 209.1631\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 9ms/step - loss: 206.0601 - val_loss: 208.0735\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.5343 - val_loss: 206.4499\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.0040 - val_loss: 202.2448\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.5784 - val_loss: 200.4455\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.4467 - val_loss: 198.3803\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 194.4924 - val_loss: 196.9020\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 192.5087 - val_loss: 194.8195\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.2433 - val_loss: 193.8757\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 188.9946 - val_loss: 190.6584\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.1472 - val_loss: 191.1150\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.2860 - val_loss: 187.9864\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 183.5697 - val_loss: 186.2463\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.3177 - val_loss: 186.2180\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.4088 - val_loss: 183.8197\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.9486 - val_loss: 184.8621\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 178.0955 - val_loss: 181.9029\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.0786 - val_loss: 180.8499\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 173.4221 - val_loss: 179.8431\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.2888 - val_loss: 178.2415\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 171.8018 - val_loss: 177.0141\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.5536 - val_loss: 177.0205\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 169.3754 - val_loss: 174.9983\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.9883 - val_loss: 175.4484\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.2803 - val_loss: 172.2535\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.7106 - val_loss: 170.8717\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 166.1893 - val_loss: 176.0520\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.4342 - val_loss: 169.8136\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.4673 - val_loss: 175.2744\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 161.7577 - val_loss: 168.7130\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.3232 - val_loss: 168.0490\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 160.6660 - val_loss: 175.4473\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.1244 - val_loss: 165.6718\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 9ms/step - loss: 156.7892 - val_loss: 164.4163\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 155.6961 - val_loss: 165.3823\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.3940 - val_loss: 163.0474\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.4093 - val_loss: 163.7058\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.8961 - val_loss: 160.8237\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.7128 - val_loss: 161.6723\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.9963 - val_loss: 165.5204\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.4455 - val_loss: 158.3882\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 150.2590 - val_loss: 157.6086\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.9802 - val_loss: 161.2053\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 147.2197 - val_loss: 157.2919\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 146.5071 - val_loss: 155.9336\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.5415 - val_loss: 156.1257\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.6913 - val_loss: 153.5677\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.4613 - val_loss: 155.8929\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 144.4155 - val_loss: 163.2564\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.9474 - val_loss: 152.2505\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 141.2843 - val_loss: 151.9289\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.6604 - val_loss: 150.6626\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.3043 - val_loss: 151.1053\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.2543 - val_loss: 149.9352\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 74ms/step - loss: 1984.4976 - val_loss: 538.5264\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 387.4895 - val_loss: 274.5797\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 270.9505 - val_loss: 219.9252\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 245.9901 - val_loss: 202.0706\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.4626 - val_loss: 191.0750\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 217.9155 - val_loss: 187.5905\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 210.3434 - val_loss: 183.4500\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 207.2975 - val_loss: 183.1053\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.8564 - val_loss: 178.5303\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.4382 - val_loss: 176.0341\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.6684 - val_loss: 173.3018\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 191.8411 - val_loss: 170.6403\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.8220 - val_loss: 167.9484\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.9692 - val_loss: 168.7300\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 181.6746 - val_loss: 163.7668\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 7ms/step - loss: 178.7056 - val_loss: 160.4482\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 7ms/step - loss: 174.8355 - val_loss: 157.1689\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.9937 - val_loss: 155.0666\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 7ms/step - loss: 168.5861 - val_loss: 150.7585\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.8158 - val_loss: 148.9618\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.2139 - val_loss: 145.0470\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 156.0971 - val_loss: 142.6610\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 7ms/step - loss: 151.9026 - val_loss: 144.0535\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 148.0764 - val_loss: 133.5846\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.0214 - val_loss: 141.5106\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 136.4745 - val_loss: 132.1490\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 129.6850 - val_loss: 122.2129\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.0342 - val_loss: 116.4645\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.3777 - val_loss: 113.2971\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 117.6252 - val_loss: 114.7958\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.1594 - val_loss: 106.7705\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 111.6812 - val_loss: 108.6948\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 109.1035 - val_loss: 103.5680\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.7496 - val_loss: 101.3924\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.4628 - val_loss: 100.4604\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.7601 - val_loss: 93.2087\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.1712 - val_loss: 93.2920\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.8200 - val_loss: 86.6274\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 98.9794 - val_loss: 89.5940\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.1458 - val_loss: 92.0748\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 95.0998 - val_loss: 83.5596\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.3682 - val_loss: 83.3050\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.1242 - val_loss: 81.7842\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.7739 - val_loss: 88.5259\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.5438 - val_loss: 80.6618\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.5453 - val_loss: 79.0494\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 87.5547 - val_loss: 80.3727\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.3995 - val_loss: 78.3473\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.0769 - val_loss: 79.5369\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.5153 - val_loss: 77.6069\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 6ms/step - loss: 84.1921 - val_loss: 81.9988\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 6ms/step - loss: 88.1854 - val_loss: 86.2901\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 6ms/step - loss: 86.5030 - val_loss: 76.7260\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 6ms/step - loss: 84.0725 - val_loss: 76.2551\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 6ms/step - loss: 84.2023 - val_loss: 76.9780\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 6ms/step - loss: 82.1654 - val_loss: 75.8359\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 10ms/step - loss: 83.8160 - val_loss: 80.3753\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.9372 - val_loss: 76.5337\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.7062 - val_loss: 74.4562\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.1576 - val_loss: 81.6666\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7178 - val_loss: 75.3486\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.9485 - val_loss: 73.7180\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.8821 - val_loss: 72.9378\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.4364 - val_loss: 75.1582\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 8ms/step - loss: 78.9649 - val_loss: 72.4350\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 6ms/step - loss: 77.5194 - val_loss: 80.4251\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 6ms/step - loss: 77.2170 - val_loss: 74.0448\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 79.1992 - val_loss: 74.2512\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.7277 - val_loss: 73.5407\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.2429 - val_loss: 73.5245\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.0424 - val_loss: 73.8905\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.3533 - val_loss: 82.5667\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.0297 - val_loss: 71.6520\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.0445 - val_loss: 75.6914\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.2904 - val_loss: 72.5013\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.6394 - val_loss: 83.8413\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.1853 - val_loss: 76.9937\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.2968 - val_loss: 72.1411\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.3480 - val_loss: 77.0268\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.7764 - val_loss: 74.7221\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.4946 - val_loss: 71.4920\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.7596 - val_loss: 72.6120\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.3360 - val_loss: 79.9370\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.2310 - val_loss: 70.2533\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.2887 - val_loss: 75.8002\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.0253 - val_loss: 70.0965\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.0324 - val_loss: 71.9741\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.6160 - val_loss: 70.9291\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.2641 - val_loss: 71.9418\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.8653 - val_loss: 68.6200\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.1320 - val_loss: 69.9660\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.5099 - val_loss: 71.1078\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.1344 - val_loss: 72.2329\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.7253 - val_loss: 69.3885\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1214 - val_loss: 73.8722\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.9638 - val_loss: 72.2576\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.4888 - val_loss: 70.8223\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.2149 - val_loss: 70.9081\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.7051 - val_loss: 69.2642\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.8283 - val_loss: 69.4988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 69ms/step - loss: 575.7813 - val_loss: 502.4803\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 397.8694 - val_loss: 356.1908\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 305.1516 - val_loss: 270.7478\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 243.0459 - val_loss: 236.3979\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.8650 - val_loss: 173.6729\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.2464 - val_loss: 151.1067\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 141.8420 - val_loss: 138.5745\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 135.9056 - val_loss: 130.4229\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.0357 - val_loss: 130.4584\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 122.3711 - val_loss: 121.3409\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.9880 - val_loss: 116.4160\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 114.1957 - val_loss: 114.6484\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 110.8988 - val_loss: 110.7887\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 105.9702 - val_loss: 108.5520\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 110.1364 - val_loss: 115.4842\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 107.9939 - val_loss: 116.8576\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.6046 - val_loss: 108.0931\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 104.4625 - val_loss: 113.0040\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.1778 - val_loss: 101.1135\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 97.8192 - val_loss: 102.1686\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 97.6024 - val_loss: 108.3979\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 96.4290 - val_loss: 99.9804\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.9712 - val_loss: 95.8091\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.6164 - val_loss: 94.4014\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.1151 - val_loss: 97.6321\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.2563 - val_loss: 91.4529\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.3734 - val_loss: 108.0718\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.5891 - val_loss: 90.2970\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.4018 - val_loss: 99.8788\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.6644 - val_loss: 89.0528\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.5667 - val_loss: 87.7087\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.2250 - val_loss: 95.2616\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 84.9086 - val_loss: 88.1650\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.6787 - val_loss: 86.9794\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.3254 - val_loss: 87.0133\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.5575 - val_loss: 86.3476\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.4283 - val_loss: 86.4637\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.1431 - val_loss: 84.5587\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.9002 - val_loss: 84.2787\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.5415 - val_loss: 82.1430\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.5034 - val_loss: 80.4905\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.2396 - val_loss: 78.4257\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.4725 - val_loss: 87.7278\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.2523 - val_loss: 76.4230\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 74.0072 - val_loss: 77.4667\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.5608 - val_loss: 75.4879\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.1534 - val_loss: 73.4741\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.6065 - val_loss: 88.7501\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.6610 - val_loss: 76.0117\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.2556 - val_loss: 71.6335\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.5330 - val_loss: 72.3610\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 71.0719 - val_loss: 69.4763\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 72.7183 - val_loss: 68.8506\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.1438 - val_loss: 70.9882\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.5366 - val_loss: 70.6508\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.5107 - val_loss: 67.1749\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 69.5792 - val_loss: 67.4512\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 68.6550 - val_loss: 67.8917\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 67.0620 - val_loss: 69.8236\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.1524 - val_loss: 65.6876\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 73.5351 - val_loss: 66.9116\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.6984 - val_loss: 63.5780\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 65.5788 - val_loss: 66.3822\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 65.8855 - val_loss: 62.4918\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.2537 - val_loss: 74.2270\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 67.1427 - val_loss: 61.4058\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.1511 - val_loss: 68.7999\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 69.3494 - val_loss: 86.3016\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 70.7607 - val_loss: 64.2064\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.0907 - val_loss: 61.3260\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 61.0822 - val_loss: 62.3193\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 61.9286 - val_loss: 74.5158\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 64.7174 - val_loss: 59.4600\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 61.1569 - val_loss: 58.4432\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.6154 - val_loss: 62.1350\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 63.0081 - val_loss: 57.2782\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.5051 - val_loss: 56.7253\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.7850 - val_loss: 67.2779\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.9539 - val_loss: 58.6844\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.5764 - val_loss: 55.3882\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.1671 - val_loss: 56.7762\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.3794 - val_loss: 59.2991\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.0956 - val_loss: 61.5865\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 66.1136 - val_loss: 75.1778\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 60.1444 - val_loss: 55.8319\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.2300 - val_loss: 55.8354\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.1244 - val_loss: 54.8402\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.2667 - val_loss: 57.2005\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 55.6905 - val_loss: 55.4402\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 55.8242 - val_loss: 52.1717\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 55.3721 - val_loss: 53.1198\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 55.8217 - val_loss: 53.3494\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 55.7164 - val_loss: 51.2547\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.1641 - val_loss: 53.9164\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.3666 - val_loss: 69.4235\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.8623 - val_loss: 58.1191\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.1070 - val_loss: 50.9434\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 53.7344 - val_loss: 55.2565\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 57.6508 - val_loss: 50.4679\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 53.0474 - val_loss: 51.4016\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 68ms/step - loss: 4867.6914 - val_loss: 2003.0404\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 1429.7505 - val_loss: 947.6407\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 708.0736 - val_loss: 506.2915\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 414.9567 - val_loss: 379.7014\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 311.1002 - val_loss: 301.1324\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 239.3429 - val_loss: 259.1770\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.3256 - val_loss: 229.0579\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 175.5970 - val_loss: 192.4785\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.4201 - val_loss: 172.3387\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.6015 - val_loss: 162.3952\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 133.3908 - val_loss: 146.3742\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.3751 - val_loss: 138.6387\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 123.2307 - val_loss: 134.8367\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 118.0842 - val_loss: 128.7355\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.9010 - val_loss: 125.0197\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 113.0998 - val_loss: 122.3161\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 111.0445 - val_loss: 120.3904\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 107.7588 - val_loss: 116.4508\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 110.4345 - val_loss: 115.3718\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 105.8718 - val_loss: 113.3058\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 104.6118 - val_loss: 111.0598\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 104.9473 - val_loss: 109.4673\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.4033 - val_loss: 113.8095\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.7240 - val_loss: 110.2149\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 99.5994 - val_loss: 106.3988\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.6527 - val_loss: 104.4437\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 102.7217 - val_loss: 107.8789\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.2957 - val_loss: 107.3744\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 100.5683 - val_loss: 101.0718\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.8120 - val_loss: 101.7520\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 95.7097 - val_loss: 99.5808\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.4743 - val_loss: 100.1053\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.8012 - val_loss: 100.1012\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.7271 - val_loss: 96.1054\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.1989 - val_loss: 95.1673\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.9441 - val_loss: 100.9744\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 94.5471 - val_loss: 107.0478\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.2736 - val_loss: 93.7601\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.6157 - val_loss: 92.6075\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.1273 - val_loss: 105.9863\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 95.0801 - val_loss: 102.1364\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 91.3757 - val_loss: 95.7396\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.7528 - val_loss: 91.2663\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.4870 - val_loss: 94.6845\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 89.7477 - val_loss: 104.9186\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 93.6050 - val_loss: 90.9562\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.2415 - val_loss: 89.7993\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.7832 - val_loss: 97.5834\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.0443 - val_loss: 89.4858\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 89.1197 - val_loss: 91.4129\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.3232 - val_loss: 95.4480\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.4653 - val_loss: 86.8852\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.7128 - val_loss: 87.1462\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.3144 - val_loss: 88.2500\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 86.0838 - val_loss: 85.6444\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.0186 - val_loss: 108.2003\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.9230 - val_loss: 84.8867\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.2271 - val_loss: 89.8661\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.3799 - val_loss: 84.4093\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 84.3284 - val_loss: 85.3898\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.7217 - val_loss: 84.2179\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 88.0868 - val_loss: 83.1544\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.5184 - val_loss: 87.1942\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.8169 - val_loss: 90.2333\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 84.2406 - val_loss: 82.3877\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.8637 - val_loss: 82.4403\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.3325 - val_loss: 86.8405\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.0421 - val_loss: 82.8327\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.2503 - val_loss: 81.2979\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.9265 - val_loss: 81.9128\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.1388 - val_loss: 81.6781\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.3887 - val_loss: 80.9815\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.9762 - val_loss: 86.6140\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 4ms/step - loss: 87.5969 - val_loss: 83.3208\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.2980 - val_loss: 79.8748\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.6937 - val_loss: 80.4983\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.5373 - val_loss: 82.1446\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.9402 - val_loss: 82.9929\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.0942 - val_loss: 82.2225\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.7280 - val_loss: 79.2841\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 4ms/step - loss: 79.4579 - val_loss: 92.7501\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 4ms/step - loss: 90.5601 - val_loss: 83.5454\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 4ms/step - loss: 83.6882 - val_loss: 79.6107\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.3285 - val_loss: 78.8866\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 80.4528 - val_loss: 79.1564\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.8182 - val_loss: 78.1099\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.7010 - val_loss: 79.1982\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.2827 - val_loss: 113.2528\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 4ms/step - loss: 81.9216 - val_loss: 113.7434\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.5796 - val_loss: 83.0451\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.6901 - val_loss: 78.7673\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 4ms/step - loss: 77.3896 - val_loss: 80.8814\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 82.0682 - val_loss: 82.8126\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.6468 - val_loss: 78.9214\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.8807 - val_loss: 77.3999\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.8878 - val_loss: 81.4671\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 78.3532 - val_loss: 78.3321\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 4ms/step - loss: 76.5581 - val_loss: 78.8138\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.4746 - val_loss: 80.2126\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 75.1737 - val_loss: 76.7948\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 90ms/step - loss: 10545.7910 - val_loss: 2617.0239\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 4ms/step - loss: 962.6587 - val_loss: 297.1042\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 4ms/step - loss: 348.8139 - val_loss: 291.5161\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 4ms/step - loss: 301.9132 - val_loss: 254.7296\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 270.7823 - val_loss: 234.8159\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 4ms/step - loss: 247.0967 - val_loss: 220.6789\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 230.9347 - val_loss: 212.4855\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 4ms/step - loss: 219.7527 - val_loss: 208.9447\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 4ms/step - loss: 213.8991 - val_loss: 206.8354\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 4ms/step - loss: 209.5573 - val_loss: 203.9090\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 4ms/step - loss: 205.6214 - val_loss: 202.1678\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 201.5527 - val_loss: 200.0785\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 4ms/step - loss: 198.6772 - val_loss: 198.0143\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 4ms/step - loss: 196.3901 - val_loss: 196.2903\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 4ms/step - loss: 194.2873 - val_loss: 194.7339\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.9086 - val_loss: 192.9194\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 4ms/step - loss: 191.1996 - val_loss: 191.2925\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 186.6734 - val_loss: 189.6510\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 4ms/step - loss: 184.4998 - val_loss: 189.4532\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 4ms/step - loss: 182.7570 - val_loss: 188.1273\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 4ms/step - loss: 179.9798 - val_loss: 186.6705\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.3168 - val_loss: 185.3749\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 4ms/step - loss: 176.4025 - val_loss: 184.1003\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 177.8947 - val_loss: 183.2744\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 4ms/step - loss: 172.6654 - val_loss: 180.9128\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 4ms/step - loss: 170.2328 - val_loss: 179.6039\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 4ms/step - loss: 168.7553 - val_loss: 180.0035\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 4ms/step - loss: 167.5537 - val_loss: 176.3182\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 165.5170 - val_loss: 175.6736\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 4ms/step - loss: 163.7847 - val_loss: 173.7459\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 4ms/step - loss: 162.9391 - val_loss: 175.0961\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 4ms/step - loss: 161.9442 - val_loss: 171.9292\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 4ms/step - loss: 160.7707 - val_loss: 171.7056\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.4614 - val_loss: 169.0804\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 4ms/step - loss: 156.4388 - val_loss: 167.5912\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 4ms/step - loss: 155.2144 - val_loss: 167.2589\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 4ms/step - loss: 153.2733 - val_loss: 166.1409\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 4ms/step - loss: 152.5157 - val_loss: 168.9550\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 4ms/step - loss: 154.5838 - val_loss: 163.0893\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 4ms/step - loss: 158.4746 - val_loss: 164.0255\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 4ms/step - loss: 151.3548 - val_loss: 163.9351\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 4ms/step - loss: 146.5629 - val_loss: 161.1263\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.4355 - val_loss: 158.9972\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 4ms/step - loss: 145.1474 - val_loss: 157.6777\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 4ms/step - loss: 143.3492 - val_loss: 159.5673\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 4ms/step - loss: 142.3620 - val_loss: 154.2062\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 4ms/step - loss: 139.8707 - val_loss: 154.3323\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 4ms/step - loss: 138.5783 - val_loss: 152.0205\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 136.7374 - val_loss: 152.1692\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 4ms/step - loss: 136.6335 - val_loss: 148.1142\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.8764 - val_loss: 146.1076\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 4ms/step - loss: 132.6404 - val_loss: 142.1398\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 4ms/step - loss: 128.3221 - val_loss: 142.7972\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 4ms/step - loss: 128.1852 - val_loss: 134.9268\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 4ms/step - loss: 125.4389 - val_loss: 134.5422\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 4ms/step - loss: 127.4541 - val_loss: 134.5950\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.8102 - val_loss: 126.1622\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 4ms/step - loss: 120.5425 - val_loss: 126.4488\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 4ms/step - loss: 119.1880 - val_loss: 123.8520\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 4ms/step - loss: 117.1416 - val_loss: 117.7474\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 4ms/step - loss: 115.1342 - val_loss: 115.1193\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 4ms/step - loss: 112.3131 - val_loss: 112.2358\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 4ms/step - loss: 109.4072 - val_loss: 113.2994\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 106.6676 - val_loss: 106.3329\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 4ms/step - loss: 103.7984 - val_loss: 103.4489\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 4ms/step - loss: 102.9034 - val_loss: 98.8069\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 4ms/step - loss: 101.9915 - val_loss: 106.9976\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 6ms/step - loss: 99.5793 - val_loss: 95.7025\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 97.3002 - val_loss: 91.0154\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 16ms/step - loss: 91.9690 - val_loss: 88.6446\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 88.4769 - val_loss: 85.3716\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8073 - val_loss: 82.6092\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 85.3163 - val_loss: 90.4431\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.8173 - val_loss: 90.5882\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.2521 - val_loss: 77.3305\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7158 - val_loss: 77.7334\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 9ms/step - loss: 79.2022 - val_loss: 76.2997\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.3148 - val_loss: 72.1324\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 7ms/step - loss: 78.8986 - val_loss: 70.7860\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.1977 - val_loss: 72.8539\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.3833 - val_loss: 68.4198\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.5647 - val_loss: 66.9661\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.2546 - val_loss: 65.6037\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.0110 - val_loss: 64.1307\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.5514 - val_loss: 68.6693\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.3857 - val_loss: 62.8828\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1764 - val_loss: 61.2815\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9298 - val_loss: 60.2396\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.5724 - val_loss: 58.9977\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.4721 - val_loss: 59.1548\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7435 - val_loss: 61.9663\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.0582 - val_loss: 57.4510\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 4ms/step - loss: 61.9669 - val_loss: 60.4515\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.6648 - val_loss: 66.1325\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.8471 - val_loss: 57.9563\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.4840 - val_loss: 57.2882\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.8102 - val_loss: 57.6545\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3702 - val_loss: 57.6578\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 4ms/step - loss: 58.1344 - val_loss: 57.1496\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 4ms/step - loss: 57.4078 - val_loss: 54.9618\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 71ms/step - loss: 2677.6648 - val_loss: 1217.5081\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 921.1915 - val_loss: 682.6879\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 551.5714 - val_loss: 464.2290\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 397.3945 - val_loss: 356.2650\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 315.2214 - val_loss: 306.2668\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 282.0266 - val_loss: 291.0162\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 273.8855 - val_loss: 285.3073\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 268.8569 - val_loss: 281.7634\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 264.4661 - val_loss: 277.1245\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 259.2552 - val_loss: 271.2365\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 253.9831 - val_loss: 266.4384\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.8013 - val_loss: 262.3218\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 9ms/step - loss: 246.3190 - val_loss: 259.4218\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 243.9034 - val_loss: 256.7214\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 240.5553 - val_loss: 254.3051\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.6013 - val_loss: 251.9467\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 236.2577 - val_loss: 248.7099\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 233.6825 - val_loss: 246.5916\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 231.5782 - val_loss: 244.8102\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 230.0158 - val_loss: 243.0410\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.0473 - val_loss: 240.9798\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.2888 - val_loss: 239.0454\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 223.6492 - val_loss: 236.9799\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 4ms/step - loss: 221.6017 - val_loss: 233.3642\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 218.1941 - val_loss: 229.0923\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.1450 - val_loss: 224.1926\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.1534 - val_loss: 219.5356\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 206.4033 - val_loss: 214.2856\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.2181 - val_loss: 207.3057\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.1923 - val_loss: 200.9130\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 190.4583 - val_loss: 194.9449\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.0237 - val_loss: 189.7013\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 179.2502 - val_loss: 181.9848\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.5388 - val_loss: 178.5432\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 170.9204 - val_loss: 173.7290\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.1566 - val_loss: 168.2337\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 163.5774 - val_loss: 163.4580\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 159.6116 - val_loss: 162.2295\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 158.6962 - val_loss: 156.0035\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 151.9933 - val_loss: 151.8828\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 148.3129 - val_loss: 147.3431\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.8440 - val_loss: 143.5187\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 143.1172 - val_loss: 141.5614\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 138.9453 - val_loss: 136.4166\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.3842 - val_loss: 138.9701\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.8257 - val_loss: 130.9990\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 132.7918 - val_loss: 128.3826\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.3895 - val_loss: 127.4004\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 4ms/step - loss: 126.8482 - val_loss: 124.6301\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 125.4376 - val_loss: 122.3239\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 124.3835 - val_loss: 121.0754\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.9497 - val_loss: 119.1042\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 121.3353 - val_loss: 120.5675\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.2176 - val_loss: 117.2845\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.0515 - val_loss: 116.7597\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.1707 - val_loss: 115.1142\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.6127 - val_loss: 114.1951\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.7532 - val_loss: 113.8348\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 116.0866 - val_loss: 112.7452\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 118.8225 - val_loss: 111.9769\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.3824 - val_loss: 113.5604\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.4758 - val_loss: 113.8718\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.7833 - val_loss: 110.4348\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 4ms/step - loss: 111.8764 - val_loss: 109.0841\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.4269 - val_loss: 111.2956\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.5809 - val_loss: 109.9509\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.0708 - val_loss: 109.8855\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 4ms/step - loss: 109.0662 - val_loss: 112.1059\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.8924 - val_loss: 109.4205\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.8011 - val_loss: 109.8051\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.9778 - val_loss: 108.6647\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.4560 - val_loss: 109.9657\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.3647 - val_loss: 108.4977\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.0904 - val_loss: 107.8557\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.4239 - val_loss: 106.8230\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.8592 - val_loss: 107.5341\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.8058 - val_loss: 105.9955\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 4ms/step - loss: 108.2208 - val_loss: 106.7805\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.4996 - val_loss: 104.9725\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.3989 - val_loss: 104.5886\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.1605 - val_loss: 105.7060\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 105.1326 - val_loss: 103.6964\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.2662 - val_loss: 103.5820\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 102.3922 - val_loss: 106.4801\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 4ms/step - loss: 103.0821 - val_loss: 102.9220\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.0641 - val_loss: 104.1005\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 104.2088 - val_loss: 105.0164\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 102.5256 - val_loss: 102.4696\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 9ms/step - loss: 101.8720 - val_loss: 101.9414\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.9396 - val_loss: 102.6867\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.1607 - val_loss: 101.9904\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.1515 - val_loss: 101.5679\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.2493 - val_loss: 103.9143\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.3625 - val_loss: 102.1257\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.1816 - val_loss: 101.5872\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.7404 - val_loss: 99.6868\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.5464 - val_loss: 104.5260\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.0240 - val_loss: 101.4994\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.6238 - val_loss: 99.4939\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.2004 - val_loss: 99.1411\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 3s - 112ms/step - loss: 1955.9326 - val_loss: 1150.1960\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 821.1157 - val_loss: 716.8466\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 595.5503 - val_loss: 543.9167\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 467.1273 - val_loss: 443.2930\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 4ms/step - loss: 397.7598 - val_loss: 397.2953\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 360.5179 - val_loss: 357.3802\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 5ms/step - loss: 337.6074 - val_loss: 332.9466\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 313.8293 - val_loss: 313.8881\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 294.0799 - val_loss: 298.9355\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 278.2426 - val_loss: 302.5044\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 272.0107 - val_loss: 277.8137\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 4ms/step - loss: 259.8902 - val_loss: 270.6646\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 249.2269 - val_loss: 263.5151\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 245.1267 - val_loss: 256.2265\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 241.0211 - val_loss: 252.3203\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 238.6256 - val_loss: 245.5077\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 228.5920 - val_loss: 241.0945\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 4ms/step - loss: 228.5344 - val_loss: 237.5199\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 226.7419 - val_loss: 237.3874\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 220.3324 - val_loss: 231.7169\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 225.8939 - val_loss: 237.0205\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.3688 - val_loss: 229.2653\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 211.5312 - val_loss: 232.7644\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 216.4014 - val_loss: 230.5358\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 215.3172 - val_loss: 226.1038\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 205.4198 - val_loss: 220.7742\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 204.4216 - val_loss: 214.7112\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 202.4509 - val_loss: 216.5729\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 4ms/step - loss: 200.0838 - val_loss: 223.2941\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 196.5783 - val_loss: 222.0368\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 195.5790 - val_loss: 211.3999\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.2743 - val_loss: 202.8243\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.5600 - val_loss: 204.6829\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 187.3271 - val_loss: 197.5427\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 185.9465 - val_loss: 203.7538\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 198.7105 - val_loss: 192.3493\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.8642 - val_loss: 201.6982\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 180.3947 - val_loss: 186.1166\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 177.6068 - val_loss: 184.5682\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0752 - val_loss: 182.3449\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 172.4595 - val_loss: 175.9092\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.0793 - val_loss: 172.2705\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 175.1942 - val_loss: 184.3001\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 167.6024 - val_loss: 172.5502\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 162.3856 - val_loss: 162.4247\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.7854 - val_loss: 161.0354\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 152.6135 - val_loss: 155.6795\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 5ms/step - loss: 145.1681 - val_loss: 155.2462\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 149.3184 - val_loss: 147.2835\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 139.9651 - val_loss: 146.6350\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 140.8903 - val_loss: 150.7773\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 136.6555 - val_loss: 137.8994\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 137.2217 - val_loss: 145.4993\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 130.5017 - val_loss: 127.9795\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 122.6191 - val_loss: 125.0274\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 120.6177 - val_loss: 121.9028\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.2665 - val_loss: 120.8740\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 115.3692 - val_loss: 114.9863\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 113.6226 - val_loss: 114.5945\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.8455 - val_loss: 114.9795\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.2836 - val_loss: 110.0281\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 110.1732 - val_loss: 108.7110\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 109.3642 - val_loss: 142.8448\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.1761 - val_loss: 119.6574\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 112.3585 - val_loss: 105.2057\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 107.8565 - val_loss: 102.6737\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.6707 - val_loss: 101.5704\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.9618 - val_loss: 99.4057\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 9ms/step - loss: 96.7140 - val_loss: 100.8299\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.0777 - val_loss: 95.9911\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.2141 - val_loss: 111.6043\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.8063 - val_loss: 92.0852\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.3107 - val_loss: 89.7848\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.3474 - val_loss: 87.4334\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.6177 - val_loss: 89.8150\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.9068 - val_loss: 87.6728\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.8019 - val_loss: 86.5648\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.2002 - val_loss: 111.1975\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.9249 - val_loss: 92.0575\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.0602 - val_loss: 90.5184\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.8560 - val_loss: 83.7813\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.9369 - val_loss: 96.0942\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.8406 - val_loss: 96.7503\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 5ms/step - loss: 99.0623 - val_loss: 83.1463\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 79.1385 - val_loss: 85.4042\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.2685 - val_loss: 85.2724\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.2738 - val_loss: 87.2261\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.5077 - val_loss: 83.0177\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.3609 - val_loss: 82.6857\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.5395 - val_loss: 81.7462\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.2394 - val_loss: 98.9315\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.9673 - val_loss: 83.2902\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.1127 - val_loss: 85.0220\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.6415 - val_loss: 81.7791\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.9836 - val_loss: 81.2448\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4601 - val_loss: 81.7061\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 85.7368 - val_loss: 107.4722\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 83.4799 - val_loss: 81.6977\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 81.1819 - val_loss: 88.0218\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.2471 - val_loss: 86.4364\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 70ms/step - loss: 4483.5029 - val_loss: 792.5495\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 5ms/step - loss: 651.5499 - val_loss: 400.6123\n",
      "Epoch 3/100\n",
      "23/23 - 0s - 5ms/step - loss: 342.6843 - val_loss: 269.5841\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 5ms/step - loss: 253.6999 - val_loss: 246.0748\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 5ms/step - loss: 229.1357 - val_loss: 239.4521\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 5ms/step - loss: 219.2859 - val_loss: 232.9491\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 4ms/step - loss: 210.3596 - val_loss: 223.8078\n",
      "Epoch 8/100\n",
      "23/23 - 0s - 5ms/step - loss: 201.3326 - val_loss: 218.1891\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 5ms/step - loss: 193.0289 - val_loss: 209.4113\n",
      "Epoch 10/100\n",
      "23/23 - 0s - 5ms/step - loss: 184.4030 - val_loss: 198.0303\n",
      "Epoch 11/100\n",
      "23/23 - 0s - 5ms/step - loss: 176.0858 - val_loss: 183.8006\n",
      "Epoch 12/100\n",
      "23/23 - 0s - 5ms/step - loss: 165.8091 - val_loss: 167.4155\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 5ms/step - loss: 154.9516 - val_loss: 149.1256\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 5ms/step - loss: 142.9982 - val_loss: 139.8092\n",
      "Epoch 15/100\n",
      "23/23 - 0s - 5ms/step - loss: 134.9781 - val_loss: 132.6350\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 5ms/step - loss: 127.8569 - val_loss: 125.5212\n",
      "Epoch 17/100\n",
      "23/23 - 0s - 5ms/step - loss: 123.9328 - val_loss: 122.3133\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 5ms/step - loss: 119.0313 - val_loss: 120.1368\n",
      "Epoch 19/100\n",
      "23/23 - 0s - 5ms/step - loss: 114.6532 - val_loss: 117.6870\n",
      "Epoch 20/100\n",
      "23/23 - 0s - 5ms/step - loss: 111.1852 - val_loss: 116.5623\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 5ms/step - loss: 108.3934 - val_loss: 113.0739\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 4ms/step - loss: 106.0519 - val_loss: 109.9524\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 5ms/step - loss: 103.0897 - val_loss: 109.1618\n",
      "Epoch 24/100\n",
      "23/23 - 0s - 5ms/step - loss: 101.5107 - val_loss: 109.4016\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 5ms/step - loss: 100.7329 - val_loss: 108.9482\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 5ms/step - loss: 98.5289 - val_loss: 103.5627\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 5ms/step - loss: 95.6189 - val_loss: 102.1929\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 5ms/step - loss: 93.3652 - val_loss: 104.6773\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 5ms/step - loss: 94.6103 - val_loss: 98.6543\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 5ms/step - loss: 92.8284 - val_loss: 97.4082\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 5ms/step - loss: 91.2506 - val_loss: 94.5186\n",
      "Epoch 32/100\n",
      "23/23 - 0s - 9ms/step - loss: 87.9232 - val_loss: 96.1465\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 5ms/step - loss: 86.4171 - val_loss: 90.0099\n",
      "Epoch 34/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.4884 - val_loss: 89.9377\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 5ms/step - loss: 84.1566 - val_loss: 89.0717\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 5ms/step - loss: 82.3579 - val_loss: 86.7317\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.7580 - val_loss: 89.1769\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 5ms/step - loss: 80.9183 - val_loss: 84.9327\n",
      "Epoch 39/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.9548 - val_loss: 84.4791\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 5ms/step - loss: 78.3022 - val_loss: 82.8706\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.7476 - val_loss: 81.9538\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 5ms/step - loss: 77.4415 - val_loss: 81.1715\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 5ms/step - loss: 75.4874 - val_loss: 81.3112\n",
      "Epoch 44/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7875 - val_loss: 80.5208\n",
      "Epoch 45/100\n",
      "23/23 - 0s - 5ms/step - loss: 76.7240 - val_loss: 79.7483\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 5ms/step - loss: 74.1190 - val_loss: 78.9540\n",
      "Epoch 47/100\n",
      "23/23 - 0s - 5ms/step - loss: 73.2327 - val_loss: 79.2446\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 10ms/step - loss: 72.2496 - val_loss: 78.2292\n",
      "Epoch 49/100\n",
      "23/23 - 0s - 5ms/step - loss: 72.6735 - val_loss: 76.5104\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 5ms/step - loss: 71.4677 - val_loss: 75.6224\n",
      "Epoch 51/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.9726 - val_loss: 78.8467\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.4961 - val_loss: 74.5764\n",
      "Epoch 53/100\n",
      "23/23 - 0s - 5ms/step - loss: 70.1933 - val_loss: 74.7076\n",
      "Epoch 54/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.2722 - val_loss: 74.6414\n",
      "Epoch 55/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.4373 - val_loss: 74.4081\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 5ms/step - loss: 69.5153 - val_loss: 73.3459\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 5ms/step - loss: 68.3568 - val_loss: 72.4488\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.7328 - val_loss: 75.2679\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.8047 - val_loss: 71.9319\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 5ms/step - loss: 67.1578 - val_loss: 71.2348\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9214 - val_loss: 72.6290\n",
      "Epoch 62/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.5831 - val_loss: 70.2692\n",
      "Epoch 63/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.6778 - val_loss: 72.9863\n",
      "Epoch 64/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.8654 - val_loss: 72.4786\n",
      "Epoch 65/100\n",
      "23/23 - 0s - 5ms/step - loss: 65.9293 - val_loss: 71.4958\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 5ms/step - loss: 66.1155 - val_loss: 71.0987\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.0874 - val_loss: 69.5404\n",
      "Epoch 68/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.2406 - val_loss: 69.9183\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.9523 - val_loss: 69.2301\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.1795 - val_loss: 70.0321\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.5705 - val_loss: 70.7411\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 5ms/step - loss: 62.9063 - val_loss: 69.7687\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.7201 - val_loss: 71.0549\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 5ms/step - loss: 64.2092 - val_loss: 72.4102\n",
      "Epoch 75/100\n",
      "23/23 - 0s - 9ms/step - loss: 61.9664 - val_loss: 69.2789\n",
      "Epoch 76/100\n",
      "23/23 - 0s - 5ms/step - loss: 63.0445 - val_loss: 68.8743\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.4758 - val_loss: 67.7943\n",
      "Epoch 78/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.7752 - val_loss: 68.3155\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8417 - val_loss: 68.0850\n",
      "Epoch 80/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.3539 - val_loss: 68.6453\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.8301 - val_loss: 67.0189\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 5ms/step - loss: 60.8060 - val_loss: 67.1278\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 5ms/step - loss: 61.0802 - val_loss: 66.6366\n",
      "Epoch 84/100\n",
      "23/23 - 0s - 4ms/step - loss: 59.8083 - val_loss: 65.3307\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.8657 - val_loss: 66.3376\n",
      "Epoch 86/100\n",
      "23/23 - 0s - 5ms/step - loss: 59.6680 - val_loss: 65.4355\n",
      "Epoch 87/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.1772 - val_loss: 64.2969\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 5ms/step - loss: 58.1267 - val_loss: 64.1790\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.6893 - val_loss: 64.1432\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.9675 - val_loss: 63.7348\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.7183 - val_loss: 63.1780\n",
      "Epoch 92/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.8827 - val_loss: 65.5907\n",
      "Epoch 93/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.3928 - val_loss: 63.4024\n",
      "Epoch 94/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.3187 - val_loss: 61.3807\n",
      "Epoch 95/100\n",
      "23/23 - 0s - 5ms/step - loss: 55.2046 - val_loss: 62.5690\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 5ms/step - loss: 54.9001 - val_loss: 60.5145\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 4ms/step - loss: 56.3708 - val_loss: 59.6071\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 5ms/step - loss: 57.2872 - val_loss: 60.1630\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 5ms/step - loss: 56.0611 - val_loss: 59.4074\n",
      "Epoch 100/100\n",
      "23/23 - 0s - 5ms/step - loss: 53.5382 - val_loss: 61.1473\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "n_cols = predictor.shape[1] # number of predictors\n",
    "mean_squared_errors = []\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for i in range(50):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(predictor, target, test_size=0.3)\n",
    "    model = regression_model()\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, verbose=2)\n",
    "    \n",
    "    predictions=model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, predictions)\n",
    "    mean_squared_errors.append(mse)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df43d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors: 105.84191786104583\n",
      "Standard Deviation of Mean Squared Errors: 184.30329178029154\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and standard deviation of the mean squared errors\n",
    "import numpy as np\n",
    "mean_mse = np.mean(mean_squared_errors)\n",
    "std_mse = np.std(mean_squared_errors)\n",
    "\n",
    "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
    "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb87be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
