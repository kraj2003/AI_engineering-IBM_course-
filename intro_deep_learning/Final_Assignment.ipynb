{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471d8f61",
   "metadata": {},
   "source": [
    "# Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1ec91",
   "metadata": {},
   "source": [
    "Import the libraries and importing keras model amd layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fa01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6115dda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"concrete_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f424dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd6ee7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b3c41",
   "metadata": {},
   "source": [
    "So the first concrete sample has 540 cubic meter of cement, 0 cubic meter of blast furnace slag, 0 cubic meter of fly ash, 162 cubic meter of water, 2.5 cubic meter of superplaticizer, 1040 cubic meter of coarse aggregate, 676 cubic meter of fine aggregate. Such a concrete mix which is 28 days old, has a compressive strength of 79.99 MPa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3fc1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4b643",
   "metadata": {},
   "source": [
    "#### Split data into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c343c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=data.drop(columns='Strength')\n",
    "target=data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5d2a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_norm=(predictor-predictor.mean())/predictor.std()\n",
    "# predictor_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54663a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(predictor,target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19098465",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check of the predictors and the target dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758069c7",
   "metadata": {},
   "source": [
    "#### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691bceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols=predictor.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b0752e",
   "metadata": {},
   "source": [
    "## Build a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8d3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    \n",
    "    # create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(10,activation='relu',input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd085d",
   "metadata": {},
   "source": [
    "The above function create a model that has three hidden layers, each of 5 hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad19e2",
   "metadata": {},
   "source": [
    "## Train and Test the Network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5576e029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d90b834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.5491 \n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.8388\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.5921 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 121.9281 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.0826 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.2868 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.7817 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.4172 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.4794\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.7809 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.1993\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.3384 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.4905\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120.3307 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.4087\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.1919 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.3778 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.7816 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119.3443\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.9054 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 110.4921\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.8371 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.0293 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.3293\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.2735 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111.9167 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.8604\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.4377 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5345 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.9414 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.1677\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120.0818  \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119.1006 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.5857 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.6560 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.6505 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115.3123 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 120.3943 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.5118 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.9215\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112.8040\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.0117\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.4586 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107.6305 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.1098 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.0554 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5059\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123.9031 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.7314\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.9431 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22efc7fd190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "470b08f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea6492da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.854254],\n",
       "       [51.30486 ],\n",
       "       [31.639975],\n",
       "       [36.91759 ],\n",
       "       [37.00411 ],\n",
       "       [37.23128 ],\n",
       "       [65.53797 ],\n",
       "       [32.68047 ],\n",
       "       [34.007893],\n",
       "       [35.94176 ],\n",
       "       [36.081287],\n",
       "       [51.821888],\n",
       "       [28.247198],\n",
       "       [12.838719],\n",
       "       [24.786337],\n",
       "       [42.079884],\n",
       "       [38.78272 ],\n",
       "       [30.961966],\n",
       "       [52.263004],\n",
       "       [19.058554],\n",
       "       [27.2732  ],\n",
       "       [49.671116],\n",
       "       [58.07085 ],\n",
       "       [36.02666 ],\n",
       "       [48.028522],\n",
       "       [33.512775],\n",
       "       [26.52239 ],\n",
       "       [25.63622 ],\n",
       "       [16.849142],\n",
       "       [36.197056],\n",
       "       [28.944723],\n",
       "       [35.846836],\n",
       "       [62.40221 ],\n",
       "       [30.264288],\n",
       "       [39.404392],\n",
       "       [30.434896],\n",
       "       [53.579792],\n",
       "       [49.21938 ],\n",
       "       [31.008718],\n",
       "       [25.102758],\n",
       "       [53.503315],\n",
       "       [25.48223 ],\n",
       "       [49.17879 ],\n",
       "       [24.493048],\n",
       "       [30.527761],\n",
       "       [59.173542],\n",
       "       [50.59212 ],\n",
       "       [25.176474],\n",
       "       [40.155598],\n",
       "       [63.535892],\n",
       "       [33.575916],\n",
       "       [59.438435],\n",
       "       [27.578817],\n",
       "       [39.2217  ],\n",
       "       [15.339894],\n",
       "       [52.551533],\n",
       "       [38.642628],\n",
       "       [35.293583],\n",
       "       [41.422855],\n",
       "       [57.256367],\n",
       "       [48.925632],\n",
       "       [54.577915],\n",
       "       [22.854422],\n",
       "       [32.376453],\n",
       "       [58.917988],\n",
       "       [38.91364 ],\n",
       "       [42.46445 ],\n",
       "       [30.742819],\n",
       "       [23.802664],\n",
       "       [40.43076 ],\n",
       "       [42.167545],\n",
       "       [33.64687 ],\n",
       "       [30.782156],\n",
       "       [39.71236 ],\n",
       "       [55.97855 ],\n",
       "       [27.99529 ],\n",
       "       [30.005362],\n",
       "       [24.318655],\n",
       "       [36.76653 ],\n",
       "       [25.10549 ],\n",
       "       [50.714985],\n",
       "       [25.668997],\n",
       "       [25.256643],\n",
       "       [31.485113],\n",
       "       [23.516867],\n",
       "       [32.7963  ],\n",
       "       [24.693747],\n",
       "       [41.967915],\n",
       "       [38.10204 ],\n",
       "       [45.425236],\n",
       "       [24.959982],\n",
       "       [47.290318],\n",
       "       [36.560123],\n",
       "       [24.019201],\n",
       "       [35.66045 ],\n",
       "       [21.269308],\n",
       "       [21.663214],\n",
       "       [45.305607],\n",
       "       [40.640125],\n",
       "       [54.428165],\n",
       "       [59.155857],\n",
       "       [37.18709 ],\n",
       "       [50.188984],\n",
       "       [27.936697],\n",
       "       [29.995886],\n",
       "       [41.243443],\n",
       "       [60.04723 ],\n",
       "       [40.45934 ],\n",
       "       [20.166021],\n",
       "       [35.039722],\n",
       "       [27.581121],\n",
       "       [51.722446],\n",
       "       [20.663702],\n",
       "       [37.1422  ],\n",
       "       [46.853886],\n",
       "       [56.069202],\n",
       "       [20.720724],\n",
       "       [26.259268],\n",
       "       [26.580084],\n",
       "       [24.933355],\n",
       "       [58.183918],\n",
       "       [26.824636],\n",
       "       [21.266165],\n",
       "       [61.016666],\n",
       "       [31.592215],\n",
       "       [23.65566 ],\n",
       "       [29.506002],\n",
       "       [30.10201 ],\n",
       "       [33.871998],\n",
       "       [64.00388 ],\n",
       "       [64.699   ],\n",
       "       [41.763126],\n",
       "       [38.12827 ],\n",
       "       [35.896168],\n",
       "       [36.62914 ],\n",
       "       [35.69678 ],\n",
       "       [30.166128],\n",
       "       [43.27178 ],\n",
       "       [27.066427],\n",
       "       [17.176031],\n",
       "       [27.473043],\n",
       "       [21.429434],\n",
       "       [25.795767],\n",
       "       [33.710392],\n",
       "       [22.118353],\n",
       "       [38.256702],\n",
       "       [57.780598],\n",
       "       [35.379032],\n",
       "       [38.98061 ],\n",
       "       [25.049551],\n",
       "       [23.577353],\n",
       "       [39.787144],\n",
       "       [25.430014],\n",
       "       [41.757526],\n",
       "       [15.755727],\n",
       "       [50.884007],\n",
       "       [24.29865 ],\n",
       "       [21.697134],\n",
       "       [25.66979 ],\n",
       "       [21.7022  ],\n",
       "       [22.111197],\n",
       "       [38.615086],\n",
       "       [64.07581 ],\n",
       "       [45.6283  ],\n",
       "       [33.373737],\n",
       "       [79.81635 ],\n",
       "       [30.20902 ],\n",
       "       [45.71361 ],\n",
       "       [23.984304],\n",
       "       [56.907795],\n",
       "       [36.503803],\n",
       "       [25.909079],\n",
       "       [25.114584],\n",
       "       [41.0479  ],\n",
       "       [23.097952],\n",
       "       [49.47452 ],\n",
       "       [40.999134],\n",
       "       [57.470325],\n",
       "       [24.748236],\n",
       "       [40.908604],\n",
       "       [14.81873 ],\n",
       "       [29.089285],\n",
       "       [57.298634],\n",
       "       [25.307302],\n",
       "       [23.632559],\n",
       "       [34.832783],\n",
       "       [30.101797],\n",
       "       [35.818623],\n",
       "       [56.61025 ],\n",
       "       [30.298285],\n",
       "       [27.14266 ],\n",
       "       [57.426228],\n",
       "       [28.748571],\n",
       "       [38.162724],\n",
       "       [35.458347],\n",
       "       [20.251394],\n",
       "       [32.68424 ],\n",
       "       [14.455647],\n",
       "       [51.40108 ],\n",
       "       [42.135334],\n",
       "       [50.402515],\n",
       "       [31.323416],\n",
       "       [35.62801 ],\n",
       "       [36.80602 ],\n",
       "       [56.913822],\n",
       "       [33.13718 ],\n",
       "       [30.816305],\n",
       "       [25.148046],\n",
       "       [47.720127],\n",
       "       [29.318106],\n",
       "       [30.434454],\n",
       "       [32.07288 ],\n",
       "       [20.434988],\n",
       "       [68.50358 ],\n",
       "       [42.763126],\n",
       "       [39.45763 ],\n",
       "       [33.349537],\n",
       "       [35.604816],\n",
       "       [60.035343],\n",
       "       [33.099094],\n",
       "       [41.248295],\n",
       "       [20.655798],\n",
       "       [19.790228],\n",
       "       [68.73432 ],\n",
       "       [18.614523],\n",
       "       [48.80968 ],\n",
       "       [45.97852 ],\n",
       "       [54.359913],\n",
       "       [35.917088],\n",
       "       [36.072163],\n",
       "       [40.583683],\n",
       "       [38.836384],\n",
       "       [45.937397],\n",
       "       [24.293417],\n",
       "       [41.95528 ],\n",
       "       [39.861042],\n",
       "       [27.940588],\n",
       "       [33.796955],\n",
       "       [35.423115],\n",
       "       [38.141895],\n",
       "       [27.945822],\n",
       "       [64.699   ],\n",
       "       [20.22373 ],\n",
       "       [50.171284],\n",
       "       [20.041769],\n",
       "       [42.4612  ],\n",
       "       [44.00217 ],\n",
       "       [29.167288],\n",
       "       [25.3644  ],\n",
       "       [25.903067],\n",
       "       [40.311146],\n",
       "       [44.465336],\n",
       "       [37.66115 ],\n",
       "       [56.444614],\n",
       "       [30.957907],\n",
       "       [54.00063 ],\n",
       "       [30.241278],\n",
       "       [20.074545],\n",
       "       [54.642155],\n",
       "       [35.15694 ],\n",
       "       [30.054983],\n",
       "       [32.01845 ],\n",
       "       [41.813618],\n",
       "       [43.46471 ],\n",
       "       [35.925327],\n",
       "       [31.273474],\n",
       "       [46.05199 ],\n",
       "       [34.227818],\n",
       "       [24.478933],\n",
       "       [26.49877 ],\n",
       "       [35.8725  ],\n",
       "       [29.093985],\n",
       "       [48.0734  ],\n",
       "       [46.709095],\n",
       "       [37.165302],\n",
       "       [27.58193 ],\n",
       "       [28.1704  ],\n",
       "       [30.211416],\n",
       "       [42.29851 ],\n",
       "       [27.407019],\n",
       "       [22.754843],\n",
       "       [32.840504],\n",
       "       [61.027287],\n",
       "       [30.283102],\n",
       "       [72.41662 ],\n",
       "       [35.940845],\n",
       "       [37.251377],\n",
       "       [25.785223],\n",
       "       [54.000614],\n",
       "       [42.1657  ],\n",
       "       [41.932163],\n",
       "       [17.965124],\n",
       "       [39.09746 ],\n",
       "       [37.66997 ],\n",
       "       [32.390736],\n",
       "       [33.44402 ],\n",
       "       [20.888021],\n",
       "       [29.405478],\n",
       "       [32.140125],\n",
       "       [32.732075],\n",
       "       [53.889484],\n",
       "       [37.821568],\n",
       "       [33.52138 ],\n",
       "       [32.536213],\n",
       "       [38.053333],\n",
       "       [31.315832],\n",
       "       [42.71636 ],\n",
       "       [45.614872],\n",
       "       [47.1516  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "# model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cfef570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 50ms/step - loss: 339054.3438 - val_loss: 223099.8906\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 150230.0156 - val_loss: 88359.3828\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 51860.8945 - val_loss: 22646.9141\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 11076.2305 - val_loss: 4846.7817\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 3797.7258 - val_loss: 3609.2131\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 3351.3218 - val_loss: 3366.3000\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3115.3877 - val_loss: 3133.8833\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 2896.5564 - val_loss: 2911.8652\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2689.5146 - val_loss: 2696.7683\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 2495.3926 - val_loss: 2491.0288\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 2304.8164 - val_loss: 2309.3550\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 2135.7114 - val_loss: 2131.6709\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1978.9510 - val_loss: 1974.5206\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1833.5338 - val_loss: 1833.0292\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1704.8586 - val_loss: 1706.7261\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1591.5784 - val_loss: 1595.1266\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1490.5144 - val_loss: 1495.0935\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1398.8260 - val_loss: 1410.0486\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1318.4963 - val_loss: 1328.0562\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1245.6089 - val_loss: 1255.3066\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1181.4767 - val_loss: 1191.4252\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1125.9675 - val_loss: 1132.8656\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1066.4801 - val_loss: 1080.8718\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1018.6854 - val_loss: 1030.0458\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 972.6662 - val_loss: 982.4590\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 929.7516 - val_loss: 937.7588\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 889.4647 - val_loss: 898.4542\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 853.6192 - val_loss: 861.3927\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 821.6868 - val_loss: 827.3173\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 787.6215 - val_loss: 797.2697\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 759.4068 - val_loss: 766.7048\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 733.4889 - val_loss: 738.4178\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 707.7795 - val_loss: 713.7965\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 683.2079 - val_loss: 688.3152\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 658.7028 - val_loss: 664.8120\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 638.4458 - val_loss: 642.9211\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 616.2332 - val_loss: 620.8880\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 596.0366 - val_loss: 601.4124\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 8ms/step - loss: 578.5311 - val_loss: 582.7200\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 559.9292 - val_loss: 563.6821\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 542.7851 - val_loss: 546.8189\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 526.6910 - val_loss: 528.9760\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 511.3605 - val_loss: 513.9490\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 496.6016 - val_loss: 498.5740\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 483.3396 - val_loss: 485.2595\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 9ms/step - loss: 470.4241 - val_loss: 471.1697\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 457.7432 - val_loss: 458.9564\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.8413 - val_loss: 447.0532\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 437.2166 - val_loss: 435.6656\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 424.7494 - val_loss: 425.3297\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 48ms/step - loss: 159014.8594 - val_loss: 89327.2344\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 52388.1406 - val_loss: 23297.1582\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 12144.9277 - val_loss: 5531.3726\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 4382.1387 - val_loss: 3874.4817\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 3765.5430 - val_loss: 3403.6609\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 3293.3870 - val_loss: 2999.7896\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2900.5510 - val_loss: 2662.1931\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 2606.3884 - val_loss: 2404.9961\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2392.2866 - val_loss: 2197.4617\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2197.7222 - val_loss: 2030.9963\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2033.1652 - val_loss: 1871.5267\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1873.5187 - val_loss: 1718.1223\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1719.9696 - val_loss: 1581.6270\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1581.5178 - val_loss: 1453.8004\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1456.2644 - val_loss: 1343.3481\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1344.4700 - val_loss: 1242.2910\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1242.5890 - val_loss: 1150.2352\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1152.2938 - val_loss: 1065.8274\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1067.6138 - val_loss: 987.3651\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 991.8036 - val_loss: 916.1207\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 921.3344 - val_loss: 852.8802\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 854.7039 - val_loss: 791.5170\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 795.6970 - val_loss: 737.7950\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 743.8897 - val_loss: 691.8097\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 699.0267 - val_loss: 649.0455\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.7905 - val_loss: 611.0331\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 621.0550 - val_loss: 578.3261\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 592.1735 - val_loss: 548.6407\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 562.8055 - val_loss: 520.9228\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.4130 - val_loss: 495.4718\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 516.3621 - val_loss: 472.9927\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 495.5588 - val_loss: 453.1575\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 477.8157 - val_loss: 432.6976\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 457.8528 - val_loss: 413.9055\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 441.6262 - val_loss: 397.4212\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 426.9124 - val_loss: 380.3883\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 412.4240 - val_loss: 366.9086\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 399.9261 - val_loss: 353.4715\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.9471 - val_loss: 341.7194\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 378.7062 - val_loss: 331.8401\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.8626 - val_loss: 321.2874\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.8273 - val_loss: 312.8645\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 350.5741 - val_loss: 303.4516\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 342.0553 - val_loss: 295.8965\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 335.0321 - val_loss: 288.1453\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 328.2639 - val_loss: 280.7788\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 320.8990 - val_loss: 273.5594\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 314.6703 - val_loss: 267.7712\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 307.9803 - val_loss: 261.9669\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 302.7714 - val_loss: 257.2510\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 48ms/step - loss: 1954.5486 - val_loss: 1176.0656\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 961.9493 - val_loss: 666.9708\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 683.3569 - val_loss: 528.0212\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 569.8394 - val_loss: 457.8777\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 499.3544 - val_loss: 388.3990\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 425.1645 - val_loss: 342.9727\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 352.7809 - val_loss: 279.0295\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 289.1797 - val_loss: 232.1883\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 231.6572 - val_loss: 199.0327\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 199.8461 - val_loss: 176.3147\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 174.6524 - val_loss: 177.2166\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.5839 - val_loss: 149.8104\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.2032 - val_loss: 148.0760\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.0019 - val_loss: 139.5614\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 129.6518 - val_loss: 149.1994\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.9744 - val_loss: 127.6784\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.0438 - val_loss: 125.5331\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 118.5493 - val_loss: 139.3728\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.3052 - val_loss: 128.0815\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 119.3426 - val_loss: 140.4541\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 114.9837 - val_loss: 118.2231\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 110.5134 - val_loss: 129.2710\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 113.5559 - val_loss: 136.0342\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.5722 - val_loss: 124.8461\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.0975 - val_loss: 120.8566\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.8332 - val_loss: 123.1397\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.6520 - val_loss: 118.5041\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.7932 - val_loss: 117.9406\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.5060 - val_loss: 136.2961\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4414 - val_loss: 131.1022\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.5358 - val_loss: 118.2391\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.2406 - val_loss: 124.3864\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.4370 - val_loss: 118.1904\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.7090 - val_loss: 123.3952\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.7347 - val_loss: 121.1949\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.3361 - val_loss: 123.5835\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.8951 - val_loss: 118.9242\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.0013 - val_loss: 119.4070\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.4891 - val_loss: 137.9755\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.6420 - val_loss: 117.9696\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.3635 - val_loss: 118.6486\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.5458 - val_loss: 130.2115\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.8313 - val_loss: 125.2293\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 106.5084 - val_loss: 117.8120\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 105.4877 - val_loss: 132.5664\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.4914 - val_loss: 118.6619\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.6594 - val_loss: 119.8285\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.9170 - val_loss: 129.4326\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.0212 - val_loss: 118.7752\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.7255 - val_loss: 123.3300\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 40962.7461 - val_loss: 13944.1992\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 8057.1167 - val_loss: 5805.0151\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 5139.8774 - val_loss: 4876.2627\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 4148.7563 - val_loss: 3967.6707\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 3397.2126 - val_loss: 3350.4231\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2829.0969 - val_loss: 2873.2185\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2407.7764 - val_loss: 2491.1665\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 2084.1865 - val_loss: 2183.8083\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1823.1746 - val_loss: 1933.0498\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1609.7998 - val_loss: 1714.8535\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1429.1598 - val_loss: 1537.3033\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1276.7935 - val_loss: 1373.2811\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1142.4263 - val_loss: 1238.6737\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1035.6726 - val_loss: 1121.0398\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 933.8944 - val_loss: 1015.6604\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 848.9752 - val_loss: 926.8642\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 773.6106 - val_loss: 841.8059\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 705.0642 - val_loss: 768.4601\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 646.6899 - val_loss: 704.3797\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 595.2136 - val_loss: 647.6851\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 547.3093 - val_loss: 594.9471\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 510.4057 - val_loss: 551.7695\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 470.1243 - val_loss: 512.8353\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.7400 - val_loss: 478.7491\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 416.2437 - val_loss: 450.8201\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 388.6232 - val_loss: 422.0040\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 369.1558 - val_loss: 402.3714\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 350.8307 - val_loss: 377.7564\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 332.9495 - val_loss: 361.4533\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 316.3846 - val_loss: 345.9343\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 303.7517 - val_loss: 331.8287\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 292.8468 - val_loss: 322.0951\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 283.5980 - val_loss: 307.2844\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 273.0143 - val_loss: 297.2757\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 265.7182 - val_loss: 291.5144\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 258.0053 - val_loss: 278.0817\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 250.3915 - val_loss: 269.6028\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 243.7066 - val_loss: 261.4449\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 236.1557 - val_loss: 254.6895\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 229.1861 - val_loss: 247.6331\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 223.8792 - val_loss: 238.6257\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 218.1945 - val_loss: 233.8021\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 212.5337 - val_loss: 225.0589\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 208.5508 - val_loss: 225.1567\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.4625 - val_loss: 211.2394\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.6281 - val_loss: 206.3138\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 193.0018 - val_loss: 196.8987\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 186.6875 - val_loss: 187.6251\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.2462 - val_loss: 177.4436\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.6131 - val_loss: 176.4683\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 15263.5703 - val_loss: 4514.7251\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1809.7668 - val_loss: 721.1983\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 744.0074 - val_loss: 670.2971\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 663.4901 - val_loss: 580.0418\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 593.0322 - val_loss: 521.5919\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.3452 - val_loss: 471.1484\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 492.6925 - val_loss: 428.5774\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 456.3584 - val_loss: 391.9727\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 422.7233 - val_loss: 363.4624\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 10ms/step - loss: 394.4507 - val_loss: 338.4536\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 370.9595 - val_loss: 317.1896\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 349.6867 - val_loss: 297.9108\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 332.4442 - val_loss: 281.6857\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.1243 - val_loss: 268.0897\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 301.2121 - val_loss: 255.5426\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 288.9770 - val_loss: 245.0894\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 276.7370 - val_loss: 234.8531\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 265.9901 - val_loss: 225.4067\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 257.1208 - val_loss: 218.6949\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 249.1358 - val_loss: 212.5699\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 242.1909 - val_loss: 205.9526\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.1911 - val_loss: 200.9681\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.4289 - val_loss: 195.1848\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 223.6221 - val_loss: 192.9181\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 218.3968 - val_loss: 187.4537\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 214.1602 - val_loss: 187.9223\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 209.0809 - val_loss: 179.8198\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.3150 - val_loss: 177.9308\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 201.7138 - val_loss: 175.0439\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 197.4662 - val_loss: 170.6883\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.6847 - val_loss: 168.4247\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.9664 - val_loss: 164.8485\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 187.7496 - val_loss: 165.1709\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4946 - val_loss: 160.0852\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.4690 - val_loss: 157.1930\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.2003 - val_loss: 155.3882\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 175.7985 - val_loss: 154.3471\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.6026 - val_loss: 154.0595\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.2627 - val_loss: 148.6217\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 169.5518 - val_loss: 148.4043\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 166.3798 - val_loss: 144.6926\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 12ms/step - loss: 164.7420 - val_loss: 142.9422\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 162.4944 - val_loss: 145.9564\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.1500 - val_loss: 141.9196\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.0441 - val_loss: 137.9065\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.4970 - val_loss: 138.2177\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.1370 - val_loss: 134.8000\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.3191 - val_loss: 135.0079\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.8298 - val_loss: 132.0691\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.0060 - val_loss: 131.8231\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 53ms/step - loss: 179587.4375 - val_loss: 115424.1562\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 75556.2188 - val_loss: 41171.1562\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 23172.5566 - val_loss: 10377.1816\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 5311.7671 - val_loss: 2560.7756\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1736.9060 - val_loss: 1541.6517\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 6ms/step - loss: 1396.9219 - val_loss: 1430.9631\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1332.9124 - val_loss: 1370.1677\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1278.5311 - val_loss: 1305.7466\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1223.3539 - val_loss: 1250.0594\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1172.8683 - val_loss: 1189.4230\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1122.4573 - val_loss: 1136.1196\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1075.9908 - val_loss: 1085.0159\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1030.8271 - val_loss: 1032.0887\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 989.1159 - val_loss: 985.3101\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 946.8041 - val_loss: 940.2840\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 909.5437 - val_loss: 902.0358\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 876.7438 - val_loss: 857.9889\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 838.7250 - val_loss: 823.4179\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 807.1912 - val_loss: 789.5781\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 778.4043 - val_loss: 756.1729\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 751.0786 - val_loss: 727.4266\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 724.8211 - val_loss: 697.5807\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 699.1671 - val_loss: 671.3701\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 676.5464 - val_loss: 647.5323\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 656.9235 - val_loss: 624.6396\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 634.3988 - val_loss: 603.1198\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 615.1520 - val_loss: 583.4022\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 597.2892 - val_loss: 564.4218\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 581.0116 - val_loss: 547.5399\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 562.2003 - val_loss: 529.9109\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 546.9714 - val_loss: 513.7178\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 534.0307 - val_loss: 497.3877\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 517.4257 - val_loss: 482.9120\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.1119 - val_loss: 469.5460\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 490.1629 - val_loss: 455.7953\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 477.4025 - val_loss: 442.7371\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 464.8098 - val_loss: 430.6451\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 453.8584 - val_loss: 417.9932\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 441.4065 - val_loss: 406.7325\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 429.5913 - val_loss: 395.0988\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 418.6755 - val_loss: 384.2224\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 408.0378 - val_loss: 373.5538\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 397.6019 - val_loss: 363.3805\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.8288 - val_loss: 354.3050\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 377.1671 - val_loss: 344.3586\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 367.3875 - val_loss: 335.3577\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 357.9926 - val_loss: 326.6095\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 349.0781 - val_loss: 318.0938\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.1368 - val_loss: 308.9528\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 331.3607 - val_loss: 301.5929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 163937.8281 - val_loss: 104348.6484\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 65590.9844 - val_loss: 37340.2734\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 21166.3262 - val_loss: 11459.3164\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 6484.3730 - val_loss: 4212.7441\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 3264.5881 - val_loss: 2898.5935\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2800.6052 - val_loss: 2676.7271\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2686.6694 - val_loss: 2580.1733\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 2585.6699 - val_loss: 2481.2920\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2483.4395 - val_loss: 2391.3713\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2379.0029 - val_loss: 2290.5312\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2276.6504 - val_loss: 2191.4871\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 2176.7036 - val_loss: 2101.4233\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2067.0667 - val_loss: 1984.5139\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1963.2278 - val_loss: 1881.1262\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1846.1746 - val_loss: 1739.1288\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1690.0638 - val_loss: 1577.1335\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1544.6646 - val_loss: 1440.8564\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1433.4984 - val_loss: 1320.9712\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1323.1664 - val_loss: 1198.9520\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1207.5465 - val_loss: 1076.5793\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1114.5278 - val_loss: 990.3003\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1032.1216 - val_loss: 904.5848\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 953.4779 - val_loss: 829.8485\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 883.2120 - val_loss: 780.3544\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 813.9954 - val_loss: 713.4935\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 749.1968 - val_loss: 655.6829\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 686.9908 - val_loss: 596.3025\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 630.1354 - val_loss: 547.4342\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 580.6231 - val_loss: 517.7862\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 545.9049 - val_loss: 492.7968\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 520.3904 - val_loss: 456.7147\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 6ms/step - loss: 493.0525 - val_loss: 440.6150\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 471.4604 - val_loss: 417.9509\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 450.5010 - val_loss: 404.0364\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 433.1208 - val_loss: 384.5980\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 416.9112 - val_loss: 371.4246\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 402.3898 - val_loss: 357.7184\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.7412 - val_loss: 347.3311\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 379.4512 - val_loss: 346.5595\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 366.9174 - val_loss: 324.9761\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 354.5725 - val_loss: 316.9283\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 343.6056 - val_loss: 303.2893\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 334.1764 - val_loss: 293.8049\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.4337 - val_loss: 286.3932\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 316.6713 - val_loss: 293.3830\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 311.8119 - val_loss: 269.2726\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 298.9241 - val_loss: 266.1910\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 291.6778 - val_loss: 261.3883\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 9ms/step - loss: 284.2573 - val_loss: 252.4542\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.6880 - val_loss: 242.4423\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 494051.7812 - val_loss: 337362.5000\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 247046.3750 - val_loss: 159860.5781\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 115598.4141 - val_loss: 72280.4531\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 52098.7812 - val_loss: 30770.9551\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 22443.7422 - val_loss: 12832.1367\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 9927.0088 - val_loss: 5743.1655\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 5125.5312 - val_loss: 3402.3850\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3586.4348 - val_loss: 2709.3525\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3065.5056 - val_loss: 2505.8525\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2859.6687 - val_loss: 2391.4473\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 2709.8945 - val_loss: 2287.2341\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2582.3469 - val_loss: 2180.5693\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2458.1477 - val_loss: 2076.0420\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2337.8076 - val_loss: 1970.8088\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2221.9709 - val_loss: 1872.8018\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 2112.7563 - val_loss: 1777.6996\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 2011.8829 - val_loss: 1698.8027\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1911.6517 - val_loss: 1611.2993\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1818.8989 - val_loss: 1531.0804\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1729.2998 - val_loss: 1457.3734\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1646.0707 - val_loss: 1389.1158\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1567.2678 - val_loss: 1319.8033\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1495.6489 - val_loss: 1259.8594\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1430.3885 - val_loss: 1207.8812\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1367.0404 - val_loss: 1148.3805\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1307.2659 - val_loss: 1102.7428\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1253.5103 - val_loss: 1061.1005\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1201.2140 - val_loss: 1013.4745\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1153.8147 - val_loss: 976.1059\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 1108.7484 - val_loss: 936.1743\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 1068.6610 - val_loss: 900.6729\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1028.7286 - val_loss: 875.4874\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 993.4394 - val_loss: 846.9975\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 959.9888 - val_loss: 817.3904\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 930.2601 - val_loss: 792.0297\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 901.5128 - val_loss: 766.5367\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 874.4338 - val_loss: 745.5350\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 849.2880 - val_loss: 728.5622\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 826.9018 - val_loss: 709.6558\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 806.4307 - val_loss: 691.7287\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 785.1906 - val_loss: 677.5978\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 765.8843 - val_loss: 661.1689\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 749.5731 - val_loss: 645.3476\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 732.9923 - val_loss: 632.7351\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 716.6745 - val_loss: 622.3410\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 8ms/step - loss: 702.1145 - val_loss: 611.5847\n",
      "Epoch 47/50\n",
      "23/23 - 1s - 26ms/step - loss: 688.5285 - val_loss: 598.1530\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 8ms/step - loss: 676.4948 - val_loss: 588.1383\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 662.9974 - val_loss: 580.9467\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 652.2828 - val_loss: 569.7012\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 60ms/step - loss: 230984.5469 - val_loss: 187707.7969\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 159876.8438 - val_loss: 132093.6719\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 114755.7422 - val_loss: 96633.1250\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 85529.4375 - val_loss: 73111.4922\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 65574.1094 - val_loss: 56575.8945\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 51257.2930 - val_loss: 44601.2656\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 40812.7422 - val_loss: 35831.4570\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 33023.0430 - val_loss: 29189.4766\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 27057.5977 - val_loss: 24067.5820\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 22382.7207 - val_loss: 20013.2539\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 18644.7773 - val_loss: 16731.8887\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 15622.0518 - val_loss: 14035.0225\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 13129.9414 - val_loss: 11794.9170\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 11057.1787 - val_loss: 9928.4551\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 9324.4160 - val_loss: 8375.2021\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 7870.7373 - val_loss: 7082.3291\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 6658.6851 - val_loss: 5998.5771\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 5650.0151 - val_loss: 5099.4092\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 4829.3013 - val_loss: 4369.2344\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 4167.9648 - val_loss: 3792.8997\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 3650.5479 - val_loss: 3333.3130\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 3243.0891 - val_loss: 2977.7498\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 2934.4109 - val_loss: 2710.8022\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 2697.8965 - val_loss: 2505.9822\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 2515.0149 - val_loss: 2348.1079\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 10ms/step - loss: 2372.4424 - val_loss: 2218.5317\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 2253.8093 - val_loss: 2120.2261\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 2158.8599 - val_loss: 2038.5964\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 1936.8552 - val_loss: 1233.1968\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 714.2378 - val_loss: 477.1024\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 471.8893 - val_loss: 390.8807\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 421.1213 - val_loss: 369.6140\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 400.5684 - val_loss: 350.6156\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 381.3899 - val_loss: 337.3648\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 367.4669 - val_loss: 326.1658\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 355.1760 - val_loss: 315.6563\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 345.1213 - val_loss: 306.9781\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 334.9626 - val_loss: 299.6622\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 326.0800 - val_loss: 292.0373\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 319.2084 - val_loss: 285.9048\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 311.5050 - val_loss: 280.0724\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 303.9392 - val_loss: 274.0558\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 297.1954 - val_loss: 268.6419\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 290.9506 - val_loss: 263.6882\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 285.2411 - val_loss: 258.3744\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 279.9336 - val_loss: 253.5028\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 273.6843 - val_loss: 248.9978\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 268.6135 - val_loss: 244.5690\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 264.6974 - val_loss: 240.0317\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 258.7975 - val_loss: 236.0141\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 320169.8438 - val_loss: 247330.2031\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 7ms/step - loss: 190075.8438 - val_loss: 135932.7500\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 16ms/step - loss: 93466.2734 - val_loss: 52071.2227\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 25901.6367 - val_loss: 5890.1309\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 12ms/step - loss: 2328.3215 - val_loss: 1174.0605\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 7ms/step - loss: 1113.2721 - val_loss: 1021.8804\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 8ms/step - loss: 948.2861 - val_loss: 916.4674\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 8ms/step - loss: 885.6712 - val_loss: 857.1883\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 8ms/step - loss: 833.0502 - val_loss: 803.8219\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 789.9199 - val_loss: 755.4398\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 743.3799 - val_loss: 714.5798\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 708.9221 - val_loss: 674.2945\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 673.8255 - val_loss: 639.5848\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 643.8416 - val_loss: 609.0666\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 616.9161 - val_loss: 581.6813\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 593.4116 - val_loss: 557.1956\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 573.9601 - val_loss: 536.2080\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 555.7055 - val_loss: 517.4165\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 539.7644 - val_loss: 500.6996\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 523.5013 - val_loss: 483.7328\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 511.1207 - val_loss: 471.0252\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 498.5621 - val_loss: 457.6627\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 487.5431 - val_loss: 446.2515\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 476.9161 - val_loss: 435.9449\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 467.4864 - val_loss: 426.8347\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 458.6760 - val_loss: 418.8389\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 451.3921 - val_loss: 409.4691\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 442.5502 - val_loss: 401.3940\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 435.3117 - val_loss: 394.2572\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 429.4413 - val_loss: 388.1056\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 9ms/step - loss: 423.2592 - val_loss: 379.8625\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 416.1057 - val_loss: 373.6727\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.7845 - val_loss: 371.8740\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.7261 - val_loss: 362.6434\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 398.1386 - val_loss: 358.5675\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 393.1568 - val_loss: 352.1913\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 388.3199 - val_loss: 349.1966\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 382.8307 - val_loss: 342.4326\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 378.7327 - val_loss: 338.2182\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 373.6904 - val_loss: 331.5906\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.0977 - val_loss: 329.1074\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 364.1864 - val_loss: 322.4845\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 361.4152 - val_loss: 322.2509\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 354.0037 - val_loss: 314.4633\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 351.6405 - val_loss: 315.3351\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.7227 - val_loss: 305.9961\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.2337 - val_loss: 304.4371\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.1489 - val_loss: 303.2071\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.4363 - val_loss: 295.6840\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 328.2701 - val_loss: 290.8714\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 146650.5781 - val_loss: 78516.7969\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 41702.7305 - val_loss: 18814.1445\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 11732.4219 - val_loss: 7258.0430\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 8157.5444 - val_loss: 6031.2837\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 7609.7441 - val_loss: 5708.8359\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 7120.8989 - val_loss: 5407.5674\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 6646.7939 - val_loss: 5081.6489\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 6180.1138 - val_loss: 4718.5044\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 5754.2402 - val_loss: 4419.3359\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 5329.2432 - val_loss: 4111.2915\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 4933.8584 - val_loss: 3840.2253\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 4553.8774 - val_loss: 3529.3127\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 4191.8394 - val_loss: 3298.6331\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 3865.5212 - val_loss: 3067.8025\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 3554.9084 - val_loss: 2815.2329\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 3268.6277 - val_loss: 2651.9009\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 3005.7021 - val_loss: 2424.6140\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 2770.4963 - val_loss: 2272.8699\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 2541.7563 - val_loss: 2088.0439\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 10ms/step - loss: 2339.2803 - val_loss: 1958.0979\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 2160.3923 - val_loss: 1838.0681\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1992.9113 - val_loss: 1685.2086\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1842.7418 - val_loss: 1586.3405\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1705.8247 - val_loss: 1493.5074\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1585.0537 - val_loss: 1386.0018\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1471.2128 - val_loss: 1308.5890\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1374.0575 - val_loss: 1248.2374\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1282.2588 - val_loss: 1169.8907\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1205.1569 - val_loss: 1099.3037\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1127.8868 - val_loss: 1050.7612\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1062.8701 - val_loss: 1004.3390\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1007.8387 - val_loss: 952.2595\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 948.4603 - val_loss: 912.2773\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 900.4165 - val_loss: 870.1268\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 857.7457 - val_loss: 831.2620\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 816.1492 - val_loss: 800.1268\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 778.6334 - val_loss: 776.7603\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 745.6070 - val_loss: 741.2386\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 715.5049 - val_loss: 714.4722\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 687.2128 - val_loss: 692.8925\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 658.4062 - val_loss: 666.1560\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 635.3837 - val_loss: 640.3342\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 610.0556 - val_loss: 627.9988\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 588.6498 - val_loss: 604.4544\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 568.2006 - val_loss: 583.6511\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 548.6948 - val_loss: 562.6087\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 531.9754 - val_loss: 542.5765\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 512.8238 - val_loss: 529.3557\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 495.6454 - val_loss: 513.5066\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 479.6309 - val_loss: 500.3269\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 173714.2188 - val_loss: 125716.2109\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 91979.8047 - val_loss: 58353.8438\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 36567.5781 - val_loss: 17823.0332\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 11783.2744 - val_loss: 8130.9941\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 7882.8184 - val_loss: 7265.1343\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 7098.5396 - val_loss: 6571.3911\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 6292.9668 - val_loss: 5721.6777\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 5322.9780 - val_loss: 4749.2344\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 4361.9448 - val_loss: 3951.3276\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 3574.9326 - val_loss: 3243.3313\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 3004.6392 - val_loss: 2776.1865\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2577.2234 - val_loss: 2419.2434\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2273.9800 - val_loss: 2141.6453\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2006.3322 - val_loss: 1910.7168\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1760.9385 - val_loss: 1689.4463\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1557.3792 - val_loss: 1504.6616\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1376.6873 - val_loss: 1327.3230\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1212.4210 - val_loss: 1184.1565\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1072.6433 - val_loss: 1055.0530\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 943.6629 - val_loss: 926.3967\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 833.9333 - val_loss: 826.6296\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 733.1005 - val_loss: 730.2115\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 651.7336 - val_loss: 652.4573\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 576.9658 - val_loss: 580.7805\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 9ms/step - loss: 510.2843 - val_loss: 513.7032\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 452.6332 - val_loss: 460.2265\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.8364 - val_loss: 413.0877\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.4687 - val_loss: 373.4492\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 327.2656 - val_loss: 334.1605\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 296.2212 - val_loss: 303.2454\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 270.1348 - val_loss: 275.4148\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.8000 - val_loss: 254.5128\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 229.7754 - val_loss: 235.4342\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 213.0495 - val_loss: 223.3357\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 200.2237 - val_loss: 206.8405\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 189.2786 - val_loss: 197.0968\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.3818 - val_loss: 186.1405\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.4434 - val_loss: 179.5005\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.4659 - val_loss: 178.4775\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.6078 - val_loss: 178.2669\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.3067 - val_loss: 162.0815\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.0776 - val_loss: 158.3729\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.2110 - val_loss: 153.8289\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.6527 - val_loss: 151.6557\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.8343 - val_loss: 147.9077\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.9330 - val_loss: 145.6404\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 138.6939 - val_loss: 143.2428\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.9124 - val_loss: 145.2986\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7986 - val_loss: 145.1033\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.4581 - val_loss: 140.7212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 50ms/step - loss: 2871.5671 - val_loss: 2213.8738\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1748.8103 - val_loss: 1503.1766\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 1197.5814 - val_loss: 980.5536\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 818.8049 - val_loss: 708.2031\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 597.4703 - val_loss: 552.2349\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 474.1034 - val_loss: 449.5529\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 378.7325 - val_loss: 381.6292\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.7049 - val_loss: 336.2834\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 291.7464 - val_loss: 314.0311\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 266.4421 - val_loss: 282.2195\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 242.8529 - val_loss: 266.5163\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 225.9054 - val_loss: 248.2580\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 219.4483 - val_loss: 234.4393\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.7189 - val_loss: 218.5942\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.5721 - val_loss: 205.4972\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.1056 - val_loss: 189.4722\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.4477 - val_loss: 179.0085\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.4407 - val_loss: 166.9389\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 143.9596 - val_loss: 159.7786\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.1552 - val_loss: 150.2491\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.6277 - val_loss: 138.5962\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.2066 - val_loss: 132.9968\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.3410 - val_loss: 126.0600\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.6511 - val_loss: 123.5710\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 108.3393 - val_loss: 118.1751\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 102.5766 - val_loss: 118.1450\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 103.6662 - val_loss: 109.3866\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 99.7035 - val_loss: 107.6246\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.3148 - val_loss: 103.4551\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 92.4949 - val_loss: 105.5523\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 90.0067 - val_loss: 107.9820\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 8ms/step - loss: 90.3370 - val_loss: 107.9289\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 84.9995 - val_loss: 95.8383\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 85.8552 - val_loss: 94.6195\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 81.6589 - val_loss: 95.6544\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 82.7375 - val_loss: 92.1625\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 79.2236 - val_loss: 93.2863\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 77.9607 - val_loss: 89.6235\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 76.4850 - val_loss: 90.3060\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 78.3943 - val_loss: 88.0632\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 76.8474 - val_loss: 87.5046\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 74.4910 - val_loss: 87.1091\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 73.7500 - val_loss: 89.3500\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 73.0605 - val_loss: 86.3823\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 76.7036 - val_loss: 85.5209\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 71.9523 - val_loss: 84.6978\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 73.1369 - val_loss: 84.3372\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 71.4488 - val_loss: 90.4543\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 70.6940 - val_loss: 83.1498\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 69.5220 - val_loss: 85.5720\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 147553.5781 - val_loss: 108797.3047\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 80533.7422 - val_loss: 59357.3711\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 43132.9453 - val_loss: 32177.0605\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 22744.2129 - val_loss: 17263.6465\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 11883.0859 - val_loss: 9568.1582\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6496.0117 - val_loss: 5813.2148\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 4035.2239 - val_loss: 4204.2051\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3027.6152 - val_loss: 3519.0332\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2618.8931 - val_loss: 3207.7017\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2434.0427 - val_loss: 3006.7778\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2303.8274 - val_loss: 2857.5881\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2196.7461 - val_loss: 2721.5278\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2097.9919 - val_loss: 2588.9170\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2004.3102 - val_loss: 2475.0977\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1919.0751 - val_loss: 2357.2825\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1834.1602 - val_loss: 2255.6841\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1759.1926 - val_loss: 2154.9307\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1687.6616 - val_loss: 2061.5554\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1621.0979 - val_loss: 1972.9177\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1558.4691 - val_loss: 1891.5918\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1497.3651 - val_loss: 1816.9551\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1442.0328 - val_loss: 1741.0552\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1386.1488 - val_loss: 1673.3671\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1335.0199 - val_loss: 1609.4222\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1288.3552 - val_loss: 1545.9054\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1243.7623 - val_loss: 1490.5710\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1201.8354 - val_loss: 1435.5538\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1164.3931 - val_loss: 1383.6201\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1124.1802 - val_loss: 1338.1549\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1090.2367 - val_loss: 1296.0516\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1055.0740 - val_loss: 1249.9915\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1023.5798 - val_loss: 1206.1920\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 992.7360 - val_loss: 1167.9125\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 963.9561 - val_loss: 1131.9131\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 936.8517 - val_loss: 1097.0571\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 910.4332 - val_loss: 1064.0591\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 886.4321 - val_loss: 1030.9979\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.5379 - val_loss: 1000.0515\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 840.4103 - val_loss: 970.0305\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 817.8794 - val_loss: 944.7734\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 797.9342 - val_loss: 917.4304\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 778.5084 - val_loss: 893.5711\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 760.0208 - val_loss: 868.2375\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 742.8505 - val_loss: 846.6226\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 724.9444 - val_loss: 823.1834\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 707.0027 - val_loss: 802.7442\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 693.7564 - val_loss: 783.4257\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 676.4351 - val_loss: 763.8282\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 661.9644 - val_loss: 745.3019\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 648.4140 - val_loss: 728.6958\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 4716.7134 - val_loss: 3280.9385\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2888.2607 - val_loss: 2338.4097\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2132.2156 - val_loss: 1799.3541\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1686.1873 - val_loss: 1440.6819\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1353.5358 - val_loss: 1166.3856\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1109.2115 - val_loss: 954.2648\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 910.6373 - val_loss: 790.8459\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 756.8855 - val_loss: 660.6411\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 633.4490 - val_loss: 556.8186\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 537.5305 - val_loss: 481.2145\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 453.1895 - val_loss: 415.1826\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 395.5674 - val_loss: 371.8141\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 341.6963 - val_loss: 330.8270\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 302.4456 - val_loss: 306.1232\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 272.0096 - val_loss: 288.7682\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 246.4678 - val_loss: 262.5285\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.7580 - val_loss: 249.7599\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 213.1821 - val_loss: 240.7899\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.1260 - val_loss: 234.4980\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 190.9407 - val_loss: 225.4661\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.0188 - val_loss: 219.6059\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.3744 - val_loss: 215.3390\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.7633 - val_loss: 209.0962\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 161.6571 - val_loss: 204.7674\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 155.7686 - val_loss: 202.4446\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.7558 - val_loss: 195.8505\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6795 - val_loss: 190.9007\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.9580 - val_loss: 186.0238\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 138.8623 - val_loss: 184.9502\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7476 - val_loss: 180.0223\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 130.2859 - val_loss: 174.2988\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 128.0337 - val_loss: 170.0279\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.1922 - val_loss: 166.9333\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.6793 - val_loss: 163.8139\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4776 - val_loss: 161.5296\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.8452 - val_loss: 160.6451\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.9084 - val_loss: 153.1539\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.7592 - val_loss: 150.3971\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 108.6210 - val_loss: 147.0701\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.5243 - val_loss: 153.4800\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.9501 - val_loss: 143.0858\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.6120 - val_loss: 140.9564\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 103.0661 - val_loss: 139.2365\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 101.0718 - val_loss: 136.7902\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.7614 - val_loss: 134.5962\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 99.0241 - val_loss: 133.7130\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 98.1655 - val_loss: 130.7953\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 97.2046 - val_loss: 129.6485\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 97.4693 - val_loss: 128.9357\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 8ms/step - loss: 94.8645 - val_loss: 126.5702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 44ms/step - loss: 53363.7109 - val_loss: 35081.5352\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 23063.1738 - val_loss: 12114.0840\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 6739.6416 - val_loss: 2975.6421\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 1791.6614 - val_loss: 1247.1962\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1116.8687 - val_loss: 1105.6918\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1038.9487 - val_loss: 1036.0985\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 969.7139 - val_loss: 973.8419\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.4858 - val_loss: 909.2128\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 844.7876 - val_loss: 852.3412\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 789.2620 - val_loss: 799.7230\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 740.2834 - val_loss: 751.7842\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 695.6665 - val_loss: 707.3674\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 655.3151 - val_loss: 669.0386\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 620.0041 - val_loss: 630.0880\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 585.4091 - val_loss: 596.2381\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 554.5767 - val_loss: 567.5211\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 527.1345 - val_loss: 538.4719\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 502.1005 - val_loss: 513.3388\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 480.4832 - val_loss: 487.9165\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 458.6158 - val_loss: 467.0020\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 439.4104 - val_loss: 444.4426\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 421.5436 - val_loss: 426.1474\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 404.3036 - val_loss: 407.8660\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 388.5613 - val_loss: 391.6383\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 374.5679 - val_loss: 374.4227\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 360.8303 - val_loss: 360.4814\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 348.0578 - val_loss: 346.7444\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 335.5018 - val_loss: 333.4392\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 324.4247 - val_loss: 321.0410\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 314.6616 - val_loss: 309.2466\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 304.2279 - val_loss: 297.8203\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 295.0717 - val_loss: 288.7961\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 286.0265 - val_loss: 278.2379\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.8399 - val_loss: 268.7754\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 270.3364 - val_loss: 261.4315\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 263.6421 - val_loss: 252.8875\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 255.8121 - val_loss: 244.8983\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 249.2004 - val_loss: 237.6143\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 243.5489 - val_loss: 230.2840\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 237.1104 - val_loss: 225.1507\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 232.0479 - val_loss: 218.7076\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 225.9928 - val_loss: 212.1344\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 221.3416 - val_loss: 206.0483\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 216.3955 - val_loss: 200.7522\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.8217 - val_loss: 195.7507\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.2578 - val_loss: 192.7869\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.0347 - val_loss: 186.4254\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 198.4351 - val_loss: 182.4221\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.3488 - val_loss: 179.1105\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.4854 - val_loss: 174.0230\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 7219.9741 - val_loss: 4827.9497\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 3839.4041 - val_loss: 3756.0405\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 3122.1724 - val_loss: 2928.6780\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2503.4983 - val_loss: 2341.1787\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2006.4607 - val_loss: 1883.8411\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1629.2458 - val_loss: 1548.3752\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1334.0618 - val_loss: 1282.1915\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1099.8348 - val_loss: 1068.8800\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 955.5541 - val_loss: 940.4185\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 816.7198 - val_loss: 822.4124\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 735.6741 - val_loss: 741.8845\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 663.8641 - val_loss: 685.8208\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 626.4972 - val_loss: 664.3900\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 581.9590 - val_loss: 593.7952\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 545.5255 - val_loss: 570.3745\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 520.1979 - val_loss: 531.6658\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 492.7164 - val_loss: 510.7353\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 470.4011 - val_loss: 484.7080\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 9ms/step - loss: 452.3391 - val_loss: 465.1847\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 434.8719 - val_loss: 449.0021\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 423.2435 - val_loss: 425.3398\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 403.2435 - val_loss: 409.2350\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.6622 - val_loss: 393.1659\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 375.2912 - val_loss: 378.4689\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 361.5537 - val_loss: 369.6782\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 356.9073 - val_loss: 354.7907\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 355.4903 - val_loss: 340.5194\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 329.3391 - val_loss: 325.0923\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 323.6750 - val_loss: 320.1801\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 307.9505 - val_loss: 303.7923\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 299.0894 - val_loss: 298.3695\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 291.5785 - val_loss: 283.2349\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 282.2457 - val_loss: 274.6987\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 277.5875 - val_loss: 264.3971\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 264.6337 - val_loss: 269.3844\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 257.1081 - val_loss: 256.8957\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 248.6904 - val_loss: 241.6905\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 250.0177 - val_loss: 239.3477\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 244.8213 - val_loss: 242.2767\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 234.3267 - val_loss: 221.4446\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 225.5906 - val_loss: 217.6144\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 217.8536 - val_loss: 211.7012\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 211.8663 - val_loss: 211.6576\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 213.4680 - val_loss: 200.0545\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 203.6528 - val_loss: 203.6034\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 205.4509 - val_loss: 198.8021\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.9018 - val_loss: 188.9883\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.0645 - val_loss: 183.8931\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.5662 - val_loss: 178.7569\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 183.6292 - val_loss: 175.0870\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 48ms/step - loss: 378003.6250 - val_loss: 238563.8594\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 161947.5938 - val_loss: 89315.6094\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 56687.5547 - val_loss: 26536.9160\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 16752.6875 - val_loss: 7431.5063\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 6035.1870 - val_loss: 3521.8306\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4009.5767 - val_loss: 3044.5940\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3747.6558 - val_loss: 2969.8564\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3639.5759 - val_loss: 2891.9392\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 3542.0403 - val_loss: 2809.9900\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 3435.7651 - val_loss: 2732.3777\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 3333.9565 - val_loss: 2656.3308\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 3230.8567 - val_loss: 2569.0264\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 3124.1318 - val_loss: 2494.0723\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 3022.0947 - val_loss: 2414.5129\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2921.9719 - val_loss: 2332.4868\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 2819.0627 - val_loss: 2263.9309\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 8ms/step - loss: 2723.9797 - val_loss: 2189.2632\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 2620.2288 - val_loss: 2110.1816\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 2526.2891 - val_loss: 2040.7473\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 2438.9465 - val_loss: 1976.4573\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 2341.7969 - val_loss: 1903.2090\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 2253.8770 - val_loss: 1842.5186\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 2169.7742 - val_loss: 1779.2205\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 2088.0039 - val_loss: 1720.9460\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 2005.2194 - val_loss: 1661.1279\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1928.3629 - val_loss: 1603.4540\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1854.2609 - val_loss: 1549.8293\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1778.3524 - val_loss: 1493.8540\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1710.8788 - val_loss: 1443.1929\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1641.4236 - val_loss: 1399.4500\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 1577.3726 - val_loss: 1348.7285\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1515.0620 - val_loss: 1303.4618\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 1461.2620 - val_loss: 1259.0258\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 11ms/step - loss: 1400.5337 - val_loss: 1220.2383\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 1339.5253 - val_loss: 1174.7400\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 1285.3763 - val_loss: 1135.4829\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 1234.7109 - val_loss: 1098.4991\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 1183.0498 - val_loss: 1061.2059\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 1135.6986 - val_loss: 1022.6181\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 1090.6232 - val_loss: 988.1890\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 1045.3248 - val_loss: 956.4489\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 1003.1982 - val_loss: 922.5291\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 967.6458 - val_loss: 892.7756\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 925.3831 - val_loss: 861.7980\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 884.4654 - val_loss: 834.9340\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 851.5721 - val_loss: 803.6670\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 815.7314 - val_loss: 778.4725\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 782.6400 - val_loss: 750.3147\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 749.9210 - val_loss: 724.7672\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 718.1517 - val_loss: 699.4465\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 58ms/step - loss: 45998.1367 - val_loss: 32489.3828\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 22016.2617 - val_loss: 12233.9160\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 7340.2637 - val_loss: 3252.8213\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2626.9031 - val_loss: 1794.7762\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2138.5601 - val_loss: 1665.9867\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 2003.9076 - val_loss: 1570.9449\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1884.3190 - val_loss: 1473.7931\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1771.9319 - val_loss: 1387.5331\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1662.6635 - val_loss: 1295.8463\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1560.9556 - val_loss: 1215.5232\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1466.0872 - val_loss: 1141.3726\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1374.3396 - val_loss: 1073.2687\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1297.1520 - val_loss: 1008.4875\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1216.3611 - val_loss: 951.1823\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1146.5444 - val_loss: 897.8484\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1080.8016 - val_loss: 848.0237\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1020.3326 - val_loss: 802.1107\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 963.6856 - val_loss: 760.0174\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 913.4631 - val_loss: 719.2786\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 864.1650 - val_loss: 682.8589\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 818.5747 - val_loss: 648.9138\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 778.0229 - val_loss: 617.5912\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 739.3531 - val_loss: 589.3895\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 704.3195 - val_loss: 562.5865\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 672.6031 - val_loss: 536.3582\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 638.7218 - val_loss: 515.1231\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 611.4946 - val_loss: 494.0016\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 585.1358 - val_loss: 474.1550\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 561.5897 - val_loss: 456.0210\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 538.7566 - val_loss: 440.1169\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 517.4163 - val_loss: 424.0178\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 498.3135 - val_loss: 409.7133\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 479.9983 - val_loss: 396.6243\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 463.3277 - val_loss: 384.0603\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.5784 - val_loss: 372.4165\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 432.3539 - val_loss: 362.0134\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.0016 - val_loss: 351.1448\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 405.9583 - val_loss: 342.5436\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 392.7500 - val_loss: 332.7599\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 380.7196 - val_loss: 325.1080\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 371.2442 - val_loss: 317.0066\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 361.2145 - val_loss: 310.5774\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 351.5659 - val_loss: 303.9312\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 343.1609 - val_loss: 297.3729\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 335.5987 - val_loss: 292.0784\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 328.1981 - val_loss: 286.3643\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 323.3269 - val_loss: 281.4429\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 315.4784 - val_loss: 276.5551\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 308.4508 - val_loss: 272.2395\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 302.2018 - val_loss: 268.0848\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 66ms/step - loss: 65643.6953 - val_loss: 40831.0039\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 6ms/step - loss: 27743.5820 - val_loss: 15502.5303\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 9381.3984 - val_loss: 4583.2773\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 2887.6499 - val_loss: 2465.6326\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 1880.1176 - val_loss: 2033.5139\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1600.5288 - val_loss: 1753.9529\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1421.0020 - val_loss: 1584.8533\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 1300.8634 - val_loss: 1451.8345\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 7ms/step - loss: 1192.2754 - val_loss: 1331.9009\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1096.8323 - val_loss: 1223.4420\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1008.5644 - val_loss: 1123.7806\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 924.8505 - val_loss: 1037.3912\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 845.5126 - val_loss: 946.6747\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 772.4146 - val_loss: 860.0220\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 710.2507 - val_loss: 779.5919\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 650.7420 - val_loss: 706.9666\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 589.1099 - val_loss: 609.4963\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 6ms/step - loss: 522.1621 - val_loss: 520.7958\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 448.7058 - val_loss: 445.2707\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 386.3941 - val_loss: 387.6411\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 338.2082 - val_loss: 342.8474\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 301.6564 - val_loss: 308.2398\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 270.0765 - val_loss: 281.6303\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 246.2821 - val_loss: 259.5732\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 227.9635 - val_loss: 245.7151\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 7ms/step - loss: 214.5708 - val_loss: 230.4489\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 199.4707 - val_loss: 220.1931\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 191.0564 - val_loss: 210.2242\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 181.3381 - val_loss: 202.3038\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 174.9946 - val_loss: 196.3954\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 168.3169 - val_loss: 190.7922\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 7ms/step - loss: 164.2664 - val_loss: 187.9971\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 161.2583 - val_loss: 184.9408\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.9660 - val_loss: 180.3041\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 155.6843 - val_loss: 176.8608\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.0793 - val_loss: 174.2217\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.5029 - val_loss: 171.1709\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.0889 - val_loss: 169.3142\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 144.6526 - val_loss: 166.7160\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 7ms/step - loss: 143.1749 - val_loss: 164.6068\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 140.5502 - val_loss: 163.9105\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.5743 - val_loss: 160.0211\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 7ms/step - loss: 137.2328 - val_loss: 158.0794\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.8110 - val_loss: 156.0206\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 134.5254 - val_loss: 154.5600\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 135.0459 - val_loss: 152.9607\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 129.5873 - val_loss: 151.7231\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.1095 - val_loss: 147.7510\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.9224 - val_loss: 144.6174\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 124.6210 - val_loss: 141.8088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 79ms/step - loss: 23214.3867 - val_loss: 5130.9531\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 3584.7517 - val_loss: 3307.7405\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 6ms/step - loss: 2892.8196 - val_loss: 2622.3696\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 2503.0610 - val_loss: 2376.3513\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2248.2971 - val_loss: 2153.0120\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 2045.8811 - val_loss: 1956.5634\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1858.6395 - val_loss: 1780.6329\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1687.6134 - val_loss: 1620.7714\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 1540.0938 - val_loss: 1477.6182\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 1407.8877 - val_loss: 1355.2651\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1292.4491 - val_loss: 1242.7987\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1188.0027 - val_loss: 1148.7753\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 1100.9792 - val_loss: 1066.5732\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1028.4869 - val_loss: 1000.5475\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 6ms/step - loss: 971.4745 - val_loss: 942.9083\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 904.6520 - val_loss: 889.0524\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 859.6118 - val_loss: 848.2178\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 815.3253 - val_loss: 806.1010\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 785.8888 - val_loss: 772.9344\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 747.0798 - val_loss: 740.1771\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 717.9223 - val_loss: 715.4954\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 6ms/step - loss: 690.0959 - val_loss: 687.2854\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 666.1512 - val_loss: 665.7673\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 6ms/step - loss: 641.1935 - val_loss: 640.9265\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 6ms/step - loss: 618.8735 - val_loss: 620.7568\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 599.5686 - val_loss: 600.1579\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 580.0845 - val_loss: 583.3386\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 11ms/step - loss: 563.3754 - val_loss: 565.2056\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 548.6093 - val_loss: 549.0106\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 6ms/step - loss: 528.0355 - val_loss: 530.0803\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 14ms/step - loss: 513.2749 - val_loss: 516.6486\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 495.4716 - val_loss: 500.5676\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 485.1023 - val_loss: 483.0161\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 464.5269 - val_loss: 467.8125\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 449.9731 - val_loss: 455.1342\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 435.8561 - val_loss: 440.9675\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 421.8299 - val_loss: 428.6579\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 412.8732 - val_loss: 422.2302\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 398.9441 - val_loss: 410.1626\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 386.1111 - val_loss: 391.5874\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.9048 - val_loss: 379.8361\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 371.4561 - val_loss: 372.1920\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 355.3115 - val_loss: 359.5947\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 346.4496 - val_loss: 350.8228\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.2951 - val_loss: 339.3491\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 323.2240 - val_loss: 327.3835\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 316.5312 - val_loss: 318.3416\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 312.0070 - val_loss: 310.1929\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 295.2733 - val_loss: 299.5695\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 287.9925 - val_loss: 292.8335\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 49ms/step - loss: 197416.3438 - val_loss: 155949.7969\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 122461.6250 - val_loss: 91888.0469\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 66068.5469 - val_loss: 42127.7656\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 25392.9766 - val_loss: 11809.7188\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 6992.7310 - val_loss: 4017.2112\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4090.8967 - val_loss: 3557.8916\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 3830.7690 - val_loss: 3355.9995\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3599.1846 - val_loss: 3166.4048\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 3398.1145 - val_loss: 2982.1091\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 3202.8108 - val_loss: 2811.0630\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 3020.3459 - val_loss: 2646.1262\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 2843.9248 - val_loss: 2491.2122\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 2675.3979 - val_loss: 2345.5947\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2516.2886 - val_loss: 2203.6582\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2370.2329 - val_loss: 2070.1709\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 2224.5613 - val_loss: 1944.3507\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 2085.3586 - val_loss: 1819.2263\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1947.8011 - val_loss: 1693.4841\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1812.1460 - val_loss: 1571.7627\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1685.8568 - val_loss: 1461.7292\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1561.3790 - val_loss: 1353.2007\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 7ms/step - loss: 1451.0983 - val_loss: 1255.5533\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1346.5525 - val_loss: 1161.2563\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1256.1486 - val_loss: 1080.2897\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1169.6350 - val_loss: 1013.4711\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1099.1270 - val_loss: 948.5632\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 1027.0085 - val_loss: 886.4800\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 963.9433 - val_loss: 834.7711\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 908.6254 - val_loss: 783.6886\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 853.3604 - val_loss: 736.9871\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 803.3445 - val_loss: 693.1071\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 759.2921 - val_loss: 652.8880\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 715.2167 - val_loss: 619.0061\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 676.6274 - val_loss: 584.4574\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 642.3774 - val_loss: 554.4467\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 609.7294 - val_loss: 526.2228\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 578.0865 - val_loss: 501.2167\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 548.4276 - val_loss: 476.8056\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 523.8784 - val_loss: 455.4612\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 497.5358 - val_loss: 434.3278\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 7ms/step - loss: 473.2079 - val_loss: 415.1443\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 7ms/step - loss: 452.1956 - val_loss: 397.5586\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 431.8989 - val_loss: 386.2750\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 8ms/step - loss: 412.5406 - val_loss: 368.3458\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 10ms/step - loss: 388.9036 - val_loss: 351.3672\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 367.6445 - val_loss: 332.9985\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 341.7285 - val_loss: 312.2671\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 312.2766 - val_loss: 291.7916\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 283.6963 - val_loss: 270.6070\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 252.8561 - val_loss: 243.1821\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 6067.7710 - val_loss: 5306.4023\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 4065.0649 - val_loss: 3898.4700\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 2973.0645 - val_loss: 2843.5200\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2258.7622 - val_loss: 2178.9900\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 7ms/step - loss: 1753.3608 - val_loss: 1711.3119\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 1388.0820 - val_loss: 1367.3859\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 6ms/step - loss: 1106.8643 - val_loss: 1080.4692\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 895.2737 - val_loss: 873.0788\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 734.7875 - val_loss: 738.0804\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 597.1763 - val_loss: 584.1005\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 494.2497 - val_loss: 476.1877\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 406.7023 - val_loss: 402.5238\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 352.5000 - val_loss: 350.8377\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 304.3201 - val_loss: 304.2395\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 262.1460 - val_loss: 249.7671\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 237.8277 - val_loss: 225.3332\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 213.7453 - val_loss: 210.4203\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 195.4746 - val_loss: 194.0521\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 187.4961 - val_loss: 183.3973\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 178.9876 - val_loss: 173.4742\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.1972 - val_loss: 171.2566\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.5818 - val_loss: 160.3003\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 155.8628 - val_loss: 161.6623\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 158.9306 - val_loss: 154.6817\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 151.5365 - val_loss: 149.9214\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 7ms/step - loss: 146.5406 - val_loss: 146.4428\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 146.3949 - val_loss: 145.0595\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.8035 - val_loss: 144.1582\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 6ms/step - loss: 136.5613 - val_loss: 150.2124\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.5055 - val_loss: 136.2781\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 133.9555 - val_loss: 134.0494\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 132.1550 - val_loss: 132.6735\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.4216 - val_loss: 130.9336\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 127.8448 - val_loss: 128.9785\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 126.5219 - val_loss: 135.0898\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 128.3380 - val_loss: 131.7164\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.1773 - val_loss: 127.1890\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 121.1672 - val_loss: 125.6806\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.2614 - val_loss: 123.8525\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 123.8425 - val_loss: 124.2955\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 118.4214 - val_loss: 120.1594\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 118.6516 - val_loss: 123.5648\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.0596 - val_loss: 122.0536\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 120.3766 - val_loss: 118.4363\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 117.1434 - val_loss: 118.6183\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 116.4583 - val_loss: 122.7804\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 115.1639 - val_loss: 126.1428\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 115.5413 - val_loss: 123.1960\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 115.8018 - val_loss: 115.5252\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 115.6244 - val_loss: 124.3330\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 34589.1602 - val_loss: 22138.1523\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 16298.0068 - val_loss: 11086.2598\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 11ms/step - loss: 9843.7285 - val_loss: 8268.4561\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 8216.5811 - val_loss: 7385.9888\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 7388.9951 - val_loss: 6634.9468\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 6644.8643 - val_loss: 5975.4541\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 5963.6299 - val_loss: 5389.8975\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 5376.1152 - val_loss: 4850.7817\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 4826.8237 - val_loss: 4398.7642\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 4390.6680 - val_loss: 3950.0122\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 3945.3210 - val_loss: 3581.3037\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 3580.4812 - val_loss: 3269.0911\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 3270.5239 - val_loss: 2998.6741\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 3006.8994 - val_loss: 2762.6050\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 2779.8245 - val_loss: 2567.0469\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 2588.4026 - val_loss: 2394.7175\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 6ms/step - loss: 2423.9592 - val_loss: 2240.2400\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 2269.6431 - val_loss: 2116.7568\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 7ms/step - loss: 2134.6479 - val_loss: 2000.6217\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 2017.9645 - val_loss: 1893.5198\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 1906.6198 - val_loss: 1796.2672\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1805.2495 - val_loss: 1705.5946\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 1713.3632 - val_loss: 1623.5168\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1629.8348 - val_loss: 1544.4579\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 1550.9071 - val_loss: 1475.0618\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1478.7821 - val_loss: 1407.9708\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 1409.3785 - val_loss: 1343.7294\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 1345.8978 - val_loss: 1282.8762\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1285.5000 - val_loss: 1226.8591\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 1227.5890 - val_loss: 1172.4733\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 1173.8351 - val_loss: 1120.4685\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 1124.3899 - val_loss: 1073.0693\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 1074.8997 - val_loss: 1029.8069\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 1029.1621 - val_loss: 984.1162\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 984.9588 - val_loss: 943.9073\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 945.8467 - val_loss: 905.7403\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 907.0445 - val_loss: 868.3824\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 870.0964 - val_loss: 835.1072\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 836.6285 - val_loss: 802.6301\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 804.6318 - val_loss: 772.0119\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 774.4099 - val_loss: 743.1735\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 745.6687 - val_loss: 717.2235\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 718.3450 - val_loss: 690.0473\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 692.3953 - val_loss: 665.6169\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 668.0555 - val_loss: 642.8498\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 645.1180 - val_loss: 621.6276\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 7ms/step - loss: 624.1712 - val_loss: 601.5558\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 603.2504 - val_loss: 582.5253\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 584.3392 - val_loss: 564.4821\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 566.3240 - val_loss: 546.3263\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 63ms/step - loss: 669760.0625 - val_loss: 511582.2500\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 405787.2812 - val_loss: 304144.4062\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 238719.8906 - val_loss: 176721.2031\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 137053.6094 - val_loss: 99526.3750\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 7ms/step - loss: 75982.9141 - val_loss: 53951.3555\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 40417.4688 - val_loss: 28071.8574\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 20651.5098 - val_loss: 13985.7705\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 10238.4844 - val_loss: 6901.7393\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 5154.3794 - val_loss: 3623.8496\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 7ms/step - loss: 2888.7651 - val_loss: 2167.4697\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1938.8750 - val_loss: 1569.8091\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 1567.3135 - val_loss: 1350.0731\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 7ms/step - loss: 1432.4187 - val_loss: 1263.5079\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1379.6760 - val_loss: 1226.2386\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1355.5621 - val_loss: 1202.0779\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 6ms/step - loss: 1336.5728 - val_loss: 1187.6001\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1320.8782 - val_loss: 1172.9406\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1303.1936 - val_loss: 1161.4045\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 6ms/step - loss: 1286.5454 - val_loss: 1147.1678\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1268.9440 - val_loss: 1135.1042\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1252.1036 - val_loss: 1122.2207\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1235.1484 - val_loss: 1106.9585\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 1217.6566 - val_loss: 1093.9146\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 1200.1257 - val_loss: 1080.2090\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 11ms/step - loss: 1183.6177 - val_loss: 1066.2830\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 1166.2336 - val_loss: 1052.4442\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 1148.6775 - val_loss: 1039.3989\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1131.7014 - val_loss: 1025.4419\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 7ms/step - loss: 1115.0989 - val_loss: 1011.1257\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 1097.7115 - val_loss: 998.2392\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 1080.9780 - val_loss: 984.3607\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 1064.4286 - val_loss: 969.9053\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 1047.8376 - val_loss: 957.3578\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 1030.3169 - val_loss: 942.7211\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 6ms/step - loss: 1014.4080 - val_loss: 929.0759\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 997.5810 - val_loss: 916.1893\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 981.3278 - val_loss: 903.7650\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 965.3596 - val_loss: 890.3206\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 7ms/step - loss: 949.9950 - val_loss: 877.3836\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 7ms/step - loss: 934.7638 - val_loss: 863.9808\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 918.4478 - val_loss: 851.4929\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 903.7103 - val_loss: 839.2988\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 888.2300 - val_loss: 825.7717\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 873.6530 - val_loss: 813.9377\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 858.2030 - val_loss: 800.2278\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 843.5394 - val_loss: 787.5795\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 828.4492 - val_loss: 775.7549\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 814.2154 - val_loss: 763.0894\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 800.0334 - val_loss: 751.2631\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 8ms/step - loss: 785.4827 - val_loss: 739.2499\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 55ms/step - loss: 78484.8750 - val_loss: 25580.1660\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 14435.2432 - val_loss: 8318.7266\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 8008.2559 - val_loss: 7588.0776\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 6961.2393 - val_loss: 6391.2744\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 6059.0986 - val_loss: 5583.7896\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 5299.1938 - val_loss: 4907.8018\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 7ms/step - loss: 4609.0698 - val_loss: 4279.2578\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 4053.3071 - val_loss: 3756.5381\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 3556.4365 - val_loss: 3273.9023\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 3129.9956 - val_loss: 2864.7732\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 2743.9473 - val_loss: 2524.9119\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 2412.3872 - val_loss: 2207.4805\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 2117.2607 - val_loss: 1939.8226\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1870.7938 - val_loss: 1699.5010\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1657.8522 - val_loss: 1497.8190\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1469.5536 - val_loss: 1332.5269\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1310.9252 - val_loss: 1185.2332\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 1177.4047 - val_loss: 1056.8848\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1051.1239 - val_loss: 949.1617\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 947.1343 - val_loss: 857.1250\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 6ms/step - loss: 855.3029 - val_loss: 773.4437\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 781.6239 - val_loss: 702.9717\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 711.2332 - val_loss: 642.8121\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 654.2953 - val_loss: 593.3677\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 607.1793 - val_loss: 545.3707\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 558.6526 - val_loss: 508.1623\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 518.6783 - val_loss: 470.5630\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 8ms/step - loss: 482.5261 - val_loss: 441.3946\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 453.9393 - val_loss: 412.4880\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 7ms/step - loss: 426.6943 - val_loss: 389.5439\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 6ms/step - loss: 401.2975 - val_loss: 367.0260\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 378.8298 - val_loss: 349.9107\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 361.7281 - val_loss: 330.4330\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 341.4655 - val_loss: 315.3590\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 325.9124 - val_loss: 299.9369\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 310.8218 - val_loss: 287.9641\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 298.3705 - val_loss: 273.8871\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 283.4321 - val_loss: 264.6200\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 10ms/step - loss: 272.9743 - val_loss: 252.4250\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.5458 - val_loss: 242.7034\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 252.4735 - val_loss: 234.0134\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 244.6334 - val_loss: 228.0247\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 238.1026 - val_loss: 219.6779\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 229.0786 - val_loss: 212.4401\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 222.9213 - val_loss: 206.2881\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 215.8279 - val_loss: 200.9833\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 210.1108 - val_loss: 194.1860\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 204.0211 - val_loss: 189.2431\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 7ms/step - loss: 199.1426 - val_loss: 183.7346\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 7ms/step - loss: 195.6649 - val_loss: 179.8544\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 53ms/step - loss: 26633.6445 - val_loss: 6181.1436\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 4236.7983 - val_loss: 3372.1899\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 3371.5876 - val_loss: 2796.4871\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 2907.0728 - val_loss: 2500.2139\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 2563.6501 - val_loss: 2174.8379\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2236.6038 - val_loss: 1897.8503\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1949.6956 - val_loss: 1645.9880\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 1685.3235 - val_loss: 1430.2544\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 1451.2404 - val_loss: 1223.9639\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1249.0499 - val_loss: 1053.5875\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 1069.0139 - val_loss: 911.4485\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 917.5397 - val_loss: 779.4161\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 786.4437 - val_loss: 677.7456\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 676.4487 - val_loss: 585.0323\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 584.3414 - val_loss: 509.8752\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 506.4687 - val_loss: 446.6631\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 440.9504 - val_loss: 394.8914\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 385.2703 - val_loss: 348.6796\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 341.2533 - val_loss: 318.4559\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 306.4786 - val_loss: 286.6361\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 276.3817 - val_loss: 259.3605\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 251.4605 - val_loss: 239.1185\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 228.9803 - val_loss: 223.9724\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 211.9561 - val_loss: 209.1646\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.0360 - val_loss: 196.6908\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.5539 - val_loss: 190.4310\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 174.7587 - val_loss: 177.7371\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.9107 - val_loss: 173.8578\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.9359 - val_loss: 164.2236\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 150.9846 - val_loss: 158.7281\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.7869 - val_loss: 157.2458\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.1123 - val_loss: 149.0491\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.6852 - val_loss: 145.2560\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.4072 - val_loss: 141.9153\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.7702 - val_loss: 142.5293\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.9030 - val_loss: 136.7168\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 7ms/step - loss: 124.0473 - val_loss: 134.5533\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.9510 - val_loss: 137.0861\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.4169 - val_loss: 130.4710\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.5731 - val_loss: 131.9197\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.8768 - val_loss: 135.8927\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.7894 - val_loss: 126.5191\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.1136 - val_loss: 125.5302\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.1229 - val_loss: 124.6486\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.0733 - val_loss: 124.3669\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.9209 - val_loss: 127.0847\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 8ms/step - loss: 111.2226 - val_loss: 127.6368\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.2437 - val_loss: 123.1733\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.4784 - val_loss: 123.6504\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.3582 - val_loss: 122.8590\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 475032.4688 - val_loss: 363423.5312\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 299452.2812 - val_loss: 217886.1406\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 174588.0781 - val_loss: 119800.3594\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 94071.6875 - val_loss: 60020.8984\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 46420.4805 - val_loss: 27932.3242\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 21959.8320 - val_loss: 12967.3115\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 10876.5352 - val_loss: 7204.1489\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 6800.5430 - val_loss: 5293.0947\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 5358.6016 - val_loss: 4820.7749\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 4918.4663 - val_loss: 4655.6157\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 4706.7188 - val_loss: 4535.4663\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 4547.8237 - val_loss: 4402.1104\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 4395.1392 - val_loss: 4264.9536\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 4245.2700 - val_loss: 4110.0151\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 4090.1057 - val_loss: 3953.6184\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 3943.3513 - val_loss: 3811.1587\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 3793.5188 - val_loss: 3672.3831\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 3651.3062 - val_loss: 3528.6553\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 3504.1775 - val_loss: 3403.0854\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 3367.4958 - val_loss: 3269.3350\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 3231.1487 - val_loss: 3134.0840\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 3099.3269 - val_loss: 3001.3660\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 2967.2700 - val_loss: 2879.3938\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 2842.0840 - val_loss: 2756.6667\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 2722.1096 - val_loss: 2637.9119\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 2605.1726 - val_loss: 2523.4302\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 2490.0356 - val_loss: 2418.6125\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 2379.4155 - val_loss: 2306.1138\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 2277.8577 - val_loss: 2217.3069\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 2170.9590 - val_loss: 2105.8691\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 2070.2419 - val_loss: 2013.6964\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1975.9691 - val_loss: 1922.4572\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 1884.3518 - val_loss: 1838.6986\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 1798.4657 - val_loss: 1756.0352\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 1713.0660 - val_loss: 1672.6334\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1633.3519 - val_loss: 1593.7803\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1556.3755 - val_loss: 1530.2450\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 1481.8755 - val_loss: 1448.3140\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 1410.6283 - val_loss: 1380.3859\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 1343.7151 - val_loss: 1317.9617\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 1279.0503 - val_loss: 1255.0959\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 1219.2870 - val_loss: 1199.9641\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 1159.4286 - val_loss: 1137.7521\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 1103.4161 - val_loss: 1088.4076\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 1051.2163 - val_loss: 1035.6842\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 998.6023 - val_loss: 982.8459\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 951.2261 - val_loss: 936.2300\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 904.1174 - val_loss: 897.4756\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 861.6766 - val_loss: 855.2300\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 821.0738 - val_loss: 812.9367\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 5755.6807 - val_loss: 4144.4663\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3428.5427 - val_loss: 2771.4580\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2501.6079 - val_loss: 1944.2137\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1817.6399 - val_loss: 1398.5726\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1287.3344 - val_loss: 967.5010\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 849.8480 - val_loss: 700.9286\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 601.1460 - val_loss: 525.0353\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 451.7160 - val_loss: 424.1254\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.2268 - val_loss: 356.4604\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 311.6234 - val_loss: 309.3408\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 267.3013 - val_loss: 270.2065\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.0481 - val_loss: 244.9373\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 212.7411 - val_loss: 230.5669\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.5535 - val_loss: 221.9316\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 188.7941 - val_loss: 213.8825\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 177.3907 - val_loss: 195.9781\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.7428 - val_loss: 187.9262\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 8ms/step - loss: 161.0136 - val_loss: 181.4035\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.2236 - val_loss: 186.2389\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.7097 - val_loss: 168.5384\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.8465 - val_loss: 162.9022\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.8133 - val_loss: 160.6939\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.3386 - val_loss: 151.7058\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.9966 - val_loss: 150.3465\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 125.5085 - val_loss: 140.8949\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.2800 - val_loss: 151.2964\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.5668 - val_loss: 136.2377\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.9235 - val_loss: 151.6840\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.1079 - val_loss: 141.6461\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.0927 - val_loss: 133.6634\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.3682 - val_loss: 129.5974\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.4019 - val_loss: 139.7947\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.8254 - val_loss: 136.6030\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.6640 - val_loss: 137.7577\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 10ms/step - loss: 117.5210 - val_loss: 124.4907\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.7670 - val_loss: 123.6859\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.7396 - val_loss: 125.2021\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.6347 - val_loss: 123.3451\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.7772 - val_loss: 128.3280\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.6123 - val_loss: 121.8730\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.6499 - val_loss: 125.8225\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.0601 - val_loss: 121.1089\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 112.2581 - val_loss: 124.7031\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 115.0595 - val_loss: 129.4489\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 112.8482 - val_loss: 117.3315\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.5533 - val_loss: 117.4202\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.3393 - val_loss: 116.3303\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.6700 - val_loss: 144.0928\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.4825 - val_loss: 115.6321\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.5832 - val_loss: 116.6690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 85017.8672 - val_loss: 37975.5352\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 18840.7344 - val_loss: 5918.5054\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 3310.5576 - val_loss: 1953.7589\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2053.7803 - val_loss: 1877.5455\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1975.3754 - val_loss: 1793.9495\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1884.4377 - val_loss: 1719.8528\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1802.6359 - val_loss: 1653.9565\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1721.8771 - val_loss: 1590.9501\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1646.1855 - val_loss: 1531.0798\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1574.8132 - val_loss: 1469.4384\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1500.6056 - val_loss: 1410.5345\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1435.3733 - val_loss: 1360.7424\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1372.9894 - val_loss: 1307.3672\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1312.9047 - val_loss: 1258.9366\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1256.9331 - val_loss: 1218.4286\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1205.7322 - val_loss: 1179.1102\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1158.7762 - val_loss: 1143.2933\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1114.6221 - val_loss: 1109.4875\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1078.7889 - val_loss: 1082.6958\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1040.3346 - val_loss: 1053.4663\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1009.1095 - val_loss: 1032.2827\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 981.2247 - val_loss: 1008.7607\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 955.3896 - val_loss: 991.2844\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 932.2743 - val_loss: 968.4743\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 910.3085 - val_loss: 953.7025\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 893.6398 - val_loss: 937.8430\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 875.0823 - val_loss: 918.4400\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 859.6508 - val_loss: 900.8507\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 846.6922 - val_loss: 889.5588\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 830.5823 - val_loss: 879.4878\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 818.0565 - val_loss: 860.6884\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 806.2112 - val_loss: 851.7631\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 8ms/step - loss: 795.8914 - val_loss: 837.0715\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 782.5638 - val_loss: 826.6443\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 775.0603 - val_loss: 825.3524\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 760.6366 - val_loss: 801.2183\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 751.8571 - val_loss: 798.0131\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 746.1703 - val_loss: 784.6925\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 734.6921 - val_loss: 771.6814\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 720.8185 - val_loss: 759.5966\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.6906 - val_loss: 754.3309\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 702.6851 - val_loss: 740.2827\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 694.1071 - val_loss: 729.3178\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 687.6985 - val_loss: 728.3680\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 681.8382 - val_loss: 715.7264\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 670.7722 - val_loss: 704.5042\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 658.0255 - val_loss: 696.9336\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.8553 - val_loss: 685.7137\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 641.9688 - val_loss: 685.8171\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 636.2490 - val_loss: 667.6414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 44ms/step - loss: 9832.0752 - val_loss: 7175.8550\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 6663.3579 - val_loss: 4805.1094\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 4408.4736 - val_loss: 3261.5105\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2977.6318 - val_loss: 2329.2412\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 2134.5579 - val_loss: 1758.2703\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1620.5787 - val_loss: 1423.5598\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1302.9469 - val_loss: 1201.1041\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1084.2098 - val_loss: 1074.2185\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 948.3317 - val_loss: 975.9292\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 871.6017 - val_loss: 910.0083\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 800.0541 - val_loss: 856.0177\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 754.1413 - val_loss: 822.3495\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 718.7212 - val_loss: 777.7653\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 692.0120 - val_loss: 745.4480\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 659.4512 - val_loss: 710.5790\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 634.4874 - val_loss: 683.3214\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.2242 - val_loss: 651.1232\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 594.1204 - val_loss: 631.4103\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 562.7496 - val_loss: 598.4727\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 6ms/step - loss: 536.6563 - val_loss: 581.4745\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 8ms/step - loss: 515.8633 - val_loss: 548.0466\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 487.4883 - val_loss: 547.3907\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 489.9834 - val_loss: 507.5089\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 462.7016 - val_loss: 472.3734\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 437.0783 - val_loss: 465.1538\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 417.7587 - val_loss: 427.6644\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 6ms/step - loss: 390.5694 - val_loss: 409.7339\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 8ms/step - loss: 378.0890 - val_loss: 390.7521\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 361.4278 - val_loss: 384.3374\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.8798 - val_loss: 357.1967\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.0633 - val_loss: 373.9684\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.7738 - val_loss: 335.3643\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 301.0629 - val_loss: 313.4611\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.6798 - val_loss: 319.4892\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 287.3611 - val_loss: 286.8324\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 275.1474 - val_loss: 276.2813\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.5958 - val_loss: 268.2024\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.9975 - val_loss: 258.2189\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 245.3653 - val_loss: 244.1719\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 233.2269 - val_loss: 261.6948\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 8ms/step - loss: 230.8159 - val_loss: 227.4245\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.4399 - val_loss: 219.1638\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 208.7048 - val_loss: 209.1192\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 200.1695 - val_loss: 201.0782\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 198.0884 - val_loss: 197.6723\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 189.2376 - val_loss: 190.2203\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4041 - val_loss: 179.5147\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.6598 - val_loss: 173.1404\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 170.5502 - val_loss: 177.4935\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 168.8803 - val_loss: 163.9661\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 1876.3064 - val_loss: 1605.4171\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1203.4048 - val_loss: 1114.1903\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 917.8937 - val_loss: 868.0865\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 712.4591 - val_loss: 651.2664\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 535.9355 - val_loss: 489.2799\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.1729 - val_loss: 366.8776\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 308.4886 - val_loss: 274.5543\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 239.8979 - val_loss: 212.7997\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.8258 - val_loss: 175.4263\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 165.0457 - val_loss: 145.4220\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.9270 - val_loss: 131.3338\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 133.7679 - val_loss: 118.2461\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 125.4598 - val_loss: 113.0094\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.8278 - val_loss: 106.3337\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 117.7911 - val_loss: 103.9111\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 113.9175 - val_loss: 101.1699\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.3424 - val_loss: 105.8076\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 110.0588 - val_loss: 95.6376\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 109.2598 - val_loss: 96.8545\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.9294 - val_loss: 93.4772\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 10ms/step - loss: 101.1539 - val_loss: 87.9147\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 99.3495 - val_loss: 87.0400\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.5603 - val_loss: 84.9690\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 96.5135 - val_loss: 86.5436\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.9319 - val_loss: 88.1444\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 96.3259 - val_loss: 83.7415\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 95.9108 - val_loss: 81.3110\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 91.7631 - val_loss: 89.2642\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 92.7057 - val_loss: 80.3714\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 89.4848 - val_loss: 77.9479\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 89.9342 - val_loss: 79.4517\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 88.7103 - val_loss: 77.1985\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 87.9620 - val_loss: 76.1116\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 90.7112 - val_loss: 74.7680\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 86.2713 - val_loss: 77.5719\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 84.6883 - val_loss: 75.1778\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 82.6975 - val_loss: 73.1296\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 81.8768 - val_loss: 73.5665\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 81.1309 - val_loss: 72.0842\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 82.0802 - val_loss: 71.5325\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 78.9079 - val_loss: 72.2418\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 79.2123 - val_loss: 70.4465\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 78.3686 - val_loss: 70.0140\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 77.3639 - val_loss: 73.0326\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 81.6222 - val_loss: 70.6261\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 77.6211 - val_loss: 69.3653\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 75.1709 - val_loss: 68.4239\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 75.1509 - val_loss: 70.8931\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 8ms/step - loss: 74.8604 - val_loss: 68.2620\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 74.0291 - val_loss: 67.7291\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 142396.3594 - val_loss: 104400.0938\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 79457.5703 - val_loss: 55481.6328\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 40904.4062 - val_loss: 27364.3398\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 19793.4473 - val_loss: 12802.5459\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 9344.4502 - val_loss: 6218.2803\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 4889.8091 - val_loss: 3520.5513\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3176.1174 - val_loss: 2571.6226\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 2594.1384 - val_loss: 2256.2620\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2397.8975 - val_loss: 2135.8000\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2302.4956 - val_loss: 2064.5789\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2234.7493 - val_loss: 2002.3876\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 2169.7336 - val_loss: 1939.9772\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2104.8945 - val_loss: 1879.9501\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 2043.5641 - val_loss: 1817.5126\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1977.1481 - val_loss: 1756.9458\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1913.3031 - val_loss: 1696.4541\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1850.7612 - val_loss: 1639.0742\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1787.2957 - val_loss: 1580.8928\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1726.0900 - val_loss: 1523.4558\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1671.7883 - val_loss: 1467.9474\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1605.7773 - val_loss: 1414.1646\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1548.0157 - val_loss: 1361.8411\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1491.0647 - val_loss: 1308.4941\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1435.7965 - val_loss: 1256.6028\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1380.0367 - val_loss: 1208.7084\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1328.7522 - val_loss: 1160.9004\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1277.5408 - val_loss: 1115.6339\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1227.3766 - val_loss: 1071.2260\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1180.1522 - val_loss: 1027.1813\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1134.3621 - val_loss: 986.8102\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1087.7728 - val_loss: 948.8683\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1046.3109 - val_loss: 910.7686\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 1004.5317 - val_loss: 874.7776\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 964.6595 - val_loss: 838.2636\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 925.8521 - val_loss: 804.5505\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 889.1553 - val_loss: 773.7289\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 853.6819 - val_loss: 743.0331\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 820.1894 - val_loss: 713.7396\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 787.0827 - val_loss: 686.9402\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 756.1281 - val_loss: 659.4766\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 727.2671 - val_loss: 634.6125\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 697.2753 - val_loss: 610.6759\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 670.7280 - val_loss: 588.2080\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 645.4669 - val_loss: 567.0708\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 621.5247 - val_loss: 546.3884\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 596.7827 - val_loss: 527.7422\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 575.2302 - val_loss: 508.8685\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 553.6237 - val_loss: 491.4444\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 534.6148 - val_loss: 475.2701\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 514.3925 - val_loss: 460.5456\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 2s - 79ms/step - loss: 141986.7969 - val_loss: 77451.3672\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 48757.2812 - val_loss: 20066.3906\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 12648.4355 - val_loss: 6975.0444\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 6356.1538 - val_loss: 6310.5483\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 8ms/step - loss: 5661.1982 - val_loss: 5727.8486\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 5142.3857 - val_loss: 5163.1855\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 4676.9863 - val_loss: 4674.0107\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 4255.5532 - val_loss: 4230.6221\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 6ms/step - loss: 3864.0693 - val_loss: 3854.9263\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 6ms/step - loss: 3507.1980 - val_loss: 3492.4736\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 3189.1731 - val_loss: 3171.2969\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 2900.3018 - val_loss: 2893.2566\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 2648.6143 - val_loss: 2636.6211\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 6ms/step - loss: 2414.7341 - val_loss: 2390.5042\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 2202.1946 - val_loss: 2199.1462\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 2016.7302 - val_loss: 2015.4945\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1855.2753 - val_loss: 1849.2090\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1704.2119 - val_loss: 1718.9183\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1578.9811 - val_loss: 1572.2278\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 7ms/step - loss: 1450.9811 - val_loss: 1471.3673\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1350.9469 - val_loss: 1366.6099\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1253.5474 - val_loss: 1272.7899\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1172.6610 - val_loss: 1195.7134\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1097.0547 - val_loss: 1117.5332\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.0425 - val_loss: 1059.2994\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 5ms/step - loss: 969.5361 - val_loss: 1001.4351\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 7ms/step - loss: 911.8806 - val_loss: 946.0317\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 861.6486 - val_loss: 900.7334\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 817.0307 - val_loss: 859.1401\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 774.9889 - val_loss: 820.8531\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 737.1790 - val_loss: 785.4175\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 704.1685 - val_loss: 750.8555\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 670.2022 - val_loss: 719.8930\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 641.7449 - val_loss: 695.2891\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 5ms/step - loss: 614.7848 - val_loss: 667.2504\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 6ms/step - loss: 590.7889 - val_loss: 643.2862\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 566.0687 - val_loss: 621.7516\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 5ms/step - loss: 545.9319 - val_loss: 602.0390\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 526.2827 - val_loss: 582.6085\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 508.1564 - val_loss: 564.5511\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 487.5271 - val_loss: 548.1422\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 471.9799 - val_loss: 533.0729\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 455.8571 - val_loss: 516.8744\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 442.9183 - val_loss: 502.9613\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 426.7060 - val_loss: 489.0891\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 415.0890 - val_loss: 476.7378\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 400.9437 - val_loss: 464.6809\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 389.5010 - val_loss: 453.1144\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 377.8494 - val_loss: 441.9806\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 367.9790 - val_loss: 431.3730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 3433.3896 - val_loss: 3991.9155\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3008.9717 - val_loss: 3388.6104\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2583.5469 - val_loss: 2919.5151\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2244.8293 - val_loss: 2561.7122\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1973.2286 - val_loss: 2264.9500\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1720.3217 - val_loss: 1972.1228\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1511.9929 - val_loss: 1729.8811\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1284.9030 - val_loss: 1361.8511\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 968.9449 - val_loss: 1024.9482\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 729.2435 - val_loss: 784.1938\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 585.0707 - val_loss: 625.1446\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 462.9970 - val_loss: 506.2884\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.4647 - val_loss: 427.9068\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 328.1741 - val_loss: 384.1159\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.7424 - val_loss: 326.6929\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 260.6728 - val_loss: 287.0798\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.2440 - val_loss: 261.0789\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 226.4505 - val_loss: 248.5853\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.7341 - val_loss: 235.9520\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.1487 - val_loss: 254.7760\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 209.2460 - val_loss: 213.1351\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 198.4196 - val_loss: 204.9130\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 188.2172 - val_loss: 210.1303\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 182.1585 - val_loss: 198.4519\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.2333 - val_loss: 190.4816\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.4564 - val_loss: 185.2145\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.1788 - val_loss: 180.6237\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.8839 - val_loss: 178.6658\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.9864 - val_loss: 170.4576\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.1487 - val_loss: 181.8211\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.0087 - val_loss: 167.1265\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.6813 - val_loss: 160.8177\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2226 - val_loss: 160.1944\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.9764 - val_loss: 157.4577\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 145.4016 - val_loss: 159.7122\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 143.1130 - val_loss: 152.4102\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.0138 - val_loss: 147.9306\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.3028 - val_loss: 153.6530\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 6ms/step - loss: 135.7715 - val_loss: 175.4856\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 136.8235 - val_loss: 149.6161\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.9410 - val_loss: 143.6936\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.0019 - val_loss: 141.7058\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 6ms/step - loss: 131.2444 - val_loss: 141.5664\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 133.0998 - val_loss: 158.6809\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 130.2312 - val_loss: 139.8854\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 6ms/step - loss: 125.7787 - val_loss: 137.4035\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.2126 - val_loss: 140.6695\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 122.9181 - val_loss: 139.3600\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.7257 - val_loss: 132.8885\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.7385 - val_loss: 160.9225\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 49ms/step - loss: 609433.1875 - val_loss: 480355.8438\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 395622.5625 - val_loss: 304072.8438\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 245901.8281 - val_loss: 184872.7188\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 5ms/step - loss: 146733.2344 - val_loss: 108263.3750\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 84332.4141 - val_loss: 60901.8203\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 46801.9297 - val_loss: 33594.6289\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 25815.3906 - val_loss: 18550.4355\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 14552.1260 - val_loss: 11019.9688\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 9058.0127 - val_loss: 7357.8906\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 6488.0610 - val_loss: 5655.7251\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 5327.3594 - val_loss: 4937.0732\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 4799.2603 - val_loss: 4574.2778\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 4538.5952 - val_loss: 4358.2578\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 4352.4937 - val_loss: 4204.5508\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 4192.7900 - val_loss: 4060.1196\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 4037.9712 - val_loss: 3907.7351\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 3874.1631 - val_loss: 3734.5911\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 3691.9783 - val_loss: 3551.4231\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 3491.3303 - val_loss: 3318.8962\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 3265.5188 - val_loss: 3038.4932\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 2969.2583 - val_loss: 2746.0781\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 2665.8091 - val_loss: 2405.6599\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 2359.7288 - val_loss: 2141.8076\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 2137.7217 - val_loss: 1946.6349\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1967.8787 - val_loss: 1821.6660\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1845.9780 - val_loss: 1727.5428\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1749.5082 - val_loss: 1662.1559\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1675.3308 - val_loss: 1614.8588\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 1618.0199 - val_loss: 1577.7594\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1572.5680 - val_loss: 1551.9290\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1534.8833 - val_loss: 1525.5516\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1501.6437 - val_loss: 1503.0729\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 1474.5028 - val_loss: 1487.8657\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 1453.4302 - val_loss: 1470.8204\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 1428.8844 - val_loss: 1458.2876\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1411.0363 - val_loss: 1441.3308\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1388.1233 - val_loss: 1426.2412\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 6ms/step - loss: 1368.4180 - val_loss: 1416.1801\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 1348.2383 - val_loss: 1400.5392\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 1328.2114 - val_loss: 1385.0125\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 6ms/step - loss: 1311.3818 - val_loss: 1373.7085\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 6ms/step - loss: 1295.3051 - val_loss: 1357.0691\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 1274.9943 - val_loss: 1352.9679\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 5ms/step - loss: 1257.1519 - val_loss: 1332.1057\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 1240.1078 - val_loss: 1316.5657\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 1226.2657 - val_loss: 1304.0017\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 6ms/step - loss: 1213.2478 - val_loss: 1284.8877\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 6ms/step - loss: 1189.8229 - val_loss: 1263.3553\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 6ms/step - loss: 1174.5103 - val_loss: 1253.2404\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 6ms/step - loss: 1156.4750 - val_loss: 1240.6060\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 54ms/step - loss: 6454.2495 - val_loss: 2392.2766\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 1243.2776 - val_loss: 778.5012\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 710.8093 - val_loss: 566.5281\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 7ms/step - loss: 524.0821 - val_loss: 445.1145\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 431.6800 - val_loss: 373.0532\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 362.5186 - val_loss: 316.1343\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 309.8248 - val_loss: 278.2198\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 279.0604 - val_loss: 248.5995\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 253.2885 - val_loss: 226.3009\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 235.2387 - val_loss: 208.6062\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 217.3173 - val_loss: 191.4750\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 205.7853 - val_loss: 184.2672\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.6309 - val_loss: 176.9688\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 180.5208 - val_loss: 163.5614\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.6858 - val_loss: 161.6284\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.0769 - val_loss: 146.4613\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.6376 - val_loss: 139.8739\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.5563 - val_loss: 135.7023\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.2583 - val_loss: 130.8286\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.3251 - val_loss: 130.8290\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 130.2486 - val_loss: 126.5916\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.1978 - val_loss: 122.4935\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.3216 - val_loss: 122.3191\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.0363 - val_loss: 118.0584\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 121.2244 - val_loss: 114.5453\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 114.3878 - val_loss: 112.1830\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 112.9454 - val_loss: 110.3358\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 111.6570 - val_loss: 107.7810\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 107.7519 - val_loss: 113.9467\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 106.6097 - val_loss: 103.8625\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 104.1579 - val_loss: 103.1263\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 105.6431 - val_loss: 101.7211\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 101.2101 - val_loss: 111.8370\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 100.2245 - val_loss: 99.1147\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 98.6280 - val_loss: 101.0134\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 93.4766 - val_loss: 95.8600\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 93.6108 - val_loss: 97.5504\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 91.5764 - val_loss: 92.9117\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 89.1349 - val_loss: 91.7042\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 87.5578 - val_loss: 90.5161\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 87.4446 - val_loss: 95.1205\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 86.2503 - val_loss: 88.7791\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 86.1656 - val_loss: 88.4628\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 85.3551 - val_loss: 95.2992\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 84.7861 - val_loss: 85.9298\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 84.9961 - val_loss: 85.2447\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 82.3030 - val_loss: 86.4798\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 79.8323 - val_loss: 86.3897\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 87.4233 - val_loss: 88.5203\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 79.1589 - val_loss: 82.1963\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 33400.6484 - val_loss: 9296.5303\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 2963.9363 - val_loss: 685.0388\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 673.6052 - val_loss: 685.2755\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 577.9333 - val_loss: 618.5359\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 535.7097 - val_loss: 589.0139\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 503.4831 - val_loss: 545.9598\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 473.3759 - val_loss: 510.4695\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 444.6493 - val_loss: 479.9236\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.0424 - val_loss: 447.7793\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 392.4987 - val_loss: 420.2931\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.3515 - val_loss: 390.1715\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 345.4267 - val_loss: 365.9510\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 324.5139 - val_loss: 342.9392\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 304.6855 - val_loss: 320.5256\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 286.3712 - val_loss: 301.8341\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 270.4023 - val_loss: 284.8606\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 255.6817 - val_loss: 267.4145\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 242.2181 - val_loss: 252.2689\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.2958 - val_loss: 240.3562\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.0689 - val_loss: 226.6893\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 209.6961 - val_loss: 218.8341\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 200.4613 - val_loss: 207.2822\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 191.9915 - val_loss: 198.3168\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.4115 - val_loss: 192.6915\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.3211 - val_loss: 182.5380\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.6750 - val_loss: 178.6872\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.6365 - val_loss: 171.5296\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.2593 - val_loss: 165.9293\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.9604 - val_loss: 162.1707\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.9044 - val_loss: 157.1003\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.0785 - val_loss: 154.9311\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 147.6053 - val_loss: 149.2040\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.9426 - val_loss: 147.2545\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.2128 - val_loss: 146.0926\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 139.4082 - val_loss: 140.6934\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.4156 - val_loss: 141.3710\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.4011 - val_loss: 136.2031\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.2078 - val_loss: 137.4962\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 131.9651 - val_loss: 134.2696\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 129.1873 - val_loss: 130.8717\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 127.3445 - val_loss: 132.6465\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 126.3985 - val_loss: 127.2939\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 124.6010 - val_loss: 126.4406\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.0966 - val_loss: 124.8375\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 123.9064 - val_loss: 123.2332\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 120.4705 - val_loss: 129.2378\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 119.9859 - val_loss: 120.9239\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 10ms/step - loss: 118.8375 - val_loss: 120.0110\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 118.2672 - val_loss: 122.4677\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 116.6183 - val_loss: 119.6350\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 6102.5298 - val_loss: 4562.9385\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3708.8853 - val_loss: 3280.3765\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2721.9370 - val_loss: 2378.0173\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2010.4467 - val_loss: 1857.2273\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1586.8761 - val_loss: 1518.6412\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1311.1682 - val_loss: 1256.5303\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 1086.9513 - val_loss: 1055.5366\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 6ms/step - loss: 928.3866 - val_loss: 887.9960\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 810.0724 - val_loss: 777.3644\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 726.8277 - val_loss: 725.0644\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 652.7046 - val_loss: 636.5851\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 5ms/step - loss: 585.7358 - val_loss: 577.0569\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 539.4132 - val_loss: 525.9288\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 498.4598 - val_loss: 485.2431\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 462.9910 - val_loss: 454.9643\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 8ms/step - loss: 430.3405 - val_loss: 420.1935\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 7ms/step - loss: 399.7525 - val_loss: 397.4858\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 9ms/step - loss: 376.6769 - val_loss: 380.9054\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 15ms/step - loss: 360.1170 - val_loss: 347.6371\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 10ms/step - loss: 332.9811 - val_loss: 327.9960\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 7ms/step - loss: 314.3329 - val_loss: 313.8145\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 8ms/step - loss: 297.7092 - val_loss: 298.3046\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 6ms/step - loss: 283.8776 - val_loss: 283.5428\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 5ms/step - loss: 269.9102 - val_loss: 278.1295\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 7ms/step - loss: 260.6122 - val_loss: 261.1639\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 6ms/step - loss: 249.8958 - val_loss: 252.8481\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 242.6072 - val_loss: 256.3656\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 6ms/step - loss: 237.4671 - val_loss: 240.7299\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 5ms/step - loss: 226.6279 - val_loss: 221.3424\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 5ms/step - loss: 218.8004 - val_loss: 218.1316\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 216.6607 - val_loss: 214.4926\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 5ms/step - loss: 208.5705 - val_loss: 210.8270\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 7ms/step - loss: 205.0945 - val_loss: 200.0113\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 5ms/step - loss: 198.9855 - val_loss: 192.9012\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 7ms/step - loss: 196.7231 - val_loss: 188.1148\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 193.1159 - val_loss: 194.6681\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 6ms/step - loss: 193.6654 - val_loss: 190.2529\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 7ms/step - loss: 186.9470 - val_loss: 179.8123\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 182.5618 - val_loss: 173.5192\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 6ms/step - loss: 182.4732 - val_loss: 170.5758\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 180.8246 - val_loss: 172.1661\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 177.3589 - val_loss: 165.6689\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 5ms/step - loss: 173.6842 - val_loss: 163.6643\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 6ms/step - loss: 171.9045 - val_loss: 162.0408\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 6ms/step - loss: 169.1624 - val_loss: 160.3387\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 5ms/step - loss: 170.7288 - val_loss: 157.2719\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 5ms/step - loss: 169.5490 - val_loss: 154.4717\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 7ms/step - loss: 171.2866 - val_loss: 155.6631\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 5ms/step - loss: 164.0700 - val_loss: 154.9969\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 11ms/step - loss: 161.8839 - val_loss: 153.2425\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 64ms/step - loss: 296073.6562 - val_loss: 201201.9531\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 136723.7656 - val_loss: 84125.2734\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 7ms/step - loss: 53136.7539 - val_loss: 29996.4336\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 6ms/step - loss: 17712.1641 - val_loss: 9721.0645\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 5ms/step - loss: 5760.8857 - val_loss: 3865.2075\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 5ms/step - loss: 2850.2078 - val_loss: 2599.4612\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 2312.1899 - val_loss: 2382.8552\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 2192.2825 - val_loss: 2292.4390\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 2120.6108 - val_loss: 2212.4856\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 2048.2935 - val_loss: 2135.9702\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 6ms/step - loss: 1978.0562 - val_loss: 2067.5923\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 6ms/step - loss: 1906.9015 - val_loss: 1988.6226\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1835.0414 - val_loss: 1916.5188\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 1766.3708 - val_loss: 1847.1064\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 5ms/step - loss: 1699.5609 - val_loss: 1775.9569\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 5ms/step - loss: 1635.1571 - val_loss: 1710.5079\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 5ms/step - loss: 1571.8545 - val_loss: 1644.8423\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 7ms/step - loss: 1510.1727 - val_loss: 1579.5627\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 1453.2566 - val_loss: 1520.0841\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 5ms/step - loss: 1398.2545 - val_loss: 1456.2250\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 5ms/step - loss: 1341.1124 - val_loss: 1403.7739\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 5ms/step - loss: 1289.4547 - val_loss: 1351.8142\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 7ms/step - loss: 1240.0411 - val_loss: 1296.2439\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 1192.6321 - val_loss: 1244.6024\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1147.4587 - val_loss: 1199.0369\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1105.8586 - val_loss: 1151.2798\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1063.9086 - val_loss: 1112.0179\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.2798 - val_loss: 1066.4623\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 987.7394 - val_loss: 1030.7739\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 954.9567 - val_loss: 991.6570\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 920.6517 - val_loss: 958.1299\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 888.2339 - val_loss: 922.5625\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 858.9560 - val_loss: 891.0537\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 830.0753 - val_loss: 859.8059\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 803.6458 - val_loss: 830.3246\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 777.3395 - val_loss: 802.9252\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 5ms/step - loss: 753.5219 - val_loss: 778.8005\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 731.4078 - val_loss: 750.3679\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 708.9096 - val_loss: 729.2695\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 688.5733 - val_loss: 704.1909\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 668.2311 - val_loss: 682.1500\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.5418 - val_loss: 665.6074\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 631.9074 - val_loss: 641.9656\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 613.6495 - val_loss: 626.9636\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 598.3582 - val_loss: 606.2580\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 584.6102 - val_loss: 590.9258\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 567.9636 - val_loss: 572.3763\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 553.5359 - val_loss: 557.8154\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 540.0327 - val_loss: 546.0548\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 526.6398 - val_loss: 528.1045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 16553.2891 - val_loss: 6667.5913\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 4930.5449 - val_loss: 2039.1608\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 2300.0549 - val_loss: 1704.0610\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2007.6311 - val_loss: 1611.8524\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1841.9926 - val_loss: 1476.1902\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1681.4830 - val_loss: 1322.4717\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1532.5529 - val_loss: 1205.5010\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1391.1018 - val_loss: 1099.6769\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1259.0026 - val_loss: 995.2554\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1137.0707 - val_loss: 899.6310\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1026.7415 - val_loss: 807.3138\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 928.0023 - val_loss: 733.8469\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 8ms/step - loss: 837.5760 - val_loss: 660.8560\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 757.1716 - val_loss: 601.2769\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 685.3452 - val_loss: 549.2162\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 622.5114 - val_loss: 497.3768\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 566.2997 - val_loss: 455.4443\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 5ms/step - loss: 517.0663 - val_loss: 413.7347\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 5ms/step - loss: 472.1272 - val_loss: 381.2787\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 431.2894 - val_loss: 348.2011\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.4242 - val_loss: 322.9654\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.8772 - val_loss: 302.0304\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 339.0141 - val_loss: 281.3933\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 315.8954 - val_loss: 258.9360\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.3199 - val_loss: 246.0441\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 274.7122 - val_loss: 229.4532\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 258.2995 - val_loss: 217.6837\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.7478 - val_loss: 206.4056\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 230.5803 - val_loss: 194.3363\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 219.1232 - val_loss: 187.5416\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 209.1425 - val_loss: 177.8933\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 200.5743 - val_loss: 171.6772\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.7547 - val_loss: 164.9674\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 185.5898 - val_loss: 159.8799\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 179.1092 - val_loss: 154.0291\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.9070 - val_loss: 149.9260\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.1252 - val_loss: 145.3535\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.4272 - val_loss: 142.0482\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 160.7863 - val_loss: 138.2079\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.3731 - val_loss: 136.8792\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.2662 - val_loss: 133.5078\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 151.7167 - val_loss: 131.3889\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.1028 - val_loss: 128.6614\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6105 - val_loss: 126.9435\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.6303 - val_loss: 125.5819\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.6232 - val_loss: 124.9081\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.4448 - val_loss: 121.7598\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.4857 - val_loss: 120.8841\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.9956 - val_loss: 120.0730\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 136.4507 - val_loss: 118.7755\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 7593.7925 - val_loss: 3179.4529\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 3433.5454 - val_loss: 2517.9404\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 5ms/step - loss: 2657.9409 - val_loss: 2171.4519\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2292.8298 - val_loss: 1845.9893\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1960.5161 - val_loss: 1572.2944\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1671.9736 - val_loss: 1337.9266\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1433.6074 - val_loss: 1134.3123\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1217.2681 - val_loss: 957.6870\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1043.7957 - val_loss: 811.3013\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 876.3513 - val_loss: 689.1657\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 750.4255 - val_loss: 591.2652\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 647.9937 - val_loss: 505.8885\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 558.8535 - val_loss: 434.3880\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 488.1296 - val_loss: 378.8725\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 10ms/step - loss: 426.2232 - val_loss: 330.4963\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 375.0489 - val_loss: 304.0551\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.3857 - val_loss: 263.2184\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 303.0269 - val_loss: 235.8344\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 273.6911 - val_loss: 229.6791\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 259.7178 - val_loss: 204.0729\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 238.5138 - val_loss: 183.9001\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 220.3434 - val_loss: 173.5152\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 206.9834 - val_loss: 167.9087\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 197.7474 - val_loss: 158.2150\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 188.2406 - val_loss: 158.5684\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.1910 - val_loss: 147.6850\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.1990 - val_loss: 153.0594\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 172.1125 - val_loss: 146.2442\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 167.3334 - val_loss: 135.5291\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.7061 - val_loss: 132.6814\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.3525 - val_loss: 131.7828\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 159.5257 - val_loss: 141.2479\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.9425 - val_loss: 129.4609\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.6603 - val_loss: 130.4776\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 8ms/step - loss: 149.6842 - val_loss: 126.3397\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2561 - val_loss: 126.8100\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6736 - val_loss: 125.0825\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 144.8050 - val_loss: 125.3819\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 142.9176 - val_loss: 124.9382\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.8206 - val_loss: 130.4052\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 140.2475 - val_loss: 121.9423\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 141.2142 - val_loss: 120.9450\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.2504 - val_loss: 119.6412\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 137.2567 - val_loss: 119.8500\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 5ms/step - loss: 137.8179 - val_loss: 118.8037\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.2946 - val_loss: 120.3878\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 134.6396 - val_loss: 118.3448\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 139.5815 - val_loss: 124.3983\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 135.2737 - val_loss: 123.1477\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 132.3473 - val_loss: 124.9176\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 55125.1445 - val_loss: 41875.0977\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 32247.8340 - val_loss: 24394.1152\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 18380.2793 - val_loss: 13607.1533\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 9957.9521 - val_loss: 7180.9126\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 5062.5132 - val_loss: 3559.0911\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2451.7437 - val_loss: 1753.7223\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1255.0253 - val_loss: 1010.4258\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 823.3659 - val_loss: 747.0092\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 692.3154 - val_loss: 666.4315\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 649.7789 - val_loss: 637.9405\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 629.8411 - val_loss: 617.0886\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 613.0919 - val_loss: 598.6654\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 596.6704 - val_loss: 580.4749\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 580.3083 - val_loss: 563.2246\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 565.2334 - val_loss: 547.1902\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.4838 - val_loss: 530.8953\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 534.6186 - val_loss: 517.1723\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 520.0708 - val_loss: 500.5152\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 505.5663 - val_loss: 486.2338\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 492.0941 - val_loss: 472.2430\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 478.3531 - val_loss: 457.9783\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 465.8495 - val_loss: 444.3423\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 453.1415 - val_loss: 432.5643\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 441.3591 - val_loss: 420.3951\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 429.1781 - val_loss: 408.4896\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.1811 - val_loss: 397.2284\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 407.4193 - val_loss: 386.3395\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 396.8709 - val_loss: 376.5089\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 386.9274 - val_loss: 365.9068\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 377.1297 - val_loss: 356.5755\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 368.1646 - val_loss: 347.4864\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 359.1889 - val_loss: 339.5620\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 6ms/step - loss: 350.8203 - val_loss: 329.1960\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 342.5589 - val_loss: 321.5960\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 334.6419 - val_loss: 314.4911\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 5ms/step - loss: 326.9673 - val_loss: 306.5761\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 319.9475 - val_loss: 299.2814\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 312.8564 - val_loss: 294.1277\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 5ms/step - loss: 306.5126 - val_loss: 285.6849\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 299.5356 - val_loss: 280.2261\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 293.7861 - val_loss: 273.4342\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 288.0634 - val_loss: 267.3495\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 281.8263 - val_loss: 263.5425\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 276.3024 - val_loss: 257.0164\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 271.4611 - val_loss: 252.2056\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 266.4597 - val_loss: 246.5823\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 261.4201 - val_loss: 242.9116\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 256.8153 - val_loss: 237.7451\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 252.1824 - val_loss: 234.5241\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 248.9818 - val_loss: 229.9507\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 71432.6250 - val_loss: 42881.1992\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 5ms/step - loss: 24506.9492 - val_loss: 10982.9297\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 5135.7017 - val_loss: 2250.1970\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1705.1233 - val_loss: 1625.1056\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 1587.3326 - val_loss: 1536.6548\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 1479.9517 - val_loss: 1470.1482\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1402.8467 - val_loss: 1387.5282\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1327.6737 - val_loss: 1314.3971\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1257.1250 - val_loss: 1244.1333\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 1193.2947 - val_loss: 1182.1893\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1133.5845 - val_loss: 1120.8911\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1075.5712 - val_loss: 1065.4702\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1024.4060 - val_loss: 1014.0049\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 973.9763 - val_loss: 965.3629\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 931.7642 - val_loss: 920.2767\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 887.1815 - val_loss: 878.5496\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 847.1578 - val_loss: 837.7407\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 809.2678 - val_loss: 800.8226\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 773.9365 - val_loss: 763.8033\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 739.7737 - val_loss: 729.8633\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 710.6456 - val_loss: 700.0276\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 679.0191 - val_loss: 667.1570\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 650.7303 - val_loss: 639.8932\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 623.0672 - val_loss: 612.0723\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 596.4847 - val_loss: 586.1528\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 574.6949 - val_loss: 562.5784\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 549.8401 - val_loss: 536.8428\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 526.5950 - val_loss: 515.8539\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 504.4657 - val_loss: 492.4893\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 484.9286 - val_loss: 473.1439\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 466.7668 - val_loss: 452.9966\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 446.4715 - val_loss: 435.1302\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 430.1606 - val_loss: 416.4149\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 411.7253 - val_loss: 399.9249\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 395.6097 - val_loss: 383.0263\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 380.9285 - val_loss: 369.0702\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 366.5548 - val_loss: 354.0278\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 351.5067 - val_loss: 340.2939\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 338.7439 - val_loss: 326.4491\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 325.6103 - val_loss: 313.8753\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 5ms/step - loss: 313.3416 - val_loss: 302.8472\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 301.7401 - val_loss: 291.0666\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 291.3724 - val_loss: 280.2744\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 281.2648 - val_loss: 270.5810\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 271.7424 - val_loss: 260.7561\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.7052 - val_loss: 251.2681\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 253.4077 - val_loss: 242.9995\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 245.5526 - val_loss: 235.1251\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 237.5904 - val_loss: 227.6163\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 231.2410 - val_loss: 220.4853\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 128185.0078 - val_loss: 63772.3125\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 33829.7188 - val_loss: 12419.0674\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 6119.2109 - val_loss: 2621.5803\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 2393.4771 - val_loss: 1960.5487\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 2182.5464 - val_loss: 1865.9421\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 2065.8555 - val_loss: 1780.1420\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 1954.7942 - val_loss: 1680.7749\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 1844.7627 - val_loss: 1587.0439\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 1737.9579 - val_loss: 1493.4169\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 5ms/step - loss: 1637.9364 - val_loss: 1405.4120\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1539.0076 - val_loss: 1326.6292\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1443.5225 - val_loss: 1242.4254\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1356.8682 - val_loss: 1169.8795\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1281.0177 - val_loss: 1097.8723\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1202.1637 - val_loss: 1037.2527\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1125.6713 - val_loss: 972.7960\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1062.7032 - val_loss: 918.2717\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 998.5931 - val_loss: 869.1061\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 944.5831 - val_loss: 820.4048\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 891.7888 - val_loss: 778.6284\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 840.7465 - val_loss: 736.4888\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 796.8286 - val_loss: 699.8041\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 755.3556 - val_loss: 664.7943\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 717.3896 - val_loss: 634.9141\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 5ms/step - loss: 683.3466 - val_loss: 605.7505\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 653.1281 - val_loss: 579.6196\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 622.0458 - val_loss: 556.3696\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 594.1716 - val_loss: 532.8295\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 568.7833 - val_loss: 514.0163\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 546.2039 - val_loss: 494.3982\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 524.2384 - val_loss: 478.1990\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 503.2361 - val_loss: 460.4498\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 484.4008 - val_loss: 444.8960\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 467.0401 - val_loss: 430.3825\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 450.5697 - val_loss: 416.1092\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 435.3756 - val_loss: 403.1111\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 421.1398 - val_loss: 392.9579\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 408.6077 - val_loss: 380.8054\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 397.5856 - val_loss: 370.8337\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 384.8198 - val_loss: 361.2743\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 374.8122 - val_loss: 351.6000\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 363.6619 - val_loss: 342.4996\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 353.5397 - val_loss: 333.5707\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 344.4904 - val_loss: 324.5242\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 334.6285 - val_loss: 316.0626\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.1024 - val_loss: 307.6257\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 317.3112 - val_loss: 299.4496\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 5ms/step - loss: 308.1584 - val_loss: 291.2599\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 299.4634 - val_loss: 283.5138\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 292.0223 - val_loss: 274.9173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 37862.0234 - val_loss: 9867.1348\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 6678.8203 - val_loss: 3779.1917\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 4258.6406 - val_loss: 3732.4021\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 3923.6660 - val_loss: 3234.4924\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 3560.9854 - val_loss: 2933.9653\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 3229.8628 - val_loss: 2685.9966\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 2926.0378 - val_loss: 2446.9690\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 2631.9915 - val_loss: 2195.1755\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2363.8784 - val_loss: 2003.5043\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2129.6619 - val_loss: 1795.0083\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 1904.9097 - val_loss: 1622.2839\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1702.9939 - val_loss: 1450.6887\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 1514.0475 - val_loss: 1327.6687\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1366.2385 - val_loss: 1185.2039\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1220.9105 - val_loss: 1069.0370\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1108.1332 - val_loss: 972.9387\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 989.9816 - val_loss: 889.6237\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 892.8621 - val_loss: 821.8124\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 806.2154 - val_loss: 734.5966\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 729.7642 - val_loss: 678.4660\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 660.5166 - val_loss: 617.0264\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 603.5453 - val_loss: 571.8596\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 545.9950 - val_loss: 524.4035\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 498.1519 - val_loss: 477.0873\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 456.1965 - val_loss: 442.3924\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 418.7497 - val_loss: 413.2261\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 5ms/step - loss: 386.6628 - val_loss: 381.9551\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 354.1698 - val_loss: 353.1920\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 327.9289 - val_loss: 328.9073\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 303.0320 - val_loss: 308.5405\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 281.9857 - val_loss: 288.3865\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.1537 - val_loss: 272.3929\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 247.4296 - val_loss: 258.2851\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 232.6158 - val_loss: 243.2654\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 221.2291 - val_loss: 233.3957\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.0511 - val_loss: 222.4674\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 199.3697 - val_loss: 211.3756\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 192.5649 - val_loss: 203.3449\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 184.8026 - val_loss: 195.3921\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 5ms/step - loss: 179.1308 - val_loss: 189.1020\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.2438 - val_loss: 182.4972\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 169.1896 - val_loss: 178.3235\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 164.8102 - val_loss: 174.0830\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 162.6592 - val_loss: 169.3323\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 157.0048 - val_loss: 164.9528\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 154.5179 - val_loss: 161.0017\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 11ms/step - loss: 152.3258 - val_loss: 158.1757\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 14ms/step - loss: 150.8832 - val_loss: 157.5466\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 148.2333 - val_loss: 152.8607\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 146.6159 - val_loss: 151.2843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 44ms/step - loss: 299302.4375 - val_loss: 210251.3125\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 146457.0469 - val_loss: 89126.9922\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 53443.1250 - val_loss: 26741.8711\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 15064.1182 - val_loss: 9901.2363\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 7714.2793 - val_loss: 8143.4814\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 6948.1489 - val_loss: 7566.0493\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 5ms/step - loss: 6445.8154 - val_loss: 7027.6523\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 5ms/step - loss: 5981.1958 - val_loss: 6523.0283\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 5559.1641 - val_loss: 6058.4268\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 5176.1323 - val_loss: 5652.9111\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 4834.3867 - val_loss: 5267.9585\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 4517.5269 - val_loss: 4925.0923\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 4235.3213 - val_loss: 4601.2397\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 3950.2625 - val_loss: 4317.9917\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 3719.2019 - val_loss: 4056.2058\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 3495.2593 - val_loss: 3816.3250\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 3299.5869 - val_loss: 3594.7747\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 3115.9609 - val_loss: 3400.8240\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 2955.7434 - val_loss: 3221.8171\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 2801.1536 - val_loss: 3040.1606\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 2657.6091 - val_loss: 2888.2178\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 2522.5986 - val_loss: 2737.6785\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 5ms/step - loss: 2401.2231 - val_loss: 2602.7554\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 2290.6470 - val_loss: 2487.3320\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 2185.0344 - val_loss: 2362.9089\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 2085.6558 - val_loss: 2258.4934\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1995.5782 - val_loss: 2153.9326\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 1909.7786 - val_loss: 2066.7141\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 1822.4240 - val_loss: 1966.4017\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 1744.9071 - val_loss: 1887.8824\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 1672.4913 - val_loss: 1802.5427\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 1607.0255 - val_loss: 1726.0511\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 5ms/step - loss: 1536.9302 - val_loss: 1651.9539\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 1474.3829 - val_loss: 1590.2627\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 1431.2622 - val_loss: 1526.0107\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 1359.8599 - val_loss: 1458.0994\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 1308.5767 - val_loss: 1406.5098\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 1264.2511 - val_loss: 1346.7039\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 1208.2242 - val_loss: 1293.8623\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 1165.4739 - val_loss: 1242.0498\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 1120.9526 - val_loss: 1196.3143\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 5ms/step - loss: 1079.3181 - val_loss: 1150.1650\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 1037.2166 - val_loss: 1109.4061\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 1001.5328 - val_loss: 1063.1445\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 958.9183 - val_loss: 1034.0787\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 924.6462 - val_loss: 986.6204\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 890.6282 - val_loss: 950.9434\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 856.2960 - val_loss: 922.0821\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 825.9677 - val_loss: 882.5925\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 794.1685 - val_loss: 850.5242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 46ms/step - loss: 1370371.5000 - val_loss: 1129913.1250\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 969134.6250 - val_loss: 793035.3125\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 674810.6250 - val_loss: 546352.2500\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 458925.2812 - val_loss: 365998.3438\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 301812.3125 - val_loss: 235672.1875\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 189983.4375 - val_loss: 144252.7812\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 113204.6797 - val_loss: 82994.9141\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 63225.6211 - val_loss: 44784.8047\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 32999.6719 - val_loss: 22598.1699\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 16165.6143 - val_loss: 10824.4365\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 7675.5029 - val_loss: 5149.1099\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 3775.4688 - val_loss: 2708.0100\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 4ms/step - loss: 2175.5547 - val_loss: 1720.5425\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1564.4580 - val_loss: 1355.9855\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1345.8287 - val_loss: 1225.1593\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 1265.2059 - val_loss: 1171.7521\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 1227.8629 - val_loss: 1142.1320\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 1203.6268 - val_loss: 1118.3722\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 1181.6616 - val_loss: 1099.7432\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 1160.5748 - val_loss: 1079.0504\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 1140.0686 - val_loss: 1059.8593\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 1119.5391 - val_loss: 1039.8456\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 1098.9714 - val_loss: 1021.9506\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 8ms/step - loss: 1078.2976 - val_loss: 1003.7183\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 1059.3356 - val_loss: 983.9524\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 1038.1494 - val_loss: 965.9772\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 1018.0623 - val_loss: 947.8978\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 998.2678 - val_loss: 930.4796\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 979.3864 - val_loss: 912.3475\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 959.9024 - val_loss: 894.2289\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 941.5643 - val_loss: 878.5031\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 922.8154 - val_loss: 860.4403\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 903.7147 - val_loss: 844.5634\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 885.2201 - val_loss: 827.2061\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 866.9760 - val_loss: 811.7376\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 849.4188 - val_loss: 796.4271\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 833.4134 - val_loss: 781.1894\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 815.7538 - val_loss: 766.7253\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 799.7292 - val_loss: 752.9318\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 784.9518 - val_loss: 738.2379\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 770.2531 - val_loss: 725.6257\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 753.7360 - val_loss: 711.3133\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 739.0798 - val_loss: 698.6876\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 725.5247 - val_loss: 686.2086\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 711.4982 - val_loss: 674.2386\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 697.4119 - val_loss: 663.0524\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 684.7576 - val_loss: 651.2516\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 671.7036 - val_loss: 640.2778\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 659.3511 - val_loss: 629.7510\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 4ms/step - loss: 647.6464 - val_loss: 619.9182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 37671.5820 - val_loss: 25415.7480\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 17593.3848 - val_loss: 10484.5518\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 6201.9854 - val_loss: 2734.9861\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 1457.1542 - val_loss: 876.1573\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 804.3455 - val_loss: 802.0134\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 756.4666 - val_loss: 750.1788\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 710.9929 - val_loss: 708.9837\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 672.8881 - val_loss: 670.5923\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 5ms/step - loss: 637.9713 - val_loss: 634.0568\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 605.6622 - val_loss: 604.2808\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 5ms/step - loss: 576.6572 - val_loss: 574.8984\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 550.6478 - val_loss: 549.3375\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 527.2036 - val_loss: 525.5414\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 5ms/step - loss: 505.6223 - val_loss: 504.7172\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 486.1034 - val_loss: 485.9761\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 469.6143 - val_loss: 468.5196\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 452.5353 - val_loss: 453.0847\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 438.3425 - val_loss: 438.5448\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 424.4672 - val_loss: 426.0561\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 412.2546 - val_loss: 413.6360\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 400.8554 - val_loss: 402.7502\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 390.2591 - val_loss: 391.9948\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 380.2749 - val_loss: 382.9414\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 7ms/step - loss: 371.6705 - val_loss: 374.1229\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 363.5930 - val_loss: 365.7616\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 355.1531 - val_loss: 358.0107\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 347.8672 - val_loss: 350.5035\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 4ms/step - loss: 340.8178 - val_loss: 343.4963\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 333.0660 - val_loss: 337.1393\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 326.8945 - val_loss: 331.1418\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 5ms/step - loss: 320.7671 - val_loss: 325.1891\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 314.7796 - val_loss: 319.5795\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 309.1602 - val_loss: 314.0973\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 304.8978 - val_loss: 309.1230\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 298.7782 - val_loss: 304.3283\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 8ms/step - loss: 293.0956 - val_loss: 299.5172\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 289.2793 - val_loss: 294.9944\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 284.2834 - val_loss: 290.7346\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 278.8399 - val_loss: 286.6215\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 275.0059 - val_loss: 282.1709\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 272.3180 - val_loss: 278.3526\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 266.3099 - val_loss: 274.1589\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 262.8285 - val_loss: 270.5701\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 258.5992 - val_loss: 266.9079\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 4ms/step - loss: 254.6802 - val_loss: 263.3086\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 250.4298 - val_loss: 259.6580\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 246.8014 - val_loss: 256.5860\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 243.9615 - val_loss: 253.0087\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 239.1505 - val_loss: 249.6743\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 10ms/step - loss: 236.8186 - val_loss: 247.1140\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SB INFO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 - 1s - 45ms/step - loss: 41484.3008 - val_loss: 9008.6250\n",
      "Epoch 2/50\n",
      "23/23 - 0s - 4ms/step - loss: 6959.0547 - val_loss: 5720.4302\n",
      "Epoch 3/50\n",
      "23/23 - 0s - 4ms/step - loss: 5737.5210 - val_loss: 4702.6733\n",
      "Epoch 4/50\n",
      "23/23 - 0s - 4ms/step - loss: 4977.5151 - val_loss: 4073.6748\n",
      "Epoch 5/50\n",
      "23/23 - 0s - 4ms/step - loss: 4475.0215 - val_loss: 3666.0396\n",
      "Epoch 6/50\n",
      "23/23 - 0s - 4ms/step - loss: 3986.4275 - val_loss: 3194.3083\n",
      "Epoch 7/50\n",
      "23/23 - 0s - 4ms/step - loss: 3521.5261 - val_loss: 2814.5686\n",
      "Epoch 8/50\n",
      "23/23 - 0s - 4ms/step - loss: 3099.2202 - val_loss: 2421.8772\n",
      "Epoch 9/50\n",
      "23/23 - 0s - 4ms/step - loss: 2707.4785 - val_loss: 2109.3518\n",
      "Epoch 10/50\n",
      "23/23 - 0s - 4ms/step - loss: 2348.4231 - val_loss: 1790.0215\n",
      "Epoch 11/50\n",
      "23/23 - 0s - 4ms/step - loss: 2029.1678 - val_loss: 1570.1111\n",
      "Epoch 12/50\n",
      "23/23 - 0s - 4ms/step - loss: 1755.7086 - val_loss: 1309.5793\n",
      "Epoch 13/50\n",
      "23/23 - 0s - 5ms/step - loss: 1508.0938 - val_loss: 1125.7102\n",
      "Epoch 14/50\n",
      "23/23 - 0s - 4ms/step - loss: 1296.8453 - val_loss: 952.0648\n",
      "Epoch 15/50\n",
      "23/23 - 0s - 4ms/step - loss: 1116.2094 - val_loss: 828.7673\n",
      "Epoch 16/50\n",
      "23/23 - 0s - 4ms/step - loss: 962.4592 - val_loss: 710.8495\n",
      "Epoch 17/50\n",
      "23/23 - 0s - 4ms/step - loss: 832.4164 - val_loss: 615.9778\n",
      "Epoch 18/50\n",
      "23/23 - 0s - 4ms/step - loss: 728.2380 - val_loss: 544.4951\n",
      "Epoch 19/50\n",
      "23/23 - 0s - 4ms/step - loss: 633.8257 - val_loss: 477.5469\n",
      "Epoch 20/50\n",
      "23/23 - 0s - 4ms/step - loss: 560.0411 - val_loss: 426.0611\n",
      "Epoch 21/50\n",
      "23/23 - 0s - 4ms/step - loss: 498.2411 - val_loss: 382.5490\n",
      "Epoch 22/50\n",
      "23/23 - 0s - 4ms/step - loss: 448.8848 - val_loss: 350.1763\n",
      "Epoch 23/50\n",
      "23/23 - 0s - 4ms/step - loss: 410.5597 - val_loss: 323.3005\n",
      "Epoch 24/50\n",
      "23/23 - 0s - 4ms/step - loss: 376.6966 - val_loss: 302.3921\n",
      "Epoch 25/50\n",
      "23/23 - 0s - 4ms/step - loss: 345.6036 - val_loss: 285.6027\n",
      "Epoch 26/50\n",
      "23/23 - 0s - 4ms/step - loss: 323.2541 - val_loss: 271.2394\n",
      "Epoch 27/50\n",
      "23/23 - 0s - 4ms/step - loss: 304.6582 - val_loss: 260.8143\n",
      "Epoch 28/50\n",
      "23/23 - 0s - 5ms/step - loss: 287.3717 - val_loss: 248.9533\n",
      "Epoch 29/50\n",
      "23/23 - 0s - 4ms/step - loss: 275.2984 - val_loss: 245.4075\n",
      "Epoch 30/50\n",
      "23/23 - 0s - 4ms/step - loss: 263.4823 - val_loss: 230.4700\n",
      "Epoch 31/50\n",
      "23/23 - 0s - 4ms/step - loss: 250.5877 - val_loss: 223.5115\n",
      "Epoch 32/50\n",
      "23/23 - 0s - 4ms/step - loss: 240.6207 - val_loss: 217.2474\n",
      "Epoch 33/50\n",
      "23/23 - 0s - 4ms/step - loss: 231.8583 - val_loss: 210.4323\n",
      "Epoch 34/50\n",
      "23/23 - 0s - 4ms/step - loss: 223.0561 - val_loss: 204.4171\n",
      "Epoch 35/50\n",
      "23/23 - 0s - 4ms/step - loss: 215.2186 - val_loss: 198.5923\n",
      "Epoch 36/50\n",
      "23/23 - 0s - 4ms/step - loss: 210.2806 - val_loss: 193.0441\n",
      "Epoch 37/50\n",
      "23/23 - 0s - 4ms/step - loss: 200.9130 - val_loss: 188.1045\n",
      "Epoch 38/50\n",
      "23/23 - 0s - 4ms/step - loss: 194.9835 - val_loss: 189.7140\n",
      "Epoch 39/50\n",
      "23/23 - 0s - 4ms/step - loss: 190.7369 - val_loss: 178.3109\n",
      "Epoch 40/50\n",
      "23/23 - 0s - 4ms/step - loss: 183.9066 - val_loss: 174.3832\n",
      "Epoch 41/50\n",
      "23/23 - 0s - 4ms/step - loss: 178.0497 - val_loss: 169.7348\n",
      "Epoch 42/50\n",
      "23/23 - 0s - 4ms/step - loss: 173.9079 - val_loss: 171.3077\n",
      "Epoch 43/50\n",
      "23/23 - 0s - 4ms/step - loss: 176.2164 - val_loss: 162.6946\n",
      "Epoch 44/50\n",
      "23/23 - 0s - 4ms/step - loss: 163.9038 - val_loss: 161.8955\n",
      "Epoch 45/50\n",
      "23/23 - 0s - 8ms/step - loss: 161.0459 - val_loss: 154.9578\n",
      "Epoch 46/50\n",
      "23/23 - 0s - 4ms/step - loss: 156.9492 - val_loss: 152.2096\n",
      "Epoch 47/50\n",
      "23/23 - 0s - 4ms/step - loss: 152.9776 - val_loss: 150.7942\n",
      "Epoch 48/50\n",
      "23/23 - 0s - 4ms/step - loss: 153.1445 - val_loss: 146.1646\n",
      "Epoch 49/50\n",
      "23/23 - 0s - 4ms/step - loss: 149.0667 - val_loss: 150.9016\n",
      "Epoch 50/50\n",
      "23/23 - 0s - 5ms/step - loss: 148.8755 - val_loss: 145.1462\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "n_cols = predictor.shape[1] # number of predictors\n",
    "mean_squared_errors = []\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for i in range(50):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(predictor, target, test_size=0.3)\n",
    "    model = regression_model()\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, verbose=2)\n",
    "    \n",
    "    predictions=model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, predictions)\n",
    "    mean_squared_errors.append(mse)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4235c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Mean Squared Errors: 306.5576972136569\n",
      "Standard Deviation of Mean Squared Errors: 236.66280913556488\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and standard deviation of the mean squared errors\n",
    "import numpy as np\n",
    "mean_mse = np.mean(mean_squared_errors)\n",
    "std_mse = np.std(mean_squared_errors)\n",
    "\n",
    "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
    "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5616c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
